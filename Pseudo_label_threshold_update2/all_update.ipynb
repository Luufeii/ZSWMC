{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "pseudo_four_data_path = 'data_fake_label/four_fake_label_WM.npz' \n",
    "pseudo_four_data = np.load(pseudo_four_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "pseudo_four_label = pseudo_four_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "pseudo_four_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_four_data['label_name']:\n",
    "    pseudo_four_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "pseudo_four_att_vector = np.array(pseudo_four_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 52, 52]) torch.Size([2593, 20])\n",
      "torch.Size([4130, 1, 52, 52]) torch.Size([4130, 20])\n",
      "torch.Size([1629, 1, 52, 52]) torch.Size([1629, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "pseudo_four_wm = pseudo_four_data['denoise_wm']\n",
    "pseudo_four_wm_tensor = torch.reshape(torch.tensor(pseudo_four_wm, dtype=torch.float32),(len(pseudo_four_wm),1,52,52))\n",
    "pseudo_four_att_tensor = torch.tensor(pseudo_four_att_vector, dtype=torch.float32)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 224, 224]) torch.Size([2593, 20])\n",
      "torch.Size([4130, 1, 224, 224]) torch.Size([4130, 20])\n",
      "torch.Size([1629, 1, 224, 224]) torch.Size([1629, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "pseudo_four_wm_tensor = trans(pseudo_four_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593 2593\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "4130 4130\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "1629 1629\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_label = list(pseudo_three_label)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)\n",
    "\n",
    "pseudo_four_wm = list(pseudo_four_wm_tensor)\n",
    "pseudo_four_label = list(pseudo_four_label)\n",
    "pseudo_four_att = list(pseudo_four_att_tensor)\n",
    "print(len(pseudo_four_wm),len(pseudo_four_att))\n",
    "print(pseudo_four_wm[10].shape, pseudo_four_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor, pseudo_four_wm_tensor, pseudo_four_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm + pseudo_four_wm\n",
    "train_label = train_single_label + pseudo_two_label + pseudo_three_label + pseudo_four_label\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att + pseudo_four_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "# train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "# train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "# train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "train_mul_wm = train_two_wm + train_three_wm + train_four_wm\n",
    "train_mul_wm_tensor = torch.tensor(np.array(train_mul_wm), dtype=torch.float32)\n",
    "\n",
    "val_wm = val_single_wm + val_two_wm + val_three_wm + val_four_wm\n",
    "val_label = val_single_label + val_two_label + val_three_label + val_four_label\n",
    "val_att = val_single_att + val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_single_label + test_two_label + test_three_label + test_four_label\n",
    "test_att = test_single_att + test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_all.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：4.593599557876587, 总Loss:2.174830015283078\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:2.6950407221447676\n",
      "第1轮训练后,整体验证集上的Accuracy:0.7402702702702703\n",
      "————第2轮训练开始————\n",
      "训练时间为：4.632336139678955, 总Loss:2.0483895069919527\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:2.7540403436287306\n",
      "第2轮训练后,整体验证集上的Accuracy:0.737027027027027\n",
      "————第3轮训练开始————\n",
      "训练时间为：4.625746011734009, 总Loss:1.9826989257708192\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:2.6772299164440483\n",
      "第3轮训练后,整体验证集上的Accuracy:0.7475675675675676\n",
      "————第4轮训练开始————\n",
      "训练时间为：4.565672159194946, 总Loss:1.979826939292252\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:2.6789710970479064\n",
      "第4轮训练后,整体验证集上的Accuracy:0.7302702702702702\n",
      "————第5轮训练开始————\n",
      "训练时间为：4.420842885971069, 总Loss:1.938035732600838\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:2.528769460914191\n",
      "第5轮训练后,整体验证集上的Accuracy:0.7429729729729729\n",
      "————第6轮训练开始————\n",
      "训练时间为：4.513551950454712, 总Loss:1.9157419227994978\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:2.6414160176354926\n",
      "第6轮训练后,整体验证集上的Accuracy:0.7375675675675676\n",
      "————第7轮训练开始————\n",
      "训练时间为：4.498087644577026, 总Loss:1.8685505520552397\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:2.7396398253622465\n",
      "第7轮训练后,整体验证集上的Accuracy:0.7248648648648649\n",
      "————第8轮训练开始————\n",
      "训练时间为：4.526318788528442, 总Loss:2.0208341870456934\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:2.695040361781139\n",
      "第8轮训练后,整体验证集上的Accuracy:0.7327027027027027\n",
      "————第9轮训练开始————\n",
      "训练时间为：4.611795663833618, 总Loss:1.978539811912924\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:2.688223550678231\n",
      "第9轮训练后,整体验证集上的Accuracy:0.7386486486486487\n",
      "————第10轮训练开始————\n",
      "训练时间为：4.5534608364105225, 总Loss:1.9884944492951035\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:2.70948879988282\n",
      "第10轮训练后,整体验证集上的Accuracy:0.7472972972972973\n",
      "————第11轮训练开始————\n",
      "训练时间为：4.498115539550781, 总Loss:1.9361335947178304\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:2.7012197951844428\n",
      "第11轮训练后,整体验证集上的Accuracy:0.7394594594594595\n",
      "————第12轮训练开始————\n",
      "训练时间为：4.52226710319519, 总Loss:1.9882716941647232\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:2.6278169902216177\n",
      "第12轮训练后,整体验证集上的Accuracy:0.7429729729729729\n",
      "————第13轮训练开始————\n",
      "训练时间为：4.62746000289917, 总Loss:2.0208963956683874\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:2.6745645558694378\n",
      "第13轮训练后,整体验证集上的Accuracy:0.7408108108108108\n",
      "————第14轮训练开始————\n",
      "训练时间为：4.515799283981323, 总Loss:2.08237293548882\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:2.76468478073366\n",
      "第14轮训练后,整体验证集上的Accuracy:0.7413513513513513\n",
      "————第15轮训练开始————\n",
      "训练时间为：4.510081768035889, 总Loss:2.0996711463667452\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:2.732052306877449\n",
      "第15轮训练后,整体验证集上的Accuracy:0.7462162162162163\n",
      "————第16轮训练开始————\n",
      "训练时间为：4.497878074645996, 总Loss:2.1746727069839835\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:2.829599064803915\n",
      "第16轮训练后,整体验证集上的Accuracy:0.7405405405405405\n",
      "————第17轮训练开始————\n",
      "训练时间为：4.634256601333618, 总Loss:2.2104881377890706\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:2.913278356718365\n",
      "第17轮训练后,整体验证集上的Accuracy:0.7497297297297297\n",
      "————第18轮训练开始————\n",
      "训练时间为：4.512059688568115, 总Loss:2.1310725761577487\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:2.8629216286353767\n",
      "第18轮训练后,整体验证集上的Accuracy:0.7443243243243243\n",
      "————第19轮训练开始————\n",
      "训练时间为：4.624321937561035, 总Loss:2.1462817369028926\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:2.9552079240093008\n",
      "第19轮训练后,整体验证集上的Accuracy:0.7408108108108108\n",
      "————第20轮训练开始————\n",
      "训练时间为：4.629149436950684, 总Loss:2.193267053924501\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:2.880942242423771\n",
      "第20轮训练后,整体验证集上的Accuracy:0.7464864864864865\n",
      "训练结束，第17轮的模型在验证集上准确率最高，为0.7497297297297297\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    mul_defect_att = update_semantic(model, mul_defect_att, train_mul_wm_tensor, 50)\n",
    "    total_defect_att = {**single_defect_att, **mul_defect_att}\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = total_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = total_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model, val_loader, total_defect_att, val_size, 'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/all_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_all/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_all/updated_mul_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(mul_defect_att, file)\n",
    "        with open('updated_semantic_all/updated_total_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(total_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset,train_loader,val_dataset,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_all.pth')\n",
    "model.eval()\n",
    "\n",
    "with open('updated_semantic_all/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_total_dict.pkl', 'rb') as file:\n",
    "    total_defect_att = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = total_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.9264, -0.0308,  0.8845,  0.9428,  0.9135,  0.8375,  0.8028, -0.0023,\n",
      "         0.9586, -0.0076,  0.0129,  0.0303,  0.9611,  1.0295,  0.6712,  0.9979,\n",
      "         0.8039,  0.0192,  0.0042,  1.0328], device='cuda:0')\n",
      "真实的属性向量tensor([ 1.0335, -0.0026,  0.9338,  1.0113,  1.2201,  0.9800,  0.8714,  0.0390,\n",
      "         1.1610, -0.0057,  0.0034,  0.0102,  1.0807,  1.2445,  0.9194,  1.1087,\n",
      "         0.8941,  0.0468,  0.0088,  1.1806])\n",
      "真实标签为：C+EL+L+S\n",
      "欧式距离计算的标签为：C+EL+L+S\n",
      "余弦相似度计算的标签为：C+EL+L+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_wm_tensor, test_att_tensor, total_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7531397704253883\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_loader, total_defect_att, len(test_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
