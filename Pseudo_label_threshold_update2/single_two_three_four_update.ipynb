{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 52, 52]) torch.Size([2593, 20])\n",
      "torch.Size([4130, 1, 52, 52]) torch.Size([4130, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 224, 224]) torch.Size([2593, 20])\n",
      "torch.Size([4130, 1, 224, 224]) torch.Size([4130, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593 2593\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "4130 4130\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_label = list(pseudo_three_label)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm\n",
    "train_label = train_single_label + pseudo_two_label + pseudo_three_label\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "# train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "# train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "# train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "train_mul_wm = train_two_wm + train_three_wm + train_four_wm\n",
    "train_mul_wm_tensor = torch.tensor(np.array(train_mul_wm), dtype=torch.float32)\n",
    "\n",
    "val_wm = val_two_wm + val_three_wm + val_four_wm\n",
    "val_label = val_two_label + val_three_label + val_four_label\n",
    "val_att = val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_two_label + test_three_label + test_four_label\n",
    "test_att = test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single_two_three.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：4.169867038726807, 总Loss:1.3380413327831775\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:1.9632880472927354\n",
      "第1轮训练后,整体验证集上的Accuracy:0.6227586206896552\n",
      "————第2轮训练开始————\n",
      "训练时间为：4.091558218002319, 总Loss:1.2094852873124182\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:1.691564348700922\n",
      "第2轮训练后,整体验证集上的Accuracy:0.6506896551724138\n",
      "————第3轮训练开始————\n",
      "训练时间为：4.035709619522095, 总Loss:1.2078350218944252\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:2.0026150842604693\n",
      "第3轮训练后,整体验证集上的Accuracy:0.6210344827586207\n",
      "————第4轮训练开始————\n",
      "训练时间为：3.982710838317871, 总Loss:1.1118560368195176\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:1.7108297305530868\n",
      "第4轮训练后,整体验证集上的Accuracy:0.6479310344827586\n",
      "————第5轮训练开始————\n",
      "训练时间为：3.9957900047302246, 总Loss:1.1454206458292902\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:1.8928421026212163\n",
      "第5轮训练后,整体验证集上的Accuracy:0.6331034482758621\n",
      "————第6轮训练开始————\n",
      "训练时间为：4.092657089233398, 总Loss:1.1596484605688602\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:1.8494657672126777\n",
      "第6轮训练后,整体验证集上的Accuracy:0.6420689655172414\n",
      "————第7轮训练开始————\n",
      "训练时间为：4.02019739151001, 总Loss:1.1702520123217255\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:1.7965635174768977\n",
      "第7轮训练后,整体验证集上的Accuracy:0.6448275862068965\n",
      "————第8轮训练开始————\n",
      "训练时间为：4.1598358154296875, 总Loss:1.1525142630562186\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:1.829732863319805\n",
      "第8轮训练后,整体验证集上的Accuracy:0.6393103448275862\n",
      "————第9轮训练开始————\n",
      "训练时间为：4.042445182800293, 总Loss:1.1602566281799227\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:1.751746448338963\n",
      "第9轮训练后,整体验证集上的Accuracy:0.6520689655172414\n",
      "————第10轮训练开始————\n",
      "训练时间为：4.044048309326172, 总Loss:1.1476867413148284\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:1.7996248611598276\n",
      "第10轮训练后,整体验证集上的Accuracy:0.6517241379310345\n",
      "————第11轮训练开始————\n",
      "训练时间为：4.1143505573272705, 总Loss:1.1109497162979096\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:1.8107751625648234\n",
      "第11轮训练后,整体验证集上的Accuracy:0.6417241379310344\n",
      "————第12轮训练开始————\n",
      "训练时间为：3.957871198654175, 总Loss:1.1198695967905223\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:1.8017958189011551\n",
      "第12轮训练后,整体验证集上的Accuracy:0.6496551724137931\n",
      "————第13轮训练开始————\n",
      "训练时间为：4.038991212844849, 总Loss:1.168024884071201\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:1.9311887319781817\n",
      "第13轮训练后,整体验证集上的Accuracy:0.6268965517241379\n",
      "————第14轮训练开始————\n",
      "训练时间为：3.9521069526672363, 总Loss:1.1383505552075803\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:1.962383240199415\n",
      "第14轮训练后,整体验证集上的Accuracy:0.6272413793103448\n",
      "————第15轮训练开始————\n",
      "训练时间为：4.001611232757568, 总Loss:1.1196959356311709\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:1.8734213547431864\n",
      "第15轮训练后,整体验证集上的Accuracy:0.6382758620689655\n",
      "————第16轮训练开始————\n",
      "训练时间为：3.9080958366394043, 总Loss:1.1359357649926096\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:1.8770630000217352\n",
      "第16轮训练后,整体验证集上的Accuracy:0.6282758620689655\n",
      "————第17轮训练开始————\n",
      "训练时间为：3.947971820831299, 总Loss:1.1391949178650975\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:1.8107588946004398\n",
      "第17轮训练后,整体验证集上的Accuracy:0.6472413793103449\n",
      "————第18轮训练开始————\n",
      "训练时间为：4.053761005401611, 总Loss:1.1714512524195015\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:1.6461069580400363\n",
      "第18轮训练后,整体验证集上的Accuracy:0.67\n",
      "————第19轮训练开始————\n",
      "训练时间为：3.9394166469573975, 总Loss:1.1832996867597103\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:1.9243970704847015\n",
      "第19轮训练后,整体验证集上的Accuracy:0.6358620689655172\n",
      "————第20轮训练开始————\n",
      "训练时间为：4.07152247428894, 总Loss:1.1278050008695573\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:1.7896795184060466\n",
      "第20轮训练后,整体验证集上的Accuracy:0.6496551724137931\n",
      "训练结束，第18轮的模型在验证集上准确率最高，为0.67\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    mul_defect_att = update_semantic(model, mul_defect_att, train_mul_wm_tensor, 50)\n",
    "    total_defect_att = {**single_defect_att, **mul_defect_att}\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = total_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = mul_defect_att[val_label[i]] \n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model, val_loader, mul_defect_att, val_size, 'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_three_four_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2_3_4/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2_3_4/updated_mul_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(mul_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset,train_loader,val_dataset,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_single_two_three.pth')\n",
    "model.eval()\n",
    "\n",
    "with open('updated_semantic_1_2_3_4/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3_4/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = mul_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 2.6125e-01,  2.7017e-01,  4.9738e-01,  6.0603e-01,  1.1526e+00,\n",
      "         7.0469e-01,  8.2194e-01,  6.1746e-01,  8.8902e-01, -1.0923e-02,\n",
      "        -9.4029e-04, -5.3838e-03,  6.8032e-01,  9.5547e-01,  5.9945e-01,\n",
      "         7.0770e-01,  8.2175e-01,  6.1747e-01,  5.4563e-01,  6.4856e-01],\n",
      "       device='cuda:0')\n",
      "真实的属性向量tensor([ 0.2693,  0.4057,  0.6978,  0.7911,  1.0909,  0.8594,  0.8367,  0.7677,\n",
      "         0.9464, -0.0147, -0.0027, -0.0093,  0.5920,  0.9872,  0.4590,  0.8578,\n",
      "         0.8368,  0.7679,  0.6062,  0.7894])\n",
      "真实标签为：ER+L+S\n",
      "欧式距离计算的标签为：ER+L+S\n",
      "余弦相似度计算的标签为：ER+L+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_wm_tensor, test_att_tensor, mul_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7008620689655173\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_loader, mul_defect_att, len(test_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21090/311944114.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  train_mul_att_tensor = torch.tensor(train_mul_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_mul_label = train_two_label + train_three_label + train_four_label\n",
    "\n",
    "train_mul_att = train_two_att + train_three_att + train_four_att\n",
    "train_mul_att_tensor = torch.tensor(train_mul_att, dtype=torch.float32)\n",
    "for i in range(len(train_mul_label)):\n",
    "    train_mul_att_tensor[i] = mul_defect_att[train_mul_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mul_dataset = MyDataSet(train_mul_wm_tensor, train_mul_att_tensor)\n",
    "\n",
    "train_mul_loader = DataLoader(train_mul_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6897536945812808\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_mul_loader, mul_defect_att, len(train_mul_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
