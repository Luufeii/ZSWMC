{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行视觉空间和语义空间都预测的实验，并行和串行的实验方案流程，可以参考《DUAL COLLABORATIVE VISUAL-SEMANTIC MAPPING FOR MULTI-LABEL\n",
    "ZERO-SHOT IMAGE RECOGNITION》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们首先得到visual space和semantic space预测的标签\n",
    "# 得到两个空间预测结果相同的标签，不相同的标签我们丢弃(不预测)，可以称为弃检率\n",
    "# 我们再计算两个空间预测结果相同的标签的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备模型以及数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型以及语义属性\n",
    "import pickle\n",
    "model = torch.load('../model_saved_pseudo/train_all.pth')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "model_fea = torch.nn.Sequential(*list(model.children())[:-2])  # 由于加了sigmoid层，所以这里是[:-2]\n",
    "model_fea = model_fea.to(device)\n",
    "model_fea.eval()\n",
    "\n",
    "'''\n",
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att\n",
    "total_defect_att = attri.total_defect_att\n",
    "'''\n",
    "\n",
    "with open('../updated_semantic_all/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('../updated_semantic_all/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n",
    "with open('../updated_semantic_all/updated_total_dict.pkl', 'rb') as file:\n",
    "    total_defect_att = pickle.load(file)\n",
    "\n",
    "from collections import Counter\n",
    "# 加载二、三、四缺陷的字典\n",
    "two_defect_att = {}\n",
    "three_defect_att = {}\n",
    "four_defect_att = {}\n",
    "for label in mul_defect_att.keys():\n",
    "    count = Counter(label)\n",
    "    if count['+'] == 1:\n",
    "        two_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 2:\n",
    "        three_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 3:\n",
    "        four_defect_att[label] = mul_defect_att[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载视觉中心\n",
    "with open('single_vc.pkl', 'rb') as file:\n",
    "    single_vc = pickle.load(file)\n",
    "with open('two_vc.pkl', 'rb') as file:\n",
    "    two_vc = pickle.load(file)\n",
    "with open('three_vc.pkl', 'rb') as file:\n",
    "    three_vc = pickle.load(file)\n",
    "with open('four_vc.pkl', 'rb') as file:\n",
    "    four_vc = pickle.load(file)\n",
    "with open('total_vc.pkl', 'rb') as file:\n",
    "    total_vc = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_defect_att = {**two_defect_att, **three_defect_att, **four_defect_att}\n",
    "mul_vc = {**two_vc, **three_vc, **four_vc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_dimen: 20\n"
     ]
    }
   ],
   "source": [
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(single_defect_att['Center'])\n",
    "print('att_dimen:', att_dimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7405, 1, 224, 224]) (7405,)\n"
     ]
    }
   ],
   "source": [
    "test_label = test_data['label_name']\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = trans(torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52)))\n",
    "print(test_wm_tensor.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "\n",
    "\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(test_wm_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):  # 参数v1,v2是np.array\n",
    "    # 计算两个向量之间的欧氏距离\n",
    "    distance = np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_visual(fea, vc):  # fea是numpy.ndarray类型\n",
    "    min_dis = math.inf\n",
    "    for c in vc.keys():  # 如果不带.keys()，for循环的字典也是默认取键\n",
    "        dis = euclidean_distance(fea, vc[c])\n",
    "        if dis < min_dis:\n",
    "            min_dis = dis\n",
    "            label = c\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_semantic(att, defect_dict):  # 使用余弦相似度\n",
    "    max_sim = -2\n",
    "    for c in defect_dict.keys():  # 如果不带.keys()，for循环的字典也是默认取键\n",
    "        sim = cosine_similarity(att, np.array(defect_dict[c]))\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            label = c\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_three_label)):\n",
    "    if test_three_label[i] in test_single_label:\n",
    "        print(i, test_three_label[i])\n",
    "    elif test_three_label[i] in test_two_label:\n",
    "        print(i, test_three_label[i])\n",
    "    elif test_three_label[i] in test_four_label:\n",
    "        print(i, test_three_label[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(model, dataloader, device):\n",
    "    x = []\n",
    "    y = []\n",
    "    with torch.no_grad():\n",
    "        for imgs,labels in dataloader:  \n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            for out in outputs:\n",
    "                x.append(out.flatten().cpu())  # 输出展开,out的维度大小变为512，没有flatten的话维度大小就是(512,1,1)\n",
    "            for label in labels:\n",
    "                y.append(label)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_space_predict(fea_arr, vc, att_arr, defect_dict, real_label):\n",
    "    \"\"\"\n",
    "    :param fea_arr: numpy array, shape (n_samples, n_features)\n",
    "    :param vc: dictionary\n",
    "    :param att_arr: numpy array, shape (n_samples, n_attributes)\n",
    "    :param defect_dict: dictionary\n",
    "    :param real_label: numpy array, shape (n_samples,)\n",
    "    \"\"\"\n",
    "    label_visual = []\n",
    "    for fea in fea_arr:\n",
    "        label_visual.append(predict_label_visual(fea, vc))\n",
    "    label_visual = np.array(label_visual)\n",
    "    \n",
    "    label_semantic = []\n",
    "    for att in att_arr:\n",
    "        label_semantic.append(predict_label_semantic(att, defect_dict))\n",
    "    label_semantic = np.array(label_semantic)\n",
    "\n",
    "    label_identical = label_visual[label_visual==label_semantic]\n",
    "    drop_rate = 1 - len(label_identical)/len(label_visual)\n",
    "\n",
    "    label_real = real_label[label_visual==label_semantic]\n",
    "\n",
    "    acc = (label_real==label_identical).sum()/len(label_real)\n",
    "\n",
    "    # 我们下面获取丢弃的样本在语义空间和视觉空间中的准确率\n",
    "    drop_real_label = real_label[label_visual!=label_semantic]\n",
    "    drop_label_semantic = label_semantic[label_visual!=label_semantic]\n",
    "    drop_label_visual = label_visual[label_visual!=label_semantic]\n",
    "\n",
    "    drop_acc_semantic = (drop_real_label==drop_label_semantic).sum()/len(drop_real_label)\n",
    "    drop_acc_visual = (drop_real_label==drop_label_visual).sum()/len(drop_real_label)\n",
    "\n",
    "    return acc, drop_rate, drop_acc_semantic, drop_acc_visual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_wm_tensor = torch.tensor(np.array(test_single_wm), dtype=torch.float32)\n",
    "single_dataset = MyDataSet(single_wm_tensor,test_single_label)\n",
    "single_loader = DataLoader(single_dataset, batch_size=32, shuffle=False)\n",
    "del single_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, single_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, single_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在狭义空间中，丢弃率为0.0212的情况下，准确率为0.9949，丢弃的样本的语义准确率为0.4412，视觉准确率为0.3824\n",
      "在广义空间中，丢弃率为0.0243的情况下，准确率为0.9962，丢弃的样本的语义准确率为0.2564，视觉准确率为0.3846\n"
     ]
    }
   ],
   "source": [
    "acc1, drop1, drop_semantic_acc1, drop_visual_acc1 = two_space_predict(x_fea, single_vc, x_att, single_defect_att, y_real)\n",
    "acc2, drop2, drop_semantic_acc2, drop_visual_acc2 = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'在狭义空间中，丢弃率为{drop1:.4f}的情况下，准确率为{acc1:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc1:.4f}，视觉准确率为{drop_visual_acc1:.4f}')\n",
    "print(f'在广义空间中，丢弃率为{drop2:.4f}的情况下，准确率为{acc2:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc2:.4f}，视觉准确率为{drop_visual_acc2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del single_dataset, single_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_wm_tensor = torch.tensor(np.array(test_two_wm), dtype=torch.float32)\n",
    "two_dataset = MyDataSet(two_wm_tensor,test_two_label)\n",
    "two_loader = DataLoader(two_dataset, batch_size=32, shuffle=False)\n",
    "del two_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, two_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, two_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在狭义空间中，丢弃率为0.0519的情况下，准确率为0.9501，丢弃的样本的语义准确率为0.6444，视觉准确率为0.2593\n",
      "在广义空间中，丢弃率为0.1288的情况下，准确率为0.8967，丢弃的样本的语义准确率为0.8000，视觉准确率为0.1224\n"
     ]
    }
   ],
   "source": [
    "acc1, drop1, drop_semantic_acc1, drop_visual_acc1 = two_space_predict(x_fea, two_vc, x_att, two_defect_att, y_real)\n",
    "acc2, drop2, drop_semantic_acc2, drop_visual_acc2 = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'在狭义空间中，丢弃率为{drop1:.4f}的情况下，准确率为{acc1:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc1:.4f}，视觉准确率为{drop_visual_acc1:.4f}')\n",
    "print(f'在广义空间中，丢弃率为{drop2:.4f}的情况下，准确率为{acc2:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc2:.4f}，视觉准确率为{drop_visual_acc2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del two_dataset, two_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_wm_tensor = torch.tensor(np.array(test_three_wm), dtype=torch.float32)\n",
    "three_dataset = MyDataSet(three_wm_tensor,test_three_label)\n",
    "three_loader = DataLoader(three_dataset, batch_size=32, shuffle=False)\n",
    "del three_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, three_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, three_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在狭义空间中，丢弃率为0.0904的情况下，准确率为0.8140，丢弃的样本的语义准确率为0.4240，视觉准确率为0.2350\n",
      "在广义空间中，丢弃率为0.1421的情况下，准确率为0.6129，丢弃的样本的语义准确率为0.4809，视觉准确率为0.1994\n"
     ]
    }
   ],
   "source": [
    "acc1, drop1, drop_semantic_acc1, drop_visual_acc1 = two_space_predict(x_fea, three_vc, x_att, three_defect_att, y_real)\n",
    "acc2, drop2, drop_semantic_acc2, drop_visual_acc2 = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'在狭义空间中，丢弃率为{drop1:.4f}的情况下，准确率为{acc1:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc1:.4f}，视觉准确率为{drop_visual_acc1:.4f}')\n",
    "print(f'在广义空间中，丢弃率为{drop2:.4f}的情况下，准确率为{acc2:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc2:.4f}，视觉准确率为{drop_visual_acc2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del three_dataset, three_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_wm_tensor = torch.tensor(np.array(test_four_wm), dtype=torch.float32)\n",
    "four_dataset = MyDataSet(four_wm_tensor,test_four_label)\n",
    "four_loader = DataLoader(four_dataset, batch_size=32, shuffle=False)\n",
    "del four_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, four_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, four_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在狭义空间中，丢弃率为0.1375的情况下，准确率为0.7101，丢弃的样本的语义准确率为0.7727，视觉准确率为0.2273\n",
      "在广义空间中，丢弃率为0.2312的情况下，准确率为0.3577，丢弃的样本的语义准确率为0.3351，视觉准确率为0.3568\n"
     ]
    }
   ],
   "source": [
    "acc1, drop1, drop_semantic_acc1, drop_visual_acc1 = two_space_predict(x_fea, four_vc, x_att, four_defect_att, y_real)\n",
    "acc2, drop2, drop_semantic_acc2, drop_visual_acc2 = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'在狭义空间中，丢弃率为{drop1:.4f}的情况下，准确率为{acc1:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc1:.4f}，视觉准确率为{drop_visual_acc1:.4f}')\n",
    "print(f'在广义空间中，丢弃率为{drop2:.4f}的情况下，准确率为{acc2:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc2:.4f}，视觉准确率为{drop_visual_acc2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del four_dataset, four_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混合故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mul_wm = test_two_wm + test_three_wm + test_four_wm\n",
    "test_mul_label = test_two_label + test_three_label + test_four_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_wm_tensor = torch.tensor(np.array(test_mul_wm), dtype=torch.float32)\n",
    "mul_dataset = MyDataSet(mul_wm_tensor,test_mul_label)\n",
    "mul_loader = DataLoader(mul_dataset, batch_size=32, shuffle=False)\n",
    "del mul_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, mul_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, mul_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在狭义空间中，丢弃率为0.1364的情况下，准确率为0.7357，丢弃的样本的语义准确率为0.5234，视觉准确率为0.2326\n",
      "在广义空间中，丢弃率为0.1484的情况下，准确率为0.7113，丢弃的样本的语义准确率为0.5738，视觉准确率为0.2033\n"
     ]
    }
   ],
   "source": [
    "acc1, drop1, drop_semantic_acc1, drop_visual_acc1 = two_space_predict(x_fea, mul_vc, x_att, mul_defect_att, y_real)\n",
    "acc2, drop2, drop_semantic_acc2, drop_visual_acc2 = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'在狭义空间中，丢弃率为{drop1:.4f}的情况下，准确率为{acc1:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc1:.4f}，视觉准确率为{drop_visual_acc1:.4f}')\n",
    "print(f'在广义空间中，丢弃率为{drop2:.4f}的情况下，准确率为{acc2:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc2:.4f}，视觉准确率为{drop_visual_acc2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mul_dataset, mul_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所有故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = MyDataSet(test_wm_tensor,test_label)\n",
    "total_loader = DataLoader(total_dataset, batch_size=32, shuffle=False)\n",
    "del test_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, _ = get_outputs(model, total_loader, device)\n",
    "x_fea, y_real = get_outputs(model_fea, total_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丢弃率为0.1215的情况下，准确率为0.7799，丢弃的样本的语义准确率为0.5600，视觉准确率为0.2111\n"
     ]
    }
   ],
   "source": [
    "acc, drop, drop_semantic_acc, drop_visual_acc = two_space_predict(x_fea, total_vc, x_att, total_defect_att, y_real)\n",
    "\n",
    "print(f'丢弃率为{drop:.4f}的情况下，准确率为{acc:.4f}，丢弃的样本的语义准确率为{drop_semantic_acc:.4f}，视觉准确率为{drop_visual_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del total_dataset, total_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
