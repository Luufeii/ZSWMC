{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这里得到视觉中心并保存，我们这里的视觉中心用伪标签的样本得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们在给样本打上伪标签之后，就可以在视觉空间中找出视觉特征每个类别的中心，然后在视觉空间中进行KNN搜索类别。\n",
    "# 使用训练集的样本以及伪标签，经过模型得到视觉特征后，可以得到视觉特征中心。\n",
    "# 然后使用测试集的样本，经过模型得到视觉特征，然后和视觉特征中心进行KNN搜索，得到预测的类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据以及模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型以及语义属性\n",
    "import pickle\n",
    "model = torch.load('../model_saved_pseudo/train_all.pth')\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "model_fea = torch.nn.Sequential(*list(model.children())[:-2])  # 由于加了sigmoid层，所以这里是[:-2]\n",
    "model_fea = model_fea.to(device)\n",
    "model_fea.eval()\n",
    "\n",
    "'''\n",
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att\n",
    "total_defect_att = attri.total_defect_att\n",
    "'''\n",
    "\n",
    "with open('../updated_semantic_all/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('../updated_semantic_all/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n",
    "with open('../updated_semantic_all/updated_total_dict.pkl', 'rb') as file:\n",
    "    total_defect_att = pickle.load(file)\n",
    "\n",
    "from collections import Counter\n",
    "# 加载二、三、四缺陷的字典\n",
    "two_defect_att = {}\n",
    "three_defect_att = {}\n",
    "four_defect_att = {}\n",
    "for label in mul_defect_att.keys():\n",
    "    count = Counter(label)\n",
    "    if count['+'] == 1:\n",
    "        two_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 2:\n",
    "        three_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 3:\n",
    "        four_defect_att[label] = mul_defect_att[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_dimen: 20\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = '../data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = '../data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "pseudo_four_data_path = '../data_fake_label/four_fake_label_WM.npz' \n",
    "pseudo_four_data = np.load(pseudo_four_data_path)\n",
    "\n",
    "att_dimen = len(single_defect_att['Center'])\n",
    "print('att_dimen:', att_dimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "pseudo_four_label = pseudo_four_data['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224])\n",
      "torch.Size([2593, 1, 224, 224])\n",
      "torch.Size([4130, 1, 224, 224])\n",
      "torch.Size([1629, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = trans(torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52)))\n",
    "print(train_wm_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52)))\n",
    "print(pseudo_two_wm_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52)))\n",
    "print(pseudo_three_wm_tensor.shape)\n",
    "\n",
    "pseudo_four_wm = pseudo_four_data['denoise_wm']\n",
    "pseudo_four_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_four_wm, dtype=torch.float32),(len(pseudo_four_wm),1,52,52)))\n",
    "print(pseudo_four_wm_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_visual_centers(X, labels, category):\n",
    "    \"\"\"\n",
    "    计算每个类别的视觉中心（均值特征向量）。\n",
    "    :param X: 特征向量，形状 (num_samples, feature_dim)\n",
    "    :param labels: 每个样本的标签，形状 (num_samples,)\n",
    "    :param category: 缺陷的类别种类\n",
    "    :return: 每个类别的视觉中心（均值向量），是一个字典\n",
    "    \"\"\"\n",
    "    visual_centers = {}\n",
    "    for c in category:\n",
    "        visual_centers[c] = np.mean(X[labels == c], axis=0)\n",
    "    return visual_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取视觉中心并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单故障"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(single_defect_att.keys())\n",
    "single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "single_dataset = MyDataSet(single_wm_tensor,train_single_label)\n",
    "single_loader = DataLoader(single_dataset, batch_size=32, shuffle=False)\n",
    "del single_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5610, 512) (5610,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = np.array(train_single_label)\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in single_loader:  \n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model_fea(imgs)\n",
    "\n",
    "        for out in outputs:\n",
    "            x.append(out.flatten().cpu())  # 输出展开,out的维度大小变为512，没有flatten的话维度大小就是(512,1,1)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del single_dataset, single_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Center', 'Donut', 'Edge_loc', 'Loc', 'Edge_ring', 'Scratch', 'Random', 'Nearfull', 'Normal'])\n"
     ]
    }
   ],
   "source": [
    "single_vc = compute_visual_centers(x, y ,category)\n",
    "print(single_vc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('single_vc.pkl', 'wb') as file:\n",
    "    pickle.dump(single_vc, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二故障"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取视觉中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(two_defect_att.keys())\n",
    "two_dataset = MyDataSet(pseudo_two_wm_tensor,pseudo_two_label)\n",
    "two_loader = DataLoader(two_dataset, batch_size=32, shuffle=False)\n",
    "del pseudo_two_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2593, 512) (2593,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = np.array(pseudo_two_label)\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in two_loader:  \n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model_fea(imgs)\n",
    "\n",
    "        for out in outputs:\n",
    "            x.append(out.flatten().cpu())  # 输出展开,out的维度大小变为512，没有flatten的话维度大小就是(512,1,1)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del two_dataset, two_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C+EL', 'C+ER', 'C+L', 'C+S', 'D+EL', 'D+ER', 'D+L', 'D+S', 'EL+L', 'EL+S', 'ER+L', 'ER+S', 'L+S'])\n"
     ]
    }
   ],
   "source": [
    "two_vc = compute_visual_centers(x, y ,category)\n",
    "print(two_vc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('two_vc.pkl', 'wb') as file:\n",
    "    pickle.dump(two_vc, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三故障"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取视觉中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(three_defect_att.keys())\n",
    "three_dataset = MyDataSet(pseudo_three_wm_tensor,pseudo_three_label)\n",
    "three_loader = DataLoader(three_dataset, batch_size=32, shuffle=False)\n",
    "del pseudo_three_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4130, 512) (4130,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = np.array(pseudo_three_label)\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in three_loader:  \n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model_fea(imgs)\n",
    "\n",
    "        for out in outputs:\n",
    "            x.append(out.flatten().cpu())  # 输出展开,out的维度大小变为512，没有flatten的话维度大小就是(512,1,1)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del three_dataset, three_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C+EL+L', 'C+EL+S', 'C+ER+L', 'C+ER+S', 'C+L+S', 'D+EL+L', 'D+EL+S', 'D+ER+L', 'D+ER+S', 'D+L+S', 'EL+L+S', 'ER+L+S'])\n"
     ]
    }
   ],
   "source": [
    "three_vc = compute_visual_centers(x, y ,category)\n",
    "print(three_vc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('three_vc.pkl', 'wb') as file:\n",
    "    pickle.dump(three_vc, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四故障"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取视觉中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(four_defect_att.keys())\n",
    "four_dataset = MyDataSet(pseudo_four_wm_tensor,pseudo_four_label)\n",
    "four_loader = DataLoader(four_dataset, batch_size=32, shuffle=False)\n",
    "del pseudo_four_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1629, 512) (1629,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = np.array(pseudo_four_label)\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in four_loader:  \n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model_fea(imgs)\n",
    "\n",
    "        for out in outputs:\n",
    "            x.append(out.flatten().cpu())  # 输出展开,out的维度大小变为512，没有flatten的话维度大小就是(512,1,1)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del four_dataset, four_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C+EL+L+S', 'C+ER+L+S', 'D+EL+L+S', 'D+ER+L+S'])\n"
     ]
    }
   ],
   "source": [
    "four_vc = compute_visual_centers(x, y ,category)\n",
    "print(four_vc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('four_vc.pkl', 'wb') as file:\n",
    "    pickle.dump(four_vc, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所有故障"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取视觉中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Center', 'Donut', 'Edge_loc', 'Loc', 'Edge_ring', 'Scratch', 'Random', 'Nearfull', 'Normal', 'C+EL', 'C+ER', 'C+L', 'C+S', 'D+EL', 'D+ER', 'D+L', 'D+S', 'EL+L', 'EL+S', 'ER+L', 'ER+S', 'L+S', 'C+EL+L', 'C+EL+S', 'C+ER+L', 'C+ER+S', 'C+L+S', 'D+EL+L', 'D+EL+S', 'D+ER+L', 'D+ER+S', 'D+L+S', 'EL+L+S', 'ER+L+S', 'C+EL+L+S', 'C+ER+L+S', 'D+EL+L+S', 'D+ER+L+S'])\n"
     ]
    }
   ],
   "source": [
    "total_vc = {**single_vc, **two_vc, **three_vc, **four_vc}\n",
    "print(total_vc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('total_vc.pkl', 'wb') as file:\n",
    "    pickle.dump(total_vc, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
