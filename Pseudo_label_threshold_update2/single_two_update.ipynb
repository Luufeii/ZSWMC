{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性\n",
    "# 由于我们需要先对混合样本进行分类，所以我们每次更新所有类别的语义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "train_label = train_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm\n",
    "train_label = train_single_label\n",
    "train_att = train_single_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "train_mul_wm = train_two_wm + train_three_wm + train_four_wm\n",
    "train_mul_wm_tensor = torch.tensor(np.array(train_mul_wm), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_two_wm + val_three_wm + val_four_wm\n",
    "val_label = val_two_label + val_three_label + val_four_label\n",
    "val_att = val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_two_label + test_three_label + test_four_label\n",
    "test_att = test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：2.021005153656006, 总Loss:0.7113084136508405\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:3.618560040835291\n",
      "第1轮训练后,整体验证集上的Accuracy:0.3275862068965517\n",
      "————第2轮训练开始————\n",
      "训练时间为：1.9320933818817139, 总Loss:0.4151627942919731\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:3.3190680677071214\n",
      "第2轮训练后,整体验证集上的Accuracy:0.3486206896551724\n",
      "————第3轮训练开始————\n",
      "训练时间为：1.9377992153167725, 总Loss:0.3717303527519107\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:3.2458943049423397\n",
      "第3轮训练后,整体验证集上的Accuracy:0.3589655172413793\n",
      "————第4轮训练开始————\n",
      "训练时间为：1.9250941276550293, 总Loss:0.3900904181646183\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:3.296967012109235\n",
      "第4轮训练后,整体验证集上的Accuracy:0.3606896551724138\n",
      "————第5轮训练开始————\n",
      "训练时间为：1.9253337383270264, 总Loss:0.3597312446217984\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:3.213748174952343\n",
      "第5轮训练后,整体验证集上的Accuracy:0.36586206896551726\n",
      "————第6轮训练开始————\n",
      "训练时间为：1.943617582321167, 总Loss:0.414568099193275\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:3.281551609747112\n",
      "第6轮训练后,整体验证集上的Accuracy:0.3682758620689655\n",
      "————第7轮训练开始————\n",
      "训练时间为：1.9496173858642578, 总Loss:0.46876114734914154\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:3.288325467845425\n",
      "第7轮训练后,整体验证集上的Accuracy:0.3686206896551724\n",
      "————第8轮训练开始————\n",
      "训练时间为：1.9284474849700928, 总Loss:0.39038487209472805\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:3.397813511546701\n",
      "第8轮训练后,整体验证集上的Accuracy:0.36689655172413793\n",
      "————第9轮训练开始————\n",
      "训练时间为：1.921783447265625, 总Loss:0.3936596146086231\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:3.3177362168207765\n",
      "第9轮训练后,整体验证集上的Accuracy:0.36758620689655175\n",
      "————第10轮训练开始————\n",
      "训练时间为：1.942988634109497, 总Loss:0.43464905489236116\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:3.355796946096234\n",
      "第10轮训练后,整体验证集上的Accuracy:0.3713793103448276\n",
      "————第11轮训练开始————\n",
      "训练时间为：1.965207576751709, 总Loss:0.44060706067830324\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:3.52098607912194\n",
      "第11轮训练后,整体验证集上的Accuracy:0.3717241379310345\n",
      "————第12轮训练开始————\n",
      "训练时间为：1.9171717166900635, 总Loss:0.48851681128144264\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:3.479409856488928\n",
      "第12轮训练后,整体验证集上的Accuracy:0.3689655172413793\n",
      "————第13轮训练开始————\n",
      "训练时间为：1.9355897903442383, 总Loss:0.5135462378384545\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:3.5311421438818797\n",
      "第13轮训练后,整体验证集上的Accuracy:0.3662068965517241\n",
      "————第14轮训练开始————\n",
      "训练时间为：1.923905372619629, 总Loss:0.475027778185904\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:3.6185232953866944\n",
      "第14轮训练后,整体验证集上的Accuracy:0.37\n",
      "————第15轮训练开始————\n",
      "训练时间为：2.0450713634490967, 总Loss:0.4979314563097432\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:3.615973184001632\n",
      "第15轮训练后,整体验证集上的Accuracy:0.3617241379310345\n",
      "————第16轮训练开始————\n",
      "训练时间为：2.033442735671997, 总Loss:0.5135820260038599\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:3.6060006148181856\n",
      "第16轮训练后,整体验证集上的Accuracy:0.3724137931034483\n",
      "————第17轮训练开始————\n",
      "训练时间为：1.9107253551483154, 总Loss:0.5370185943320394\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:3.687314117094502\n",
      "第17轮训练后,整体验证集上的Accuracy:0.37344827586206897\n",
      "————第18轮训练开始————\n",
      "训练时间为：1.9308395385742188, 总Loss:0.5277601215057075\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:3.8149410561891273\n",
      "第18轮训练后,整体验证集上的Accuracy:0.3706896551724138\n",
      "————第19轮训练开始————\n",
      "训练时间为：1.9109511375427246, 总Loss:0.5423768910113722\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:3.8197307194350287\n",
      "第19轮训练后,整体验证集上的Accuracy:0.3713793103448276\n",
      "————第20轮训练开始————\n",
      "训练时间为：1.9020113945007324, 总Loss:0.5634208230767399\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:3.8682174953864887\n",
      "第20轮训练后,整体验证集上的Accuracy:0.37310344827586206\n",
      "训练结束，第17轮的模型在验证集上准确率最高，为0.37344827586206897\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = single_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    # 由于更新语义需要的样本较多，所以我们使用训练集的故障样本\n",
    "    mul_defect_att = update_semantic(model, mul_defect_att, train_mul_wm_tensor, 50)\n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = mul_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model,val_loader,two_defect_att,val_size,'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2/updated_mul_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(mul_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_single.pth')\n",
    "model.eval()\n",
    "with open('updated_semantic_1_2/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n",
    "\n",
    "from collections import Counter\n",
    "# 加载二、三、四缺陷的字典\n",
    "two_defect_att = {}\n",
    "three_defect_att = {}\n",
    "four_defect_att = {}\n",
    "for label in mul_defect_att.keys():\n",
    "    count = Counter(label)\n",
    "    if count['+'] == 1:\n",
    "        two_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 2:\n",
    "        three_defect_att[label] = mul_defect_att[label]\n",
    "    if count['+'] == 3:\n",
    "        four_defect_att[label] = mul_defect_att[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = mul_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.4640,  0.0168, -0.0347,  0.4746,  0.4806,  0.9807,  0.3993,  0.4778,\n",
      "         0.0772, -0.0664, -0.0053,  0.0889,  0.5605, -0.0197,  0.0913,  0.3541,\n",
      "         0.3915,  0.5246,  0.5024, -0.0798], device='cuda:0')\n",
      "真实的属性向量tensor([ 0.6204, -0.0336, -0.0535,  0.6047,  0.4969,  1.0738,  0.4459,  0.3993,\n",
      "         0.0232, -0.0679, -0.0126,  0.0798,  0.6978,  0.0216,  0.0739,  0.5887,\n",
      "         0.4335,  0.4401,  0.4677, -0.0434])\n",
      "真实标签为：C+ER+S\n",
      "欧式距离计算的标签为：C+ER+S\n",
      "余弦相似度计算的标签为：C+ER\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_wm_tensor, test_att_tensor, mul_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5008620689655172\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_loader, mul_defect_att, len(test_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1262/311944114.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  train_mul_att_tensor = torch.tensor(train_mul_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_mul_label = train_two_label + train_three_label + train_four_label\n",
    "\n",
    "train_mul_att = train_two_att + train_three_att + train_four_att\n",
    "train_mul_att_tensor = torch.tensor(train_mul_att, dtype=torch.float32)\n",
    "for i in range(len(train_mul_label)):\n",
    "    train_mul_att_tensor[i] = mul_defect_att[train_mul_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mul_dataset = MyDataSet(train_mul_wm_tensor, train_mul_att_tensor)\n",
    "\n",
    "train_mul_loader = DataLoader(train_mul_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5023152709359606\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_mul_loader, mul_defect_att, len(train_mul_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
