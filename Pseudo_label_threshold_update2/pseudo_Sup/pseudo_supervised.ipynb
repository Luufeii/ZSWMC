{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用打了伪标签的数据进行有监督分类，以进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果这个准确率较低，说明了学习属性方法的优越性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里加载属性是为了方便获取类别的种类\n",
    "attri = Att()\n",
    "attri.compute_mul_defect_att()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = '../data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = '../data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "pseudo_four_data_path = '../data_fake_label/four_fake_label_WM.npz' \n",
    "pseudo_four_data = np.load(pseudo_four_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "pseudo_four_label = pseudo_four_data['label_name']\n",
    "val_label = val_data['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) (25910,)\n",
      "torch.Size([2593, 1, 224, 224]) (2593,)\n",
      "torch.Size([4130, 1, 224, 224]) (4130,)\n",
      "torch.Size([1629, 1, 224, 224]) (1629,)\n",
      "torch.Size([3700, 1, 224, 224]) (3700,)\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = trans(torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52)))\n",
    "print(train_wm_tensor.shape, train_label.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52)))\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_label.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52)))\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_label.shape)\n",
    "\n",
    "pseudo_four_wm = pseudo_four_data['denoise_wm']\n",
    "pseudo_four_wm_tensor = trans(torch.reshape(torch.tensor(pseudo_four_wm, dtype=torch.float32),(len(pseudo_four_wm),1,52,52)))\n",
    "print(pseudo_four_wm_tensor.shape,  pseudo_four_label.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = trans(torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52)))\n",
    "print(val_wm_tensor.shape, val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593\n",
      "torch.Size([1, 224, 224])\n",
      "4130\n",
      "torch.Size([1, 224, 224])\n",
      "1629\n",
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "print(len(pseudo_two_wm))\n",
    "print(pseudo_two_wm[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_label = list(pseudo_three_label)\n",
    "print(len(pseudo_three_wm))\n",
    "print(pseudo_three_wm[10].shape)\n",
    "\n",
    "pseudo_four_wm = list(pseudo_four_wm_tensor)\n",
    "pseudo_four_label = list(pseudo_four_label)\n",
    "print(len(pseudo_four_wm))\n",
    "print(pseudo_four_wm[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_three_wm_tensor, pseudo_four_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13962, 1, 224, 224]) (13962,)\n",
      "torch.Size([3700, 1, 224, 224]) (3700,)\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm + pseudo_four_wm\n",
    "train_label = train_single_label + pseudo_two_label + pseudo_three_label + pseudo_four_label\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "print(train_wm_tensor.shape, train_label.shape)\n",
    "print(val_wm_tensor.shape, val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将标签的多热编码改为独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Center', 'Donut', 'Edge_loc', 'Loc', 'Edge_ring', 'Scratch', 'Random', 'Nearfull', 'Normal', 'C+EL', 'C+ER', 'C+L', 'C+S', 'D+EL', 'D+ER', 'D+L', 'D+S', 'EL+L', 'EL+S', 'ER+L', 'ER+S', 'L+S', 'C+EL+L', 'C+EL+S', 'C+ER+L', 'C+ER+S', 'C+L+S', 'D+EL+L', 'D+EL+S', 'D+ER+L', 'D+ER+S', 'D+L+S', 'EL+L+S', 'ER+L+S', 'C+EL+L+S', 'C+ER+L+S', 'D+EL+L+S', 'D+ER+L+S']\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "label_order = list(attri.total_defect_att.keys())\n",
    "print(label_order)\n",
    "print(len(label_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Center': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Donut': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Edge_loc': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Loc': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Edge_ring': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Scratch': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Random': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Nearfull': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Normal': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+EL': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+ER': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+EL': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+ER': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EL+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EL+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ER+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ER+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+EL+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+EL+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+ER+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+ER+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'C+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+EL+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+EL+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D+ER+L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'D+ER+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'D+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'EL+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'ER+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'C+EL+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'C+ER+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'D+EL+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'D+ER+L+S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "label_map_dict = {}  # 字符标签映射为one-hot的字典\n",
    "for i in range(len(label_order)):\n",
    "    oh = [0 for _ in range(len(label_order))]\n",
    "    oh[i] = 1\n",
    "    label_map_dict[label_order[i]] = oh\n",
    "print(label_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = []\n",
    "for l in train_label:\n",
    "    train_label_oh.append(label_map_dict[l])\n",
    "\n",
    "val_label_oh = []\n",
    "for l in val_label:\n",
    "    val_label_oh.append(label_map_dict[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13962, 1, 224, 224]) torch.Size([13962, 38])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 38])\n"
     ]
    }
   ],
   "source": [
    "train_label_tensor = torch.tensor(train_label_oh, dtype=torch.float32)\n",
    "val_label_tensor = torch.tensor(val_label_oh, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_label_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_label_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataSet(train_wm_tensor, train_label_tensor)\n",
    "val_dataset = MyDataSet(val_wm_tensor, val_label_tensor)\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义resnet18和训练需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=38, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 替换第一个卷积以适应我们的单通道图像\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(label_order))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测outputs中预测正确的个数\n",
    "def predict_num(outputs,labels_oh):\n",
    "    right = 0\n",
    "    for i in range(len(outputs)):\n",
    "        if np.argmax(outputs[i]) == np.argmax(labels_oh[i]):\n",
    "            right += 1\n",
    "    \n",
    "    return right\n",
    "\n",
    "def get_acc(model, dataloader,data_size):\n",
    "    model.eval()\n",
    "    total_right_num = 0  # 记录正确的总个数\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for batch_idx, (inputs, labels_oh) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels_oh = labels_oh.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            labels_oh = labels_oh.cpu().numpy()\n",
    "            \n",
    "            right_num = predict_num(outputs,labels_oh)\n",
    "            total_right_num += right_num\n",
    "    acc = total_right_num / data_size\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示混淆矩阵的函数\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def show_cmat(true_label, predict_label, label_order,typ = 'per', size = 10):\n",
    "    # 生成混淆矩阵\n",
    "    cm = confusion_matrix(true_label, predict_label, labels=label_order)  # 按照label_order中的顺序给数据排序\n",
    "    # 将混淆矩阵中的数字转换为百分比\n",
    "    # 通过将cm中的每个元素除以其所在行的总和（即该类的真实样本数），再乘以100，将其转换为百分比。\n",
    "    cm_percentage = cm / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "    plt.figure(figsize=(size,size))  # 这个要定义在sns.heatmap()前面才可以定义大小\n",
    "    # 使用seaborn来可视化混淆矩阵\n",
    "    if typ == 'per':\n",
    "        # fmt=\".1f\"参数设置注释的格式为保留一位小数的浮点数, cmap=\"Blues\"指定了颜色映射\n",
    "        sns.heatmap(pd.DataFrame(cm_percentage, index=label_order, columns=label_order), annot=True, fmt=\".1f\", cmap=\"Blues\")\n",
    "        plt.title('Confusion Matrix in Percentage')\n",
    "    else:\n",
    "        # fmt=\"d\"表示格式化为整数，\n",
    "        sns.heatmap(pd.DataFrame(cm, index=label_order, columns=label_order), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Confusion Matrix in Number')\n",
    "    \n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "# 获取真实标签\n",
    "def predict_labels(outputs, labels_oh, label_order):\n",
    "    pred_labels = []\n",
    "    rel_labels = []\n",
    "    for i in range(len(outputs)):\n",
    "        pred_labels.append(label_order[np.argmax(outputs[i])])\n",
    "        rel_labels.append(label_order[np.argmax(labels_oh[i])])\n",
    "    return rel_labels, pred_labels\n",
    "\n",
    "def get_labels(model, dataloader, label_order):\n",
    "    label_true = []\n",
    "    label_pre = []\n",
    "    with torch.no_grad(): \n",
    "        for imgs,labels in dataloader:  \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            y_true,y_pre = predict_labels(outputs, labels, label_order)\n",
    "            \n",
    "            label_true = label_true + y_true\n",
    "            label_pre = label_pre + y_pre\n",
    "\n",
    "    return label_true,label_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.CrossEntropyLoss().to(device=device) \n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：14.683267831802368, 总Loss:335.48893225193024\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:275.08902257680893\n",
      "第1轮训练后,整体验证集上的Accuracy:0.30405405405405406\n",
      "————第2轮训练开始————\n",
      "训练时间为：12.44685435295105, 总Loss:145.0502940416336\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:213.18583150207996\n",
      "第2轮训练后,整体验证集上的Accuracy:0.44351351351351354\n",
      "————第3轮训练开始————\n",
      "训练时间为：12.357510805130005, 总Loss:102.247353464365\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:170.03096205554903\n",
      "第3轮训练后,整体验证集上的Accuracy:0.5827027027027027\n",
      "————第4轮训练开始————\n",
      "训练时间为：12.403621435165405, 总Loss:83.73572927713394\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:176.9027147218585\n",
      "第4轮训练后,整体验证集上的Accuracy:0.5127027027027027\n",
      "————第5轮训练开始————\n",
      "训练时间为：12.435837268829346, 总Loss:72.44981379806995\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:165.31857767235488\n",
      "第5轮训练后,整体验证集上的Accuracy:0.5681081081081081\n",
      "————第6轮训练开始————\n",
      "训练时间为：12.461488962173462, 总Loss:65.4671423882246\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:181.66920434311032\n",
      "第6轮训练后,整体验证集上的Accuracy:0.5616216216216217\n",
      "————第7轮训练开始————\n",
      "训练时间为：12.446796894073486, 总Loss:58.66358536481857\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:164.93429937120527\n",
      "第7轮训练后,整体验证集上的Accuracy:0.615945945945946\n",
      "————第8轮训练开始————\n",
      "训练时间为：12.463016986846924, 总Loss:53.04350075125694\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:166.92752029560506\n",
      "第8轮训练后,整体验证集上的Accuracy:0.6183783783783784\n",
      "————第9轮训练开始————\n",
      "训练时间为：12.475224018096924, 总Loss:49.244273498654366\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:167.19214874086902\n",
      "第9轮训练后,整体验证集上的Accuracy:0.5537837837837838\n",
      "————第10轮训练开始————\n",
      "训练时间为：12.5793936252594, 总Loss:44.828673496842384\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:166.00705379154533\n",
      "第10轮训练后,整体验证集上的Accuracy:0.6318918918918919\n",
      "————第11轮训练开始————\n",
      "训练时间为：12.487229585647583, 总Loss:42.185827143490314\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:165.99893905874342\n",
      "第11轮训练后,整体验证集上的Accuracy:0.6289189189189189\n",
      "————第12轮训练开始————\n",
      "训练时间为：12.59181523323059, 总Loss:39.77472638338804\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:282.5044171437621\n",
      "第12轮训练后,整体验证集上的Accuracy:0.24297297297297296\n",
      "————第13轮训练开始————\n",
      "训练时间为：12.509912014007568, 总Loss:37.66636508703232\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:208.11377459391952\n",
      "第13轮训练后,整体验证集上的Accuracy:0.5021621621621621\n",
      "————第14轮训练开始————\n",
      "训练时间为：12.509209156036377, 总Loss:35.560756385326385\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:150.9083968522027\n",
      "第14轮训练后,整体验证集上的Accuracy:0.6432432432432432\n",
      "————第15轮训练开始————\n",
      "训练时间为：12.603390216827393, 总Loss:33.27631149068475\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:176.85220757918432\n",
      "第15轮训练后,整体验证集上的Accuracy:0.6132432432432432\n",
      "————第16轮训练开始————\n",
      "训练时间为：12.70041012763977, 总Loss:31.578335285186768\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:173.1836599484086\n",
      "第16轮训练后,整体验证集上的Accuracy:0.6381081081081081\n",
      "————第17轮训练开始————\n",
      "训练时间为：12.562245845794678, 总Loss:30.300357159227133\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:167.96636953949928\n",
      "第17轮训练后,整体验证集上的Accuracy:0.6470270270270271\n",
      "————第18轮训练开始————\n",
      "训练时间为：12.521103858947754, 总Loss:30.080997094511986\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:162.28951716050506\n",
      "第18轮训练后,整体验证集上的Accuracy:0.6513513513513514\n",
      "————第19轮训练开始————\n",
      "训练时间为：12.59215760231018, 总Loss:28.613024778664112\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:216.93164129555225\n",
      "第19轮训练后,整体验证集上的Accuracy:0.5427027027027027\n",
      "————第20轮训练开始————\n",
      "训练时间为：12.537057876586914, 总Loss:27.876628573983908\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:188.27666585799307\n",
      "第20轮训练后,整体验证集上的Accuracy:0.6051351351351352\n",
      "————第21轮训练开始————\n",
      "训练时间为：12.529727697372437, 总Loss:26.82928068190813\n",
      "****第21轮训练结束****\n",
      "第21轮训练后,整体验证集上的Loss:182.4324353854172\n",
      "第21轮训练后,整体验证集上的Accuracy:0.6151351351351352\n",
      "————第22轮训练开始————\n",
      "训练时间为：12.533292055130005, 总Loss:26.593853428959846\n",
      "****第22轮训练结束****\n",
      "第22轮训练后,整体验证集上的Loss:210.94816460367292\n",
      "第22轮训练后,整体验证集上的Accuracy:0.5862162162162162\n",
      "————第23轮训练开始————\n",
      "训练时间为：12.64196515083313, 总Loss:26.08695900067687\n",
      "****第23轮训练结束****\n",
      "第23轮训练后,整体验证集上的Loss:205.60457131452858\n",
      "第23轮训练后,整体验证集上的Accuracy:0.5956756756756757\n",
      "————第24轮训练开始————\n",
      "训练时间为：12.541358470916748, 总Loss:25.920282319188118\n",
      "****第24轮训练结束****\n",
      "第24轮训练后,整体验证集上的Loss:167.25264786090702\n",
      "第24轮训练后,整体验证集上的Accuracy:0.6556756756756756\n",
      "————第25轮训练开始————\n",
      "训练时间为：12.53518557548523, 总Loss:25.453176144510508\n",
      "****第25轮训练结束****\n",
      "第25轮训练后,整体验证集上的Loss:163.24789323750883\n",
      "第25轮训练后,整体验证集上的Accuracy:0.6410810810810811\n",
      "————第26轮训练开始————\n",
      "训练时间为：12.530795097351074, 总Loss:24.72366045601666\n",
      "****第26轮训练结束****\n",
      "第26轮训练后,整体验证集上的Loss:187.12258304667193\n",
      "第26轮训练后,整体验证集上的Accuracy:0.6310810810810811\n",
      "————第27轮训练开始————\n",
      "训练时间为：12.626583576202393, 总Loss:24.37704609706998\n",
      "****第27轮训练结束****\n",
      "第27轮训练后,整体验证集上的Loss:183.18435951508582\n",
      "第27轮训练后,整体验证集上的Accuracy:0.6289189189189189\n",
      "————第28轮训练开始————\n",
      "训练时间为：12.543587923049927, 总Loss:24.24336576089263\n",
      "****第28轮训练结束****\n",
      "第28轮训练后,整体验证集上的Loss:238.91237953095697\n",
      "第28轮训练后,整体验证集上的Accuracy:0.5583783783783783\n",
      "————第29轮训练开始————\n",
      "训练时间为：12.535583734512329, 总Loss:23.78325879201293\n",
      "****第29轮训练结束****\n",
      "第29轮训练后,整体验证集上的Loss:186.08526148693636\n",
      "第29轮训练后,整体验证集上的Accuracy:0.65\n",
      "————第30轮训练开始————\n",
      "训练时间为：12.537059783935547, 总Loss:23.0113480463624\n",
      "****第30轮训练结束****\n",
      "第30轮训练后,整体验证集上的Loss:240.58540078799706\n",
      "第30轮训练后,整体验证集上的Accuracy:0.5640540540540541\n",
      "训练结束，第24轮的模型在验证集上准确率最高，为0.6556756756756756\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for i in range(epochs):\n",
    "    # total_train_steps = 0\n",
    "    print(f'————第{i+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:   # 这里的label是一个38维的向量\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{i+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "\n",
    "    model.eval()   # 开始验证\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader: \n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "        # 计算准确率\n",
    "        acc = get_acc(model,val_loader,val_size)\n",
    "        print(f'第{i+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "        print(f'第{i+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "        if acc > best_acc:  \n",
    "            best_acc = acc\n",
    "            No = i+1\n",
    "            torch.save(obj=model,f='pseudo_supervised.pth')\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
