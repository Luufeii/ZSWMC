{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 52, 52]) torch.Size([2593, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([2593, 1, 224, 224]) torch.Size([2593, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593 2593\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm\n",
    "train_label = train_single_label + pseudo_two_label\n",
    "train_att = train_single_att + pseudo_two_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "# train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "# train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "# train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "train_mul_wm = train_two_wm + train_three_wm + train_four_wm\n",
    "train_mul_wm_tensor = torch.tensor(np.array(train_mul_wm), dtype=torch.float32)\n",
    "\n",
    "val_wm = val_two_wm + val_three_wm + val_four_wm\n",
    "val_label = val_two_label + val_three_label + val_four_label\n",
    "val_att = val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_two_label + test_three_label + test_four_label\n",
    "test_att = test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single_two.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：2.7169241905212402, 总Loss:1.0897157127037644\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:3.6606870964169502\n",
      "第1轮训练后,整体验证集上的Accuracy:0.5775862068965517\n",
      "————第2轮训练开始————\n",
      "训练时间为：2.613274574279785, 总Loss:0.8616234227083623\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:3.7977760452777147\n",
      "第2轮训练后,整体验证集上的Accuracy:0.5875862068965517\n",
      "————第3轮训练开始————\n",
      "训练时间为：2.6120412349700928, 总Loss:0.8386847907677293\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:3.7863394753076136\n",
      "第3轮训练后,整体验证集上的Accuracy:0.586551724137931\n",
      "————第4轮训练开始————\n",
      "训练时间为：2.6420106887817383, 总Loss:0.8499908000230789\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:3.9852512013167143\n",
      "第4轮训练后,整体验证集上的Accuracy:0.5810344827586207\n",
      "————第5轮训练开始————\n",
      "训练时间为：2.582965612411499, 总Loss:0.8959821483585984\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:4.101160414516926\n",
      "第5轮训练后,整体验证集上的Accuracy:0.5696551724137932\n",
      "————第6轮训练开始————\n",
      "训练时间为：2.6641228199005127, 总Loss:0.8651228214148432\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:4.019561926368624\n",
      "第6轮训练后,整体验证集上的Accuracy:0.583103448275862\n",
      "————第7轮训练开始————\n",
      "训练时间为：2.5969815254211426, 总Loss:0.8531831598374993\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:4.031402607448399\n",
      "第7轮训练后,整体验证集上的Accuracy:0.5806896551724138\n",
      "————第8轮训练开始————\n",
      "训练时间为：2.611635208129883, 总Loss:0.8867065326776356\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:4.288989069405943\n",
      "第8轮训练后,整体验证集上的Accuracy:0.5682758620689655\n",
      "————第9轮训练开始————\n",
      "训练时间为：2.6511306762695312, 总Loss:0.8912239505443722\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:4.253981682471931\n",
      "第9轮训练后,整体验证集上的Accuracy:0.5786206896551724\n",
      "————第10轮训练开始————\n",
      "训练时间为：2.5941431522369385, 总Loss:0.8818214405328035\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:4.468633831944317\n",
      "第10轮训练后,整体验证集上的Accuracy:0.5724137931034483\n",
      "————第11轮训练开始————\n",
      "训练时间为：2.583399534225464, 总Loss:0.9194957681465894\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:4.287404179573059\n",
      "第11轮训练后,整体验证集上的Accuracy:0.5855172413793104\n",
      "————第12轮训练开始————\n",
      "训练时间为：2.5876739025115967, 总Loss:0.9214857313781977\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:4.406495225150138\n",
      "第12轮训练后,整体验证集上的Accuracy:0.5813793103448276\n",
      "————第13轮训练开始————\n",
      "训练时间为：2.5857675075531006, 总Loss:0.9565447091590613\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:4.611473275814205\n",
      "第13轮训练后,整体验证集上的Accuracy:0.5741379310344827\n",
      "————第14轮训练开始————\n",
      "训练时间为：2.5883729457855225, 总Loss:0.9492458645254374\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:4.7333544278517365\n",
      "第14轮训练后,整体验证集上的Accuracy:0.5703448275862069\n",
      "————第15轮训练开始————\n",
      "训练时间为：2.592345714569092, 总Loss:0.9787459061481059\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:4.777079303748906\n",
      "第15轮训练后,整体验证集上的Accuracy:0.57\n",
      "————第16轮训练开始————\n",
      "训练时间为：2.5893845558166504, 总Loss:1.0348795161116868\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:4.9343067817389965\n",
      "第16轮训练后,整体验证集上的Accuracy:0.5651724137931035\n",
      "————第17轮训练开始————\n",
      "训练时间为：2.5900721549987793, 总Loss:0.978583867661655\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:4.842098295688629\n",
      "第17轮训练后,整体验证集上的Accuracy:0.5696551724137932\n",
      "————第18轮训练开始————\n",
      "训练时间为：2.6023128032684326, 总Loss:1.0715997838415205\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:5.01755719166249\n",
      "第18轮训练后,整体验证集上的Accuracy:0.5644827586206896\n",
      "————第19轮训练开始————\n",
      "训练时间为：2.5821542739868164, 总Loss:1.0575055067893118\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:5.180157987400889\n",
      "第19轮训练后,整体验证集上的Accuracy:0.5613793103448276\n",
      "————第20轮训练开始————\n",
      "训练时间为：2.6333706378936768, 总Loss:1.0643483868334442\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:5.117748002987355\n",
      "第20轮训练后,整体验证集上的Accuracy:0.5706896551724138\n",
      "训练结束，第2轮的模型在验证集上准确率最高，为0.5875862068965517\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    mul_defect_att = update_semantic(model, mul_defect_att, train_mul_wm_tensor, 50)\n",
    "    total_defect_att = {**single_defect_att, **mul_defect_att}\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = total_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor, train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    " \n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = mul_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model, val_loader, mul_defect_att, val_size, 'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_three_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2_3/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2_3/updated_mul_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(mul_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset,train_loader,val_dataset,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_single_two.pth')\n",
    "# model = torch.load('model_saved_pseudo/single_two_three_updated.pth')\n",
    "model.eval()\n",
    "with open('updated_semantic_1_2_3/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3/updated_mul_dict.pkl', 'rb') as file:\n",
    "    mul_defect_att = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = mul_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.8788,  0.0100,  0.1211,  0.8718,  0.7890,  0.8271,  0.8166,  0.1423,\n",
      "         0.1905, -0.0187,  0.0323, -0.0109,  0.8624,  0.7855,  0.0686,  1.2755,\n",
      "         0.7821,  0.1230,  0.0991,  0.7587], device='cuda:0')\n",
      "真实的属性向量tensor([ 0.9214,  0.0143,  0.0628,  0.8648,  0.8925,  0.7624,  0.9089,  0.1380,\n",
      "         0.1050, -0.0349,  0.0094, -0.0092,  0.9270,  0.8274,  0.0490,  1.3239,\n",
      "         0.8846,  0.1110,  0.1138,  0.8278])\n",
      "真实标签为：C+EL\n",
      "欧式距离计算的标签为：C+EL\n",
      "余弦相似度计算的标签为：C+EL\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_wm_tensor, test_att_tensor, mul_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5841379310344827\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_loader, mul_defect_att, len(test_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mul_label = train_two_label + train_three_label + train_four_label\n",
    "\n",
    "train_mul_att = train_two_att + train_three_att + train_four_att\n",
    "train_mul_att_tensor = torch.tensor(train_mul_att, dtype=torch.float32)\n",
    "for i in range(len(train_mul_label)):\n",
    "    train_mul_att_tensor[i] = mul_defect_att[train_mul_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mul_dataset = MyDataSet(train_mul_wm_tensor, train_mul_att_tensor)\n",
    "\n",
    "train_mul_loader = DataLoader(train_mul_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5820689655172414\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_mul_loader, mul_defect_att, len(train_mul_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
