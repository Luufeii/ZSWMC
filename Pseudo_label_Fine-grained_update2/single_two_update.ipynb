{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "train_label = train_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm\n",
    "train_label = train_single_label\n",
    "train_att = train_single_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_two_wm\n",
    "val_label = val_two_label\n",
    "val_att = val_two_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm\n",
    "test_label = test_single_label + test_two_label\n",
    "test_att = test_single_att + test_two_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：1.910825490951538, 总Loss:0.6021528567653149\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:0.7884001499041915\n",
      "第1轮训练后,整体验证集上的Accuracy:0.8530769230769231\n",
      "————第2轮训练开始————\n",
      "训练时间为：1.8190293312072754, 总Loss:0.5007165258284658\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:0.7241196918766946\n",
      "第2轮训练后,整体验证集上的Accuracy:0.8792307692307693\n",
      "————第3轮训练开始————\n",
      "训练时间为：1.8093228340148926, 总Loss:0.4645272633060813\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:0.6872486541979015\n",
      "第3轮训练后,整体验证集上的Accuracy:0.8884615384615384\n",
      "————第4轮训练开始————\n",
      "训练时间为：1.8003475666046143, 总Loss:0.49268592591397464\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:0.6689735613763332\n",
      "第4轮训练后,整体验证集上的Accuracy:0.8953846153846153\n",
      "————第5轮训练开始————\n",
      "训练时间为：1.8206207752227783, 总Loss:0.5058551183901727\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:0.6589283151552081\n",
      "第5轮训练后,整体验证集上的Accuracy:0.8992307692307693\n",
      "————第6轮训练开始————\n",
      "训练时间为：1.8165512084960938, 总Loss:0.5406144310254604\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:0.650532491505146\n",
      "第6轮训练后,整体验证集上的Accuracy:0.8992307692307693\n",
      "————第7轮训练开始————\n",
      "训练时间为：1.8361411094665527, 总Loss:0.5231986846774817\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:0.6224084000568837\n",
      "第7轮训练后,整体验证集上的Accuracy:0.9092307692307692\n",
      "————第8轮训练开始————\n",
      "训练时间为：1.808943510055542, 总Loss:0.525390881113708\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:0.6134604595135897\n",
      "第8轮训练后,整体验证集上的Accuracy:0.9069230769230769\n",
      "————第9轮训练开始————\n",
      "训练时间为：1.8198869228363037, 总Loss:0.5625519156455994\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:0.6065555980894715\n",
      "第9轮训练后,整体验证集上的Accuracy:0.9130769230769231\n",
      "————第10轮训练开始————\n",
      "训练时间为：1.8694887161254883, 总Loss:0.5627169355284423\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:0.6078898832201958\n",
      "第10轮训练后,整体验证集上的Accuracy:0.9146153846153846\n",
      "————第11轮训练开始————\n",
      "训练时间为：1.8442602157592773, 总Loss:0.6192527445964515\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:0.6275647054426372\n",
      "第11轮训练后,整体验证集上的Accuracy:0.91\n",
      "————第12轮训练开始————\n",
      "训练时间为：1.810100793838501, 总Loss:0.5678597572259605\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:0.6302166250534356\n",
      "第12轮训练后,整体验证集上的Accuracy:0.9069230769230769\n",
      "————第13轮训练开始————\n",
      "训练时间为：1.814868688583374, 总Loss:0.5710134266410023\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:0.6360674116294831\n",
      "第13轮训练后,整体验证集上的Accuracy:0.91\n",
      "————第14轮训练开始————\n",
      "训练时间为：1.8107008934020996, 总Loss:0.599983942694962\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:0.6122607518918812\n",
      "第14轮训练后,整体验证集上的Accuracy:0.9130769230769231\n",
      "————第15轮训练开始————\n",
      "训练时间为：1.9108829498291016, 总Loss:0.602124699158594\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:0.6339981015771627\n",
      "第15轮训练后,整体验证集上的Accuracy:0.9084615384615384\n",
      "————第16轮训练开始————\n",
      "训练时间为：1.8272745609283447, 总Loss:0.6035230006091297\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:0.6334838692564517\n",
      "第16轮训练后,整体验证集上的Accuracy:0.9092307692307692\n",
      "————第17轮训练开始————\n",
      "训练时间为：1.8231565952301025, 总Loss:0.6266210279427469\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:0.6262280035298318\n",
      "第17轮训练后,整体验证集上的Accuracy:0.9115384615384615\n",
      "————第18轮训练开始————\n",
      "训练时间为：1.8142673969268799, 总Loss:0.6453465442173183\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:0.6558739051688462\n",
      "第18轮训练后,整体验证集上的Accuracy:0.9069230769230769\n",
      "————第19轮训练开始————\n",
      "训练时间为：1.8018028736114502, 总Loss:0.6185733766760677\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:0.64313774718903\n",
      "第19轮训练后,整体验证集上的Accuracy:0.9092307692307692\n",
      "————第20轮训练开始————\n",
      "训练时间为：1.8080964088439941, 总Loss:0.6111721638590097\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:0.6612530550919473\n",
      "第20轮训练后,整体验证集上的Accuracy:0.9076923076923077\n",
      "训练结束，第10轮的模型在验证集上准确率最高，为0.9146153846153846\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = single_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    # 由于更新语义需要的样本较多，所以我们使用训练集的二故障样本\n",
    "    two_defect_att = update_semantic(model, two_defect_att, train_two_wm_tensor, 50)  \n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = two_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model,val_loader,two_defect_att,val_size,'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2/updated_two_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(two_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_saved_pseudo/single_two_updated.pth')\n",
    "model = torch.load('model_saved_pseudo/train_single.pth')\n",
    "with open('updated_semantic_1_2/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2/updated_two_dict.pkl', 'rb') as file:\n",
    "    two_defect_att = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5112/1213832699.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n",
    "for i in range(len(test_single_label)):\n",
    "    test_single_att_tensor[i] = single_defect_att[test_single_label[i]]\n",
    "\n",
    "test_two_att_tensor = torch.tensor(test_two_att, dtype=torch.float32)\n",
    "for i in range(len(test_two_label)):\n",
    "    test_two_att_tensor[i] = two_defect_att[test_two_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(test_single_wm, dtype=torch.float32)\n",
    "test_two_wm_tensor = torch.tensor(test_two_wm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.0118,  0.0320,  0.0179, -0.0057,  0.9963,  0.1531,  0.4652,  0.1558,\n",
      "         0.5645, -0.1180, -0.0075,  0.0148,  0.5398,  0.8969,  0.5744,  0.3527,\n",
      "         0.4758,  0.1248,  0.1467,  0.3656], device='cuda:0')\n",
      "真实的属性向量tensor([-0.0216, -0.0066, -0.0611, -0.0871,  1.2669,  0.0663,  0.6251,  0.0986,\n",
      "         0.5885, -0.1727,  0.0077, -0.0027,  0.6264,  1.1165,  0.6453,  0.4598,\n",
      "         0.6012,  0.0846,  0.1196,  0.4734])\n",
      "真实标签为：EL+S\n",
      "欧式距离计算的标签为：EL+S\n",
      "余弦相似度计算的标签为：EL+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_two_wm_tensor, test_two_att_tensor, two_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor, test_single_att_tensor)\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor, test_two_att_tensor)\n",
    "\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688473520249221\n",
      "0.8988461538461539\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, two_defect_att, len(test_two_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_att_tensor = torch.tensor(train_single_att, dtype=torch.float32)\n",
    "for i in range(len(train_single_label)):\n",
    "    train_single_att_tensor[i] = single_defect_att[train_single_label[i]]\n",
    "\n",
    "train_two_att_tensor = torch.tensor(train_two_att, dtype=torch.float32)\n",
    "for i in range(len(train_two_label)):\n",
    "    train_two_att_tensor[i] = two_defect_att[train_two_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_dataset = MyDataSet(train_single_wm_tensor, train_single_att_tensor)\n",
    "train_two_dataset = MyDataSet(train_two_wm_tensor, train_two_att_tensor)\n",
    "\n",
    "train_single_loader = DataLoader(train_single_dataset, batch_size=32, shuffle=False)\n",
    "train_two_loader = DataLoader(train_two_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9834224598930481\n",
      "0.8908791208791209\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_single_loader, single_defect_att, len(train_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_two_loader, two_defect_att, len(train_two_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
