{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 52, 52]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 52, 52]) torch.Size([8400, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 224, 224]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 224, 224]) torch.Size([8400, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 9100\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "8400 8400\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_label = list(pseudo_three_label)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm\n",
    "train_label = train_single_label + pseudo_two_label + pseudo_three_label\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_four_wm\n",
    "val_label = val_four_label\n",
    "val_att = val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_single_label + test_two_label + test_three_label + test_four_label\n",
    "test_att = test_single_att + test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single_two_three.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：8.07073712348938, 总Loss:2.795765388291329\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:0.1023066220805049\n",
      "第1轮训练后,整体验证集上的Accuracy:0.9\n",
      "————第2轮训练开始————\n",
      "训练时间为：7.791868209838867, 总Loss:2.7088923696428537\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:0.08638957305811346\n",
      "第2轮训练后,整体验证集上的Accuracy:0.945\n",
      "————第3轮训练开始————\n",
      "训练时间为：7.803165435791016, 总Loss:2.6639955632854253\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:0.08704480645246804\n",
      "第3轮训练后,整体验证集上的Accuracy:0.9375\n",
      "————第4轮训练开始————\n",
      "训练时间为：7.77438497543335, 总Loss:2.716744404984638\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:0.08722930098883808\n",
      "第4轮训练后,整体验证集上的Accuracy:0.9575\n",
      "————第5轮训练开始————\n",
      "训练时间为：7.892982244491577, 总Loss:2.76859495555982\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:0.09202711167745292\n",
      "第5轮训练后,整体验证集上的Accuracy:0.905\n",
      "————第6轮训练开始————\n",
      "训练时间为：7.9885969161987305, 总Loss:2.9306188602931798\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:0.09567924658767879\n",
      "第6轮训练后,整体验证集上的Accuracy:0.92\n",
      "————第7轮训练开始————\n",
      "训练时间为：8.046982526779175, 总Loss:2.937093110755086\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:0.09470495604909956\n",
      "第7轮训练后,整体验证集上的Accuracy:0.9225\n",
      "————第8轮训练开始————\n",
      "训练时间为：7.754583358764648, 总Loss:2.885853503830731\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:0.0913080582395196\n",
      "第8轮训练后,整体验证集上的Accuracy:0.9375\n",
      "————第9轮训练开始————\n",
      "训练时间为：7.825162410736084, 总Loss:2.9821014124900103\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:0.09450361342169344\n",
      "第9轮训练后,整体验证集上的Accuracy:0.92\n",
      "————第10轮训练开始————\n",
      "训练时间为：7.980346918106079, 总Loss:3.0408870079554617\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:0.0915189862716943\n",
      "第10轮训练后,整体验证集上的Accuracy:0.955\n",
      "————第11轮训练开始————\n",
      "训练时间为：8.105247259140015, 总Loss:2.943049652967602\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:0.09782752906903625\n",
      "第11轮训练后,整体验证集上的Accuracy:0.9175\n",
      "————第12轮训练开始————\n",
      "训练时间为：8.132776260375977, 总Loss:2.9920305092819035\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:0.10009463271126151\n",
      "第12轮训练后,整体验证集上的Accuracy:0.945\n",
      "————第13轮训练开始————\n",
      "训练时间为：7.877069473266602, 总Loss:2.926843184279278\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:0.10374680650420487\n",
      "第13轮训练后,整体验证集上的Accuracy:0.93\n",
      "————第14轮训练开始————\n",
      "训练时间为：7.8725433349609375, 总Loss:3.041997953085229\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:0.10938001284375787\n",
      "第14轮训练后,整体验证集上的Accuracy:0.9\n",
      "————第15轮训练开始————\n",
      "训练时间为：8.08701753616333, 总Loss:3.150210839463398\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:0.09399801469407976\n",
      "第15轮训练后,整体验证集上的Accuracy:0.9575\n",
      "————第16轮训练开始————\n",
      "训练时间为：7.879839658737183, 总Loss:3.0386775927618146\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:0.11190171260386705\n",
      "第16轮训练后,整体验证集上的Accuracy:0.905\n",
      "————第17轮训练开始————\n",
      "训练时间为：8.050811767578125, 总Loss:3.0435802133288234\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:0.09815460862591863\n",
      "第17轮训练后,整体验证集上的Accuracy:0.91\n",
      "————第18轮训练开始————\n",
      "训练时间为：7.952545166015625, 总Loss:3.048508807318285\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:0.09511022176593542\n",
      "第18轮训练后,整体验证集上的Accuracy:0.935\n",
      "————第19轮训练开始————\n",
      "训练时间为：7.9438629150390625, 总Loss:3.194115827558562\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:0.10984715051017702\n",
      "第19轮训练后,整体验证集上的Accuracy:0.9125\n",
      "————第20轮训练开始————\n",
      "训练时间为：7.892803907394409, 总Loss:3.0957820096518844\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:0.10996633302420378\n",
      "第20轮训练后,整体验证集上的Accuracy:0.915\n",
      "训练结束，第4轮的模型在验证集上准确率最高，为0.9575\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    two_defect_att = update_semantic(model, two_defect_att, train_two_wm_tensor, 50)\n",
    "    three_defect_att = update_semantic(model, three_defect_att, train_three_wm_tensor, 50)\n",
    "    train_defect_att = {**single_defect_att, **two_defect_att, **three_defect_att}\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = train_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    # 由于更新语义需要的样本较多，所以我们使用训练集的四故障样本\n",
    "    four_defect_att = update_semantic(model, four_defect_att, train_four_wm_tensor, 50)  \n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = four_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model, val_loader, four_defect_att, val_size, 'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_three_four_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2_3_4/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2_3_4/updated_two_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(two_defect_att, file)\n",
    "        with open('updated_semantic_1_2_3_4/updated_three_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(three_defect_att, file)\n",
    "        with open('updated_semantic_1_2_3_4/updated_four_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(four_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset,train_loader,val_dataset,val_loader,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# model = torch.load('model_saved_pseudo/single_two_three_four_updated.pth')\n",
    "model = torch.load('model_saved_pseudo/train_single_two_three.pth')\n",
    "with open('updated_semantic_1_2_3_4/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3_4/updated_two_dict.pkl', 'rb') as file:\n",
    "    two_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3_4/updated_three_dict.pkl', 'rb') as file:\n",
    "    three_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3_4/updated_four_dict.pkl', 'rb') as file:\n",
    "    four_defect_att = pickle.load(file)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_defect_att = {**single_defect_att, **two_defect_att, **three_defect_att, **four_defect_att}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_655/3154717973.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n",
    "for i in range(len(test_single_label)):\n",
    "    test_single_att_tensor[i] = single_defect_att[test_single_label[i]]\n",
    "\n",
    "test_two_att_tensor = torch.tensor(test_two_att, dtype=torch.float32)\n",
    "for i in range(len(test_two_label)):\n",
    "    test_two_att_tensor[i] = two_defect_att[test_two_label[i]]\n",
    "\n",
    "test_three_att_tensor = torch.tensor(test_three_att, dtype=torch.float32)\n",
    "for i in range(len(test_three_label)):\n",
    "    test_three_att_tensor[i] = three_defect_att[test_three_label[i]]\n",
    "\n",
    "test_four_att_tensor = torch.tensor(test_four_att, dtype=torch.float32)\n",
    "for i in range(len(test_four_label)):\n",
    "    test_four_att_tensor[i] = four_defect_att[test_four_label[i]]\n",
    "\n",
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = total_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(test_single_wm, dtype=torch.float32)\n",
    "test_two_wm_tensor = torch.tensor(test_two_wm, dtype=torch.float32)\n",
    "test_three_wm_tensor = torch.tensor(test_three_wm, dtype=torch.float32)\n",
    "test_four_wm_tensor = torch.tensor(test_four_wm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.1222,  0.6384,  0.7408,  0.7659,  1.1127,  1.0269,  0.8200,  1.0264,\n",
      "         1.1633, -0.0234, -0.0030, -0.0175,  0.7516,  1.1475,  0.7432,  0.8608,\n",
      "         0.8199,  1.0264,  0.6129,  0.8213], device='cuda:0')\n",
      "真实的属性向量tensor([ 0.1261,  0.6549,  0.7414,  0.7692,  1.0966,  1.0408,  0.8315,  1.0385,\n",
      "         1.1315, -0.0222, -0.0029, -0.0166,  0.7138,  1.1295,  0.6882,  0.8684,\n",
      "         0.8315,  1.0385,  0.6132,  0.8285])\n",
      "真实标签为：D+ER+L+S\n",
      "欧式距离计算的标签为：D+ER+L+S\n",
      "余弦相似度计算的标签为：D+ER+L+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_four_wm_tensor, test_four_att_tensor, four_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor, test_single_att_tensor)\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor, test_two_att_tensor)\n",
    "test_three_dataset = MyDataSet(test_three_wm_tensor, test_three_att_tensor)\n",
    "test_four_dataset = MyDataSet(test_four_wm_tensor, test_four_att_tensor)\n",
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)\n",
    "test_three_loader = DataLoader(test_three_dataset, batch_size=32, shuffle=False)\n",
    "test_four_loader = DataLoader(test_four_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815576323987539\n",
      "0.9565384615384616\n",
      "0.9354166666666667\n",
      "0.9275\n",
      "0.8642808912896691\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, two_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, three_defect_att, len(test_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_four_loader, four_defect_att, len(test_four_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_loader, total_defect_att, len(test_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_att_tensor = torch.tensor(train_single_att, dtype=torch.float32)\n",
    "for i in range(len(train_single_label)):\n",
    "    train_single_att_tensor[i] = single_defect_att[train_single_label[i]]\n",
    "\n",
    "train_two_att_tensor = torch.tensor(train_two_att, dtype=torch.float32)\n",
    "for i in range(len(train_two_label)):\n",
    "    train_two_att_tensor[i] = two_defect_att[train_two_label[i]]\n",
    "\n",
    "train_three_att_tensor = torch.tensor(train_three_att, dtype=torch.float32)\n",
    "for i in range(len(train_three_label)):\n",
    "    train_three_att_tensor[i] = three_defect_att[train_three_label[i]]\n",
    "\n",
    "train_four_att_tensor = torch.tensor(train_four_att, dtype=torch.float32)\n",
    "for i in range(len(train_four_label)):\n",
    "    train_four_att_tensor[i] = four_defect_att[train_four_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_dataset = MyDataSet(train_single_wm_tensor, train_single_att_tensor)\n",
    "train_two_dataset = MyDataSet(train_two_wm_tensor, train_two_att_tensor)\n",
    "train_three_dataset = MyDataSet(train_three_wm_tensor, train_three_att_tensor)\n",
    "train_four_dataset = MyDataSet(train_four_wm_tensor, train_four_att_tensor)\n",
    "\n",
    "train_single_loader = DataLoader(train_single_dataset, batch_size=32, shuffle=False)\n",
    "train_two_loader = DataLoader(train_two_dataset, batch_size=32, shuffle=False)\n",
    "train_three_loader = DataLoader(train_three_dataset, batch_size=32, shuffle=False)\n",
    "train_four_loader = DataLoader(train_four_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8267379679144385\n",
      "0.9556043956043956\n",
      "0.9322619047619047\n",
      "0.9203571428571429\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_single_loader, single_defect_att, len(train_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_two_loader, two_defect_att, len(train_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_three_loader, three_defect_att, len(train_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_four_loader, four_defect_att, len(train_four_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
