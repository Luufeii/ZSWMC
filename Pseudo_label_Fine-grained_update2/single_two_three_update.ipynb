{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 52, 52]) torch.Size([9100, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 224, 224]) torch.Size([9100, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 9100\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm\n",
    "train_label = train_single_label + pseudo_two_label\n",
    "train_att = train_single_att + pseudo_two_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_three_wm\n",
    "val_label = val_three_label\n",
    "val_att = val_three_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm\n",
    "test_label = test_single_label + test_two_label + test_three_label\n",
    "test_att = test_single_att + test_two_att + test_three_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "mul_defect_att = attri.mul_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_single_two.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：4.959113597869873, 总Loss:2.005633313441649\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:0.5351859191432595\n",
      "第1轮训练后,整体验证集上的Accuracy:0.8625\n",
      "————第2轮训练开始————\n",
      "训练时间为：4.755158424377441, 总Loss:1.8758211152162403\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:0.49233588366769254\n",
      "第2轮训练后,整体验证集上的Accuracy:0.8691666666666666\n",
      "————第3轮训练开始————\n",
      "训练时间为：4.803324222564697, 总Loss:1.9876475972123444\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:0.4920128080993891\n",
      "第3轮训练后,整体验证集上的Accuracy:0.8725\n",
      "————第4轮训练开始————\n",
      "训练时间为：4.731184720993042, 总Loss:1.9573010436724871\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:0.47280160803347826\n",
      "第4轮训练后,整体验证集上的Accuracy:0.875\n",
      "————第5轮训练开始————\n",
      "训练时间为：4.838423252105713, 总Loss:1.9257036643102765\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:0.5031918475870043\n",
      "第5轮训练后,整体验证集上的Accuracy:0.865\n",
      "————第6轮训练开始————\n",
      "训练时间为：4.820999383926392, 总Loss:1.9550088113173842\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:0.4713185739237815\n",
      "第6轮训练后,整体验证集上的Accuracy:0.8758333333333334\n",
      "————第7轮训练开始————\n",
      "训练时间为：4.768095016479492, 总Loss:1.9511998950038105\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:0.4790590286720544\n",
      "第7轮训练后,整体验证集上的Accuracy:0.8691666666666666\n",
      "————第8轮训练开始————\n",
      "训练时间为：4.814857482910156, 总Loss:1.9460981185548007\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:0.452223164960742\n",
      "第8轮训练后,整体验证集上的Accuracy:0.8808333333333334\n",
      "————第9轮训练开始————\n",
      "训练时间为：4.7741944789886475, 总Loss:1.934311379911378\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:0.46274636103771627\n",
      "第9轮训练后,整体验证集上的Accuracy:0.8758333333333334\n",
      "————第10轮训练开始————\n",
      "训练时间为：4.7915802001953125, 总Loss:1.9584849814418703\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:0.45057395356707275\n",
      "第10轮训练后,整体验证集上的Accuracy:0.885\n",
      "————第11轮训练开始————\n",
      "训练时间为：4.751802206039429, 总Loss:1.9556155824102461\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:0.4655635741073638\n",
      "第11轮训练后,整体验证集上的Accuracy:0.8758333333333334\n",
      "————第12轮训练开始————\n",
      "训练时间为：4.742692470550537, 总Loss:1.9521423617843539\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:0.4680202261079103\n",
      "第12轮训练后,整体验证集上的Accuracy:0.8716666666666667\n",
      "————第13轮训练开始————\n",
      "训练时间为：4.7503228187561035, 总Loss:2.0289999772794545\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:0.4761345135048032\n",
      "第13轮训练后,整体验证集上的Accuracy:0.8708333333333333\n",
      "————第14轮训练开始————\n",
      "训练时间为：4.785539865493774, 总Loss:2.009511746233329\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:0.455249180784449\n",
      "第14轮训练后,整体验证集上的Accuracy:0.8816666666666667\n",
      "————第15轮训练开始————\n",
      "训练时间为：4.765876293182373, 总Loss:2.062881751684472\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:0.4683673537801951\n",
      "第15轮训练后,整体验证集上的Accuracy:0.8691666666666666\n",
      "————第16轮训练开始————\n",
      "训练时间为：4.728183031082153, 总Loss:2.152019830653444\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:0.5087108341977\n",
      "第16轮训练后,整体验证集上的Accuracy:0.865\n",
      "————第17轮训练开始————\n",
      "训练时间为：4.953172445297241, 总Loss:2.083656156202778\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:0.5010921817738563\n",
      "第17轮训练后,整体验证集上的Accuracy:0.865\n",
      "————第18轮训练开始————\n",
      "训练时间为：4.753770351409912, 总Loss:2.161404813406989\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:0.49136970075778663\n",
      "第18轮训练后,整体验证集上的Accuracy:0.8741666666666666\n",
      "————第19轮训练开始————\n",
      "训练时间为：4.797547101974487, 总Loss:2.1889088165480644\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:0.4550547964172438\n",
      "第19轮训练后,整体验证集上的Accuracy:0.8841666666666667\n",
      "————第20轮训练开始————\n",
      "训练时间为：4.789916038513184, 总Loss:2.103398388950154\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:0.46552275284193456\n",
      "第20轮训练后,整体验证集上的Accuracy:0.8791666666666667\n",
      "训练结束，第10轮的模型在验证集上准确率最高，为0.885\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    two_defect_att = update_semantic(model, two_defect_att, train_two_wm_tensor, 50)\n",
    "    train_defect_att = {**single_defect_att, **two_defect_att}\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = train_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    # 由于更新语义需要的样本较多，所以我们使用训练集的三故障样本\n",
    "    three_defect_att = update_semantic(model, three_defect_att, train_three_wm_tensor, 50)  \n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = three_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model,val_loader,three_defect_att,val_size,'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/single_two_three_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_1_2_3/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_1_2_3/updated_two_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(two_defect_att, file)\n",
    "        with open('updated_semantic_1_2_3/updated_three_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(three_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_single_two.pth')\n",
    "with open('updated_semantic_1_2_3/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3/updated_two_dict.pkl', 'rb') as file:\n",
    "    two_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_1_2_3/updated_three_dict.pkl', 'rb') as file:\n",
    "    three_defect_att = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12851/101677459.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n",
    "for i in range(len(test_single_label)):\n",
    "    test_single_att_tensor[i] = single_defect_att[test_single_label[i]]\n",
    "\n",
    "test_two_att_tensor = torch.tensor(test_two_att, dtype=torch.float32)\n",
    "for i in range(len(test_two_label)):\n",
    "    test_two_att_tensor[i] = two_defect_att[test_two_label[i]]\n",
    "\n",
    "test_three_att_tensor = torch.tensor(test_three_att, dtype=torch.float32)\n",
    "for i in range(len(test_three_label)):\n",
    "    test_three_att_tensor[i] = three_defect_att[test_three_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(test_single_wm, dtype=torch.float32)\n",
    "test_two_wm_tensor = torch.tensor(test_two_wm, dtype=torch.float32)\n",
    "test_three_wm_tensor = torch.tensor(test_three_wm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.5913,  0.0530,  0.0412,  0.6114,  1.0817,  0.9927,  0.7487,  0.6612,\n",
      "         0.5326, -0.0099, -0.0012, -0.0034,  0.9686,  0.5941,  0.5219,  0.6431,\n",
      "         0.7488,  0.6612,  0.6718,  0.1556], device='cuda:0')\n",
      "真实的属性向量tensor([ 0.6418,  0.0576,  0.1518,  0.7596,  1.1599,  1.0891,  0.8024,  0.7304,\n",
      "         0.6587, -0.0101, -0.0031, -0.0087,  1.0328,  0.6987,  0.5478,  0.7648,\n",
      "         0.8024,  0.7303,  0.7364,  0.2386])\n",
      "真实标签为：C+ER+S\n",
      "欧式距离计算的标签为：C+ER+S\n",
      "余弦相似度计算的标签为：C+ER+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_three_wm_tensor, test_three_att_tensor, three_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor, test_single_att_tensor)\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor, test_two_att_tensor)\n",
    "test_three_dataset = MyDataSet(test_three_wm_tensor, test_three_att_tensor)\n",
    "\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)\n",
    "test_three_loader = DataLoader(test_three_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875389408099688\n",
      "0.9561538461538461\n",
      "0.9058333333333334\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, two_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, three_defect_att, len(test_three_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_att_tensor = torch.tensor(train_single_att, dtype=torch.float32)\n",
    "for i in range(len(train_single_label)):\n",
    "    train_single_att_tensor[i] = single_defect_att[train_single_label[i]]\n",
    "\n",
    "train_two_att_tensor = torch.tensor(train_two_att, dtype=torch.float32)\n",
    "for i in range(len(train_two_label)):\n",
    "    train_two_att_tensor[i] = two_defect_att[train_two_label[i]]\n",
    "\n",
    "train_three_att_tensor = torch.tensor(train_three_att, dtype=torch.float32)\n",
    "for i in range(len(train_three_label)):\n",
    "    train_three_att_tensor[i] = three_defect_att[train_three_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_dataset = MyDataSet(train_single_wm_tensor, train_single_att_tensor)\n",
    "train_two_dataset = MyDataSet(train_two_wm_tensor, train_two_att_tensor)\n",
    "train_three_dataset = MyDataSet(train_three_wm_tensor, train_three_att_tensor)\n",
    "\n",
    "train_single_loader = DataLoader(train_single_dataset, batch_size=32, shuffle=False)\n",
    "train_two_loader = DataLoader(train_two_dataset, batch_size=32, shuffle=False)\n",
    "train_three_loader = DataLoader(train_three_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9811051693404634\n",
      "0.9491208791208792\n",
      "0.9094047619047619\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, train_single_loader, single_defect_att, len(train_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_two_loader, two_defect_att, len(train_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, train_three_loader, three_defect_att, len(train_three_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
