{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这里用单、二、三、四故障训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "pseudo_four_data_path = 'data_fake_label/four_fake_label_WM.npz' \n",
    "pseudo_four_data = np.load(pseudo_four_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "pseudo_four_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_four_data['label_name']:\n",
    "    pseudo_four_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "pseudo_four_att_vector = np.array(pseudo_four_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 52, 52]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 52, 52]) torch.Size([8400, 20])\n",
      "torch.Size([2800, 1, 52, 52]) torch.Size([2800, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "pseudo_four_wm = pseudo_four_data['denoise_wm']\n",
    "pseudo_four_wm_tensor = torch.reshape(torch.tensor(pseudo_four_wm, dtype=torch.float32),(len(pseudo_four_wm),1,52,52))\n",
    "pseudo_four_att_tensor = torch.tensor(pseudo_four_att_vector, dtype=torch.float32)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 224, 224]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 224, 224]) torch.Size([8400, 20])\n",
      "torch.Size([2800, 1, 224, 224]) torch.Size([2800, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "pseudo_four_wm_tensor = trans(pseudo_four_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 9100\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "8400 8400\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "2800 2800\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)\n",
    "\n",
    "pseudo_four_wm = list(pseudo_four_wm_tensor)\n",
    "pseudo_four_att = list(pseudo_four_att_tensor)\n",
    "print(len(pseudo_four_wm),len(pseudo_four_att))\n",
    "print(pseudo_four_wm[10].shape, pseudo_four_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor, pseudo_four_wm_tensor, pseudo_four_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm + pseudo_four_wm\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att + pseudo_four_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_single_wm + val_two_wm + val_three_wm + val_four_wm\n",
    "val_att = val_single_att + val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm + test_four_wm\n",
    "test_att = test_single_att + test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25910 3700 7405\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "\n",
    "train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "val_dataset = MyDataSet(val_wm_tensor,val_att_tensor)\n",
    "test_dataset = MyDataSet(test_wm_tensor,test_att_tensor)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 116 232\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader),len(val_loader),len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor\n",
    "del val_wm_tensor,val_att_tensor\n",
    "del test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "# 替换第一个卷积以适应我们的单通道图像\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# 替换最后的全连接层以适配我们的属性输出\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(attri.att_name))\n",
    "model.add_module('sigmoid', nn.Sigmoid())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加正则化项\n",
    "def regularization_loss(model, lambda_reg):\n",
    "    l2_reg = 0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param) ** 2  # 计算L2范数的平方\n",
    "    return lambda_reg * l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50  # 训练迭代的次数，一个epoch把训练集过一遍\n",
    "lambda_reg = 0.01  # 正则化强度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：28.23004937171936, 总Loss:26658.790088653564\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:8.742825939320028\n",
      "第1轮训练后,整体验证集上的Accuracy:0.46837837837837837\n",
      "————第2轮训练开始————\n",
      "训练时间为：25.17689323425293, 总Loss:22660.632122039795\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:7.69609265960753\n",
      "第2轮训练后,整体验证集上的Accuracy:0.5875675675675676\n",
      "————第3轮训练开始————\n",
      "训练时间为：25.1828351020813, 总Loss:19271.454921722412\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:6.687794511206448\n",
      "第3轮训练后,整体验证集上的Accuracy:0.6008108108108108\n",
      "————第4轮训练开始————\n",
      "训练时间为：25.192487478256226, 总Loss:16390.63161468506\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:5.647337376140058\n",
      "第4轮训练后,整体验证集上的Accuracy:0.7064864864864865\n",
      "————第5轮训练开始————\n",
      "训练时间为：25.18515682220459, 总Loss:13941.052656173706\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:5.294318964704871\n",
      "第5轮训练后,整体验证集上的Accuracy:0.7470270270270271\n",
      "————第6轮训练开始————\n",
      "训练时间为：25.192424297332764, 总Loss:11858.042915344238\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:5.1050385581329465\n",
      "第6轮训练后,整体验证集上的Accuracy:0.73\n",
      "————第7轮训练开始————\n",
      "训练时间为：25.18699049949646, 总Loss:10086.672746658325\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:4.604686782695353\n",
      "第7轮训练后,整体验证集上的Accuracy:0.7964864864864865\n",
      "————第8轮训练开始————\n",
      "训练时间为：25.19095277786255, 总Loss:8580.51421546936\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:4.175569341983646\n",
      "第8轮训练后,整体验证集上的Accuracy:0.8154054054054054\n",
      "————第9轮训练开始————\n",
      "训练时间为：25.166870594024658, 总Loss:7299.481805801392\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:3.934884605463594\n",
      "第9轮训练后,整体验证集上的Accuracy:0.8521621621621621\n",
      "————第10轮训练开始————\n",
      "训练时间为：25.181358575820923, 总Loss:6210.190493583679\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:3.654891418525949\n",
      "第10轮训练后,整体验证集上的Accuracy:0.8705405405405405\n",
      "————第11轮训练开始————\n",
      "训练时间为：25.254151582717896, 总Loss:5283.9591588974\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:3.5628294772468507\n",
      "第11轮训练后,整体验证集上的Accuracy:0.8724324324324324\n",
      "————第12轮训练开始————\n",
      "训练时间为：25.208498239517212, 总Loss:4496.259359359741\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:4.5717373308725655\n",
      "第12轮训练后,整体验证集上的Accuracy:0.7894594594594595\n",
      "————第13轮训练开始————\n",
      "训练时间为：25.277039766311646, 总Loss:3826.737895965576\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:3.3405905519612134\n",
      "第13轮训练后,整体验证集上的Accuracy:0.8586486486486486\n",
      "————第14轮训练开始————\n",
      "训练时间为：25.24492573738098, 总Loss:3257.3560523986816\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:3.153364988975227\n",
      "第14轮训练后,整体验证集上的Accuracy:0.8694594594594595\n",
      "————第15轮训练开始————\n",
      "训练时间为：25.24070119857788, 总Loss:2773.3012590408325\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:3.4928050762973726\n",
      "第15轮训练后,整体验证集上的Accuracy:0.8478378378378378\n",
      "————第16轮训练开始————\n",
      "训练时间为：25.23347568511963, 总Loss:2361.757143497467\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:2.7993051088415086\n",
      "第16轮训练后,整体验证集上的Accuracy:0.8967567567567568\n",
      "————第17轮训练开始————\n",
      "训练时间为：25.443673849105835, 总Loss:2011.9838781356812\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:3.003035190049559\n",
      "第17轮训练后,整体验证集上的Accuracy:0.8635135135135135\n",
      "————第18轮训练开始————\n",
      "训练时间为：25.309306621551514, 总Loss:1714.8201274871826\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:3.113293783273548\n",
      "第18轮训练后,整体验证集上的Accuracy:0.8405405405405405\n",
      "————第19轮训练开始————\n",
      "训练时间为：25.208194494247437, 总Loss:1462.37300157547\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:2.790918420534581\n",
      "第19轮训练后,整体验证集上的Accuracy:0.885945945945946\n",
      "————第20轮训练开始————\n",
      "训练时间为：25.239295959472656, 总Loss:1248.0610563755035\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:2.7913755057379603\n",
      "第20轮训练后,整体验证集上的Accuracy:0.8808108108108108\n",
      "————第21轮训练开始————\n",
      "训练时间为：25.42707109451294, 总Loss:1066.0458548069\n",
      "****第21轮训练结束****\n",
      "第21轮训练后,整体验证集上的Loss:2.7624748526141047\n",
      "第21轮训练后,整体验证集上的Accuracy:0.89\n",
      "————第22轮训练开始————\n",
      "训练时间为：25.220342874526978, 总Loss:911.7536447048187\n",
      "****第22轮训练结束****\n",
      "第22轮训练后,整体验证集上的Loss:3.3449450554326177\n",
      "第22轮训练后,整体验证集上的Accuracy:0.8608108108108108\n",
      "————第23轮训练开始————\n",
      "训练时间为：25.26106309890747, 总Loss:780.9346923828125\n",
      "****第23轮训练结束****\n",
      "第23轮训练后,整体验证集上的Loss:3.255271088331938\n",
      "第23轮训练后,整体验证集上的Accuracy:0.8194594594594594\n",
      "————第24轮训练开始————\n",
      "训练时间为：25.21817374229431, 总Loss:670.2489176988602\n",
      "****第24轮训练结束****\n",
      "第24轮训练后,整体验证集上的Loss:3.064977889880538\n",
      "第24轮训练后,整体验证集上的Accuracy:0.8716216216216216\n",
      "————第25轮训练开始————\n",
      "训练时间为：25.195743322372437, 总Loss:576.5953276157379\n",
      "****第25轮训练结束****\n",
      "第25轮训练后,整体验证集上的Loss:3.153492322191596\n",
      "第25轮训练后,整体验证集上的Accuracy:0.8821621621621621\n",
      "————第26轮训练开始————\n",
      "训练时间为：25.197349309921265, 总Loss:497.4236704111099\n",
      "****第26轮训练结束****\n",
      "第26轮训练后,整体验证集上的Loss:4.082718184217811\n",
      "第26轮训练后,整体验证集上的Accuracy:0.784054054054054\n",
      "————第27轮训练开始————\n",
      "训练时间为：25.193724393844604, 总Loss:430.7148771286011\n",
      "****第27轮训练结束****\n",
      "第27轮训练后,整体验证集上的Loss:3.5638558445498347\n",
      "第27轮训练后,整体验证集上的Accuracy:0.8383783783783784\n",
      "————第28轮训练开始————\n",
      "训练时间为：25.19437336921692, 总Loss:374.3978859782219\n",
      "****第28轮训练结束****\n",
      "第28轮训练后,整体验证集上的Loss:4.085798358544707\n",
      "第28轮训练后,整体验证集上的Accuracy:0.8283783783783784\n",
      "————第29轮训练开始————\n",
      "训练时间为：25.212074518203735, 总Loss:326.910802423954\n",
      "****第29轮训练结束****\n",
      "第29轮训练后,整体验证集上的Loss:3.7389415204524994\n",
      "第29轮训练后,整体验证集上的Accuracy:0.8245945945945946\n",
      "————第30轮训练开始————\n",
      "训练时间为：25.27794051170349, 总Loss:286.95136618614197\n",
      "****第30轮训练结束****\n",
      "第30轮训练后,整体验证集上的Loss:3.812011814676225\n",
      "第30轮训练后,整体验证集上的Accuracy:0.8045945945945946\n",
      "————第31轮训练开始————\n",
      "训练时间为：25.307142972946167, 总Loss:253.24466395378113\n",
      "****第31轮训练结束****\n",
      "第31轮训练后,整体验证集上的Loss:3.817206984385848\n",
      "第31轮训练后,整体验证集上的Accuracy:0.8264864864864865\n",
      "————第32轮训练开始————\n",
      "训练时间为：25.212185382843018, 总Loss:224.7668697834015\n",
      "****第32轮训练结束****\n",
      "第32轮训练后,整体验证集上的Loss:3.9122080337256193\n",
      "第32轮训练后,整体验证集上的Accuracy:0.8156756756756757\n",
      "————第33轮训练开始————\n",
      "训练时间为：25.338207244873047, 总Loss:200.66036036610603\n",
      "****第33轮训练结束****\n",
      "第33轮训练后,整体验证集上的Loss:4.961086578667164\n",
      "第33轮训练后,整体验证集上的Accuracy:0.6113513513513513\n",
      "————第34轮训练开始————\n",
      "训练时间为：25.23327136039734, 总Loss:180.1918885409832\n",
      "****第34轮训练结束****\n",
      "第34轮训练后,整体验证集上的Loss:4.103173458948731\n",
      "第34轮训练后,整体验证集上的Accuracy:0.8164864864864865\n",
      "————第35轮训练开始————\n",
      "训练时间为：25.225118398666382, 总Loss:162.80980283021927\n",
      "****第35轮训练结束****\n",
      "第35轮训练后,整体验证集上的Loss:4.187688998878002\n",
      "第35轮训练后,整体验证集上的Accuracy:0.7624324324324324\n",
      "————第36轮训练开始————\n",
      "训练时间为：25.175844430923462, 总Loss:148.24544510245323\n",
      "****第36轮训练结束****\n",
      "第36轮训练后,整体验证集上的Loss:4.8401434905827045\n",
      "第36轮训练后,整体验证集上的Accuracy:0.6994594594594594\n",
      "————第37轮训练开始————\n",
      "训练时间为：25.189616203308105, 总Loss:135.6216758787632\n",
      "****第37轮训练结束****\n",
      "第37轮训练后,整体验证集上的Loss:10.424611736088991\n",
      "第37轮训练后,整体验证集上的Accuracy:0.3545945945945946\n",
      "————第38轮训练开始————\n",
      "训练时间为：25.25751757621765, 总Loss:124.84435066580772\n",
      "****第38轮训练结束****\n",
      "第38轮训练后,整体验证集上的Loss:4.628157790750265\n",
      "第38轮训练后,整体验证集上的Accuracy:0.7891891891891892\n",
      "————第39轮训练开始————\n",
      "训练时间为：25.369953155517578, 总Loss:116.3750464618206\n",
      "****第39轮训练结束****\n",
      "第39轮训练后,整体验证集上的Loss:4.731107871979475\n",
      "第39轮训练后,整体验证集上的Accuracy:0.7981081081081081\n",
      "————第40轮训练开始————\n",
      "训练时间为：25.18522548675537, 总Loss:107.8804090321064\n",
      "****第40轮训练结束****\n",
      "第40轮训练后,整体验证集上的Loss:5.129968944936991\n",
      "第40轮训练后,整体验证集上的Accuracy:0.7705405405405406\n",
      "————第41轮训练开始————\n",
      "训练时间为：25.20000982284546, 总Loss:101.02501532435417\n",
      "****第41轮训练结束****\n",
      "第41轮训练后,整体验证集上的Loss:5.198196733370423\n",
      "第41轮训练后,整体验证集上的Accuracy:0.7002702702702702\n",
      "————第42轮训练开始————\n",
      "训练时间为：25.37099599838257, 总Loss:95.07744219899178\n",
      "****第42轮训练结束****\n",
      "第42轮训练后,整体验证集上的Loss:4.881954560056329\n",
      "第42轮训练后,整体验证集上的Accuracy:0.7643243243243243\n",
      "————第43轮训练开始————\n",
      "训练时间为：25.33550262451172, 总Loss:90.25826200842857\n",
      "****第43轮训练结束****\n",
      "第43轮训练后,整体验证集上的Loss:8.082364274188876\n",
      "第43轮训练后,整体验证集上的Accuracy:0.2921621621621622\n",
      "————第44轮训练开始————\n",
      "训练时间为：25.232977151870728, 总Loss:86.59066443145275\n",
      "****第44轮训练结束****\n",
      "第44轮训练后,整体验证集上的Loss:4.620548186823726\n",
      "第44轮训练后,整体验证集上的Accuracy:0.7916216216216216\n",
      "————第45轮训练开始————\n",
      "训练时间为：25.226045846939087, 总Loss:82.05517214536667\n",
      "****第45轮训练结束****\n",
      "第45轮训练后,整体验证集上的Loss:5.272743411362171\n",
      "第45轮训练后,整体验证集上的Accuracy:0.6754054054054054\n",
      "————第46轮训练开始————\n",
      "训练时间为：25.17188334465027, 总Loss:78.87672878801823\n",
      "****第46轮训练结束****\n",
      "第46轮训练后,整体验证集上的Loss:5.323511056602001\n",
      "第46轮训练后,整体验证集上的Accuracy:0.6543243243243243\n",
      "————第47轮训练开始————\n",
      "训练时间为：25.23832058906555, 总Loss:76.20095339417458\n",
      "****第47轮训练结束****\n",
      "第47轮训练后,整体验证集上的Loss:5.40470015630126\n",
      "第47轮训练后,整体验证集上的Accuracy:0.6459459459459459\n",
      "————第48轮训练开始————\n",
      "训练时间为：25.214425086975098, 总Loss:74.08191893994808\n",
      "****第48轮训练结束****\n",
      "第48轮训练后,整体验证集上的Loss:7.116579266265035\n",
      "第48轮训练后,整体验证集上的Accuracy:0.42324324324324325\n",
      "————第49轮训练开始————\n",
      "训练时间为：25.214418411254883, 总Loss:72.17750960588455\n",
      "****第49轮训练结束****\n",
      "第49轮训练后,整体验证集上的Loss:6.3301974311470985\n",
      "第49轮训练后,整体验证集上的Accuracy:0.46405405405405403\n",
      "————第50轮训练开始————\n",
      "训练时间为：25.287691116333008, 总Loss:70.02583433687687\n",
      "****第50轮训练结束****\n",
      "第50轮训练后,整体验证集上的Loss:5.3956249468028545\n",
      "第50轮训练后,整体验证集上的Accuracy:0.6908108108108109\n",
      "训练结束，第16轮的模型在验证集上准确率最高，为0.8967567567567568\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for i in range(epochs):\n",
    "    # total_train_steps = 0\n",
    "    print(f'————第{i+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels) + regularization_loss(model, lambda_reg)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{i+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for data_v in val_loader:  \n",
    "            imgs,labels = data_v\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model,val_loader,attri.total_defect_att,val_size,'cos')\n",
    "    print(f'第{i+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{i+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:  # 我们在这里保存准确率最高的模型\n",
    "        best_acc = acc\n",
    "        No = i+1\n",
    "        torch.save(obj=model,f='model_saved_pseudo/train_all.pth')\n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('model_saved_pseudo/train_all.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(np.array(test_single_wm), dtype=torch.float32)\n",
    "test_single_att_tensor = torch.tensor(np.array(test_single_att), dtype=torch.float32)\n",
    "\n",
    "test_two_wm_tensor = torch.tensor(np.array(test_two_wm), dtype=torch.float32)\n",
    "test_two_att_tensor = torch.tensor(np.array(test_two_att), dtype=torch.float32)\n",
    "\n",
    "test_three_wm_tensor = torch.tensor(np.array(test_three_wm), dtype=torch.float32)\n",
    "test_three_att_tensor = torch.tensor(np.array(test_three_att), dtype=torch.float32)\n",
    "\n",
    "test_four_wm_tensor = torch.tensor(np.array(test_four_wm), dtype=torch.float32)\n",
    "test_four_att_tensor = torch.tensor(np.array(test_four_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwqUlEQVR4nO3dfXRU5YHH8d8ESQTNTAyQTFIDRldFRCgixhytxSUFIqVS6K5SrKgUqg12Jeq66akQ3Jewumv3aFk9PadCd32t5xRc6coe5LVoQAlmrW85xhMECgkWNhmCEgi5+4fNkEkmybzcO/dlvp9z5pzM3DuTZ5577/O7z73P3OszDMMQAAAOlGF3AQAA6A8hBQBwLEIKAOBYhBQAwLEIKQCAYxFSAADHIqQAAI5FSAEAHIuQAgA4FiEFAHAs20Jq9erVuuiii3TuueeqpKREb7/9tl1FAQA4lC0h9fLLL6uyslIrVqzQ3r17NXHiRM2YMUNHjhyxozgAAIfy2XGB2ZKSEk2ZMkW/+MUvJEldXV0qKirSfffdp7/7u78b9P1dXV06dOiQsrOz5fP5rC4uAMBkhmHo+PHjKiwsVEZG//2lc1JYJknSqVOnVFdXp6qqqvBrGRkZKisrU21tbdT3dHR0qKOjI/z8j3/8o8aNG2d5WQEA1jpw4IAuvPDCfqenPKT+9Kc/6cyZM8rPz494PT8/Xx9//HHU99TU1GjlypV9Xj9w4ID8fr8l5QQAWCcUCqmoqEjZ2dkDzpfykEpEVVWVKisrw8+7v5zf7yekAMDFBjtlk/KQGjlypIYMGaKWlpaI11taWhQMBqO+JysrS1lZWakoHgDAQVI+ui8zM1OTJ0/W5s2bw691dXVp8+bNKi0tTXVxAAAOZsvhvsrKSi1cuFDXXHONrr32Wv3bv/2bTpw4obvuusuO4gAAHMqWkLr11lv1+eefa/ny5WpubtbXv/51bdy4sc9gCgBAerPld1LJCoVCCgQCamtrY+AELOFbye/vBmKscF2zAYeJtR3n2n0A4kaII1UIKaAXGuDYUE9IBUIK6IGGNz7UF6xGSAEAHIuQAv6MXkFiqDdYiZACREObLOoPVnHFtfuAgdBAOoMZy4Gh7eiNnhRcjYDyFpYneiOk4Fo0aN7EckVPhBQAwLEIKQCAYxFScCUOCXkbyxfdCCm4Dg1YevCt9LGswRB0uAcNVnrqXu4MT09PhBRShpBBMpJZfwg49+JwHwDPYwfJvQgppASNBOzGOuhOhBQsR+MAp2BddB/OSSGtGdX9T/MNMA2pN9CyGgjL0d18hmG47oxiKBRSIBBQW1ub/H6/3cVBP5y61xpvY0cjZ59Eg6m3aMuQwRT2irUd53AfLOGVgEr0PUiemfUe7bOcuo4iEof7ELd03LiNanpUqWTFjkG0ZTjYukxvy370pBAXNwcUPSLEfajXxeu7VxBSQIwIufREUNmLkELM2FgJKiDVCCnEhIA6i6ACUoeQwqAIqL6MasIqnXBFdvswug/9YqMcXHdQMfIvPXBF9tSjJ4WoCCigf2wfqUNIoQ82wPhx6C/9sJ2khukhVVNToylTpig7O1t5eXmaM2eOGhoaIuaZOnWqfD5fxOOee+4xuyhIABseEDu2F+uZHlLbt29XRUWFdu3apU2bNun06dOaPn26Tpw4ETHf4sWLdfjw4fDjscceM7soQATOGwHuY/rAiY0bN0Y8X7t2rfLy8lRXV6cbb7wx/Prw4cMVDAbN/vdIAnuF8DordlR8K30MpLCQ5eek2traJEm5ubkRrz///PMaOXKkxo8fr6qqKn3xxRf9fkZHR4dCoVDEA+ZKl4CiN5W+WPbuZOkQ9K6uLt1///26/vrrNX78+PDr3//+9zVmzBgVFhbqvffe08MPP6yGhgb99re/jfo5NTU1WrlypZVFTVvpEk49dTdWDHZID6kIp57bEb0qc1l6P6l7771Xr7/+unbu3KkLL7yw3/m2bNmiadOmqbGxUZdcckmf6R0dHero6Ag/D4VCKioq4n5SSUrHgIrGynsWITFuXyYE1eBsv5/U0qVLtWHDBm3dunXAgJKkkpISSVJjY2PU6VlZWfL7/REPJIeAgtfZudPA9mUe00PKMAwtXbpU69at05YtW1RcXDzoe+rr6yVJBQUFZhcHUbABRaIH5D1OWKZsZ+Yw/ZxURUWFXnjhBb366qvKzs5Wc3OzJCkQCGjYsGH69NNP9cILL+jmm2/WiBEj9N5772nZsmW68cYbNWHCBLOLA8TEV805KqdgOaAn089J+XzR9x7WrFmjO++8UwcOHNDtt9+u999/XydOnFBRUZG++93v6mc/+1nMh/FiPZaJvti7618yjaMT9tzdzsxwctLy4PxUdLG246b3pAbLvKKiIm3fvt3sfwskLdHelJMaRDei54SBcBX0NEEPKjbxDk8noDAYrpyeHELKAwgg8xE+1ku3HlQs2ylB1hdXQXc5AgrwDrbnvggpF2OFBryH7ToSIQUAcCxCyqXY2wK8i+37LELKhViBAe9jO/8KIeUyrLhA+mB7Zwi6a7CyAukp3X9nRU/KBQgoAOnaDhBSDpeuKyaAvtKxPSCkAKRcul1tAokjpBwsHfea4H0EVHLSrV1g4IRDpduKCO9LVTg59bqLZl602LfSlzYDKQgpByKg4CWEU/zzE1RncbjPQXwrfQQUkACnBlSiYu51pUGbQUg5hNdXNKQnq3tRvmpnB1Qy3z+e93q5/SCkHMDLKxiA1PBqO0JIAbBEKnpRXsdISEIKgAulQ0B1S/egIqQAwOHSOagYgg7ANdKpB9Vbz6BKp3qgJwXAFdKpYcZZhBQAR3P6MHM7pNPhP0IKgCUIFpiBkALgWARdfLz4WylCymZeXKmAbsmEjBcCyqrv4IW6iRUhBQBwLELKJulwYUhASmyv30s9BbO/y2Cf57W2xWcYhuuu9R4KhRQIBNTW1ia/3293ceLipZUHQHySGZWXaNg59XYesbbj9KRSiIAC0luiw+mTOrfn8nbH9JCqrq6Wz+eLeIwdOzY8/eTJk6qoqNCIESN0/vnna968eWppaTG7GI7j9hUFQOqZ9RsxN7c/lvSkrrzySh0+fDj82LlzZ3jasmXL9Nprr+mVV17R9u3bdejQIc2dO9eKYjiGm1cQAOaz45ybW9shS67dd8455ygYDPZ5va2tTb/61a/0wgsv6C//8i8lSWvWrNEVV1yhXbt26brrrov6eR0dHero6Ag/D4VCVhQbAOAwlvSkPvnkExUWFuriiy/WggULtH//fklSXV2dTp8+rbKysvC8Y8eO1ejRo1VbW9vv59XU1CgQCIQfRUVFVhTbEm7dewFgrUFH6Q0yPaH/6cL2yPSQKikp0dq1a7Vx40Y9/fTTampq0je+8Q0dP35czc3NyszMVE5OTsR78vPz1dzc3O9nVlVVqa2tLfw4cOCA2cW2hBtXCACp018QeWkIfrJMP9xXXl4e/nvChAkqKSnRmDFj9Jvf/EbDhg1L6DOzsrKUlZVlVhEtRzgBiFWqA6ln++TU4ek9WT4EPScnR5dddpkaGxsVDAZ16tQptba2RszT0tIS9RyWGxFQANzCDe2V5SHV3t6uTz/9VAUFBZo8ebKGDh2qzZs3h6c3NDRo//79Ki0ttboolnPDAgeAnpzebpl+uO/BBx/U7NmzNWbMGB06dEgrVqzQkCFDNH/+fAUCAS1atEiVlZXKzc2V3+/Xfffdp9LS0n5H9rmF0xc0ALiR6SF18OBBzZ8/X0ePHtWoUaN0ww03aNeuXRo1apQk6ec//7kyMjI0b948dXR0aMaMGfr3f/93s4sBAIiRb6XPseenuHafCehFAfCCVAYV1+5LEQIKgFc4sT0jpJLgxAUKAMlwWrtmyWWRvM5pCxEAzNTdxjnhPBU9qTgRUADShRPaO0IKAOBYhBQAwLEIKQCAYzFwAgAsZlTHNz9XQT+LnhQAWCjegEr0PV5FSAGAAxFUXyGkAMAiBE3yCCkAgGMRUnFwwg/bACCV7G73CKkY2b2gAMAudrZ/hBQAYFB2BRUhNQjfSh+9KACQPUFFSA2AcAKASKnecSekoqD3BAADS1UbSUgBABKSiqAipAAAjkVIAYBFkrlQLBeZ/QohBQAOQ0Cdxa06AMBCPQNnsGv5EU59EVIAkCKEUPw43AcAcCxCCgDgWIQUAMCxCCkAgGMxcAIwSe+RW2adJI/17q6clIcX0ZMCTBAtSJK9dbhRHd9ncKtyeJHpIXXRRRfJ5/P1eVRUVEiSpk6d2mfaPffcY3YxgJQZKBxSHRzxBhvgdKYf7nvnnXd05syZ8PP3339f3/rWt/RXf/VX4dcWL16sRx99NPx8+PDhZhcDcAyjOv5DcQQN8BXTQ2rUqFERz1etWqVLLrlE3/zmN8OvDR8+XMFgMObP7OjoUEdHR/h5KBRKvqCACQgTwFqWnpM6deqUnnvuOd19993y+c5e0v3555/XyJEjNX78eFVVVemLL74Y8HNqamoUCATCj6KiIsvKzH2kYAU7DvsBXmBpSK1fv16tra268847w699//vf13PPPaetW7eqqqpK//mf/6nbb799wM+pqqpSW1tb+HHgwAEriw3EJN4gIKiA+PkMwzCs+vAZM2YoMzNTr732Wr/zbNmyRdOmTVNjY6MuueSSmD43FAopEAiora1Nfr/frOLSi8KgzGr4BztHZUXAMEQdVjJWxBclsbbjlvWkPvvsM73xxhv64Q9/OOB8JSUlkqTGxkarihITAgqDMTM46OUAsbHsx7xr1qxRXl6eZs2aNeB89fX1kqSCggKritIvggmxsiJUEhn1l+z/k+hRwRo929N4e1UDsaQn1dXVpTVr1mjhwoU655yzOfjpp5/q7//+71VXV6d9+/bpv/7rv3THHXfoxhtv1IQJE6woSr8IKDgBPSp4kZntqyUh9cYbb2j//v26++67I17PzMzUG2+8oenTp2vs2LF64IEHNG/evAHPWVmBgEI8vBYkXvs+cCaz2llLDvdNnz5d0cZjFBUVafv27Vb8S8C1eh/2I0SAs7h2HzAArw4bJwjhFlwFHYjCq+EU7X8ykAJORkgBPaRjD4OwgpNxuA/4s3QMKMDpCCkAkghpOBMhBYgGuhv1AKchpJD2aJgB5yKkAEQgtOEkjO5D2qIx7h8j/uAUhBTSDuEUO8IKduNwH9IKAQW4CyEFYFCEO+xCSCFt0NAmh/qDHQgpAIBjEVIAYkZvCqmWdqP7uOGh96T6NuzpbrCgYlmgm2+lL+lbyadVSBFQ3tKzsWSotHP0XC4sDyQbVGkRUoST9/S3N0+vyllYHpD6aYNPxvZez5+TIqC8Z7DDTZw3AbzDsyHlW+kjoAAHYKcByfBsSCG90TAC3kBIwVUSDR9Cy17UPxKVFgMn4H6JNHI0jM7CCMz0EOt2F5IUiGE+QgqORtB4D2HlTVZtqxzug2MRUN7G8vUOK5clIQXANL7qs49YEFTuZ/UyJKTgSDRe7sPhO1iBkAJgCnYsYAVCCoCtCDcMhNF9cCRfNY2XGyX7OzYOGaK3uHtSO3bs0OzZs1VYWCifz6f169dHTDcMQ8uXL1dBQYGGDRumsrIyffLJJxHzHDt2TAsWLJDf71dOTo4WLVqk9vb2pL4IvIcGK/0Y1eycIFLcIXXixAlNnDhRq1evjjr9scce05NPPqlnnnlGu3fv1nnnnacZM2bo5Mmzl7xdsGCBPvjgA23atEkbNmzQjh07tGTJksS/BTwrnpFi8A6CCt18hmEkfKMPn8+ndevWac6cOZK+6kUVFhbqgQce0IMPPihJamtrU35+vtauXavbbrtNH330kcaNG6d33nlH11xzjSRp48aNuvnmm3Xw4EEVFhYO+n9DoZACgYDa2trk9/ujl42Ly3oSjVd6YQfF+RLdJruvODFQOy6ZPHCiqalJzc3NKisrC78WCARUUlKi2tpaSVJtba1ycnLCASVJZWVlysjI0O7du6N+bkdHh0KhUMQDAOB9poZUc3OzJCk/Pz/i9fz8/PC05uZm5eXlRUw/55xzlJubG56nt5qaGgUCgfCjqKjIzGLDRdizBtKLK4agV1VVqa2tLfw4cOCA3UWCTTjcB6QXU0MqGAxKklpaWiJeb2lpCU8LBoM6cuRIxPTOzk4dO3YsPE9vWVlZ8vv9EQ+kHwIqvdBrhmTy76SKi4sVDAa1efNmff3rX5f01SCH3bt3695775UklZaWqrW1VXV1dZo8ebIkacuWLerq6lJJSYmZxYFLED7ojYBCt7hDqr29XY2NjeHnTU1Nqq+vV25urkaPHq37779f//AP/6BLL71UxcXFeuSRR1RYWBgeAXjFFVdo5syZWrx4sZ555hmdPn1aS5cu1W233RbTyD54CwGF3ggo9BR3SO3Zs0c33XRT+HllZaUkaeHChVq7dq3+9m//VidOnNCSJUvU2tqqG264QRs3btS5554bfs/zzz+vpUuXatq0acrIyNC8efP05JNPmvB1AHfiquGEE6JL6ndSduF3Ut7g5QY3XukeUgSUe7nqd1IA4hdPA+3FxtyL3wnmIaQAGyXSQNOoI50QUgAAxyKkAJsk0yOiN4V0wf2kgBQzK2C6P8ergykAiZACTJfqXg43iISXEVKASew8BEevCl7FOSnYgsYUQCwIKQCAYxFSSDkv9qKcMtrOKeWIldvKi9QjpJAyRjUBlQpOK09/3FJO2IuBE7CcF4Opm1MbWqcPpHBqvcF5CCkgAW5pZJ02PN0t9Qbn4HAfLOWkBtIsbmtonVJep5QD7kJIAXFwa0Nrd7nt/v9wL0IKAOBYngwpbnjoHOxBQ/LuyE5Yz/MDJ2LZMGhIgdRge0S8PNmTihd7eNbyVdPwIHZsj+jJcyHV81BfPCs7hyOsR1ghVmyL6Oa5kILzEVSIBUEFycMhlegKzoYBAM7h2ZCCs9GbAhALQgoA4FiEFAAgYVYfFSGkAABJsTKoPP9jXgCA9eIOqpOSVg0+Gz0pAIBjEVIAAMfybEgleoyUodEA4Bxxh9SOHTs0e/ZsFRYWyufzaf369eFpp0+f1sMPP6yrrrpK5513ngoLC3XHHXfo0KFDEZ9x0UUXyefzRTxWrYrh4CRgM7f+2Nut5QbiHjhx4sQJTZw4UXfffbfmzp0bMe2LL77Q3r179cgjj2jixIn6v//7P/3N3/yNvvOd72jPnj0R8z766KNavHhx+Hl2dnaCXyGSscIIX78v3ltn04tCLLrXKaesL14NIKfUL2IXz7oYkhSIYb64Q6q8vFzl5eVRpwUCAW3atCnitV/84he69tprtX//fo0ePTr8enZ2toLBYLz/3jJsEIiX3WHl1XCS2B7dyKr10fJzUm1tbfL5fMrJyYl4fdWqVRoxYoQmTZqkxx9/XJ2dnf1+RkdHh0KhUMTDLFyZG8myIyy8GlBsj+5k5fpo6e+kTp48qYcffljz58+X3+8Pv/6Tn/xEV199tXJzc/XWW2+pqqpKhw8f1hNPPBH1c2pqarRy5cqY/2/vQ36Al3gxoNhO3cvq9dFnGIaR8Jt9Pq1bt05z5szpM+306dOaN2+eDh48qG3btkWEVG/PPvusfvSjH6m9vV1ZWVl9pnd0dKijoyP8PBQKqaioSG1tbf1+LreQdz6vNbapamipNzhJoutj9zmpgdpxyaKe1OnTp/XXf/3X+uyzz7Rly5YBCyBJJSUl6uzs1L59+3T55Zf3mZ6VlRU1vAAA9knFDpPp56S6A+qTTz7RG2+8oREjRgz6nvr6emVkZCgvL8/s4sDBvLYH7bUeDjCQVK3vcfek2tvb1djYGH7e1NSk+vp65ebmqqCgQN/73ve0d+9ebdiwQWfOnFFzc7MkKTc3V5mZmaqtrdXu3bt10003KTs7W7W1tVq2bJluv/12XXDBBeZ9M8AGRrX3wtdK1JU7pXKHLO5zUtu2bdNNN93U5/WFCxequrpaxcXFUd+3detWTZ06VXv37tWPf/xjffzxx+ro6FBxcbF+8IMfqLKyMuZDeqFQSIFAgHNSHuHlHogVjbBX6ouAch8z1z3LzklNnTpVA+XaYJl39dVXa9euXfH+W3hYd2PllcYXAyOc3Mmu7dOz1+6D+3jxNzIE71leXL7pws71mJACLEZQEU5IHCEFx6FBA5zD7p0sQgpIAbM2dLsbjEQZ1e4te7qze6eR28cDKUIjDbeK944SZqInBSBluntUBLb72NWjIqQA2IKgch87RmgSUgCAuKQyqAgpALahN+VeqQoqz4aUsSLhO5AAAGKQiqDybEhJBBXgBvSmMBDPD0HveZdeAM7UHVR2/yYH8YtneHrE8j0padXg7/F0T6qbscKgVwW4AL0qdxpo56J7RGCiOyCe70n1RK8KcD56Ve7U824GZi67tAopiaACACv1F1C9j2aFQiEFVgUG/by0CykA1unZQCV76I67HHtDsqda0uKcFAAg9cwYC0BIAQAci8N9cCQ7r7qMxJm5zDjUB4meFByMRip9sezRjZCCo9FYpR+WOXricB8cr+fvL+BdhBOioScF16AR8y6WLfpDSMFVaMy8h2WKgRBSAADHIqTgOux5ewfLEoMhpOBKNG7uxzJELAgpuBaNnHux7BArhqDD1cxo7Bja3lcyw/4JIJiJnhSACMmEDAEFs8UdUjt27NDs2bNVWFgon8+n9evXR0y/88475fP5Ih4zZ86MmOfYsWNasGCB/H6/cnJytGjRIrW3tyf1RYBE0bD2L566oR5hhbhD6sSJE5o4caJWr17d7zwzZ87U4cOHw48XX3wxYvqCBQv0wQcfaNOmTdqwYYN27NihJUuWxF96AJaLJXwIKPRmxm06pATOSZWXl6u8vHzAebKyshQMBqNO++ijj7Rx40a98847uuaaayRJTz31lG6++Wb9y7/8iwoLC+MtEgDAQcwKKMmic1Lbtm1TXl6eLr/8ct177706evRoeFptba1ycnLCASVJZWVlysjI0O7du6N+XkdHh0KhUMQDQOoM1FOiF4VuxgrD1ICSLBjdN3PmTM2dO1fFxcX69NNP9dOf/lTl5eWqra3VkCFD1NzcrLy8vMhCnHOOcnNz1dzcHPUza2pqtHLlSrOLCiAO0Ub8EVCQzO059WZ6SN12223hv6+66ipNmDBBl1xyibZt26Zp06Yl9JlVVVWqrKwMPw+FQioqKkq6rADiRzAhlSwfgn7xxRdr5MiRamxslCQFg0EdOXIkYp7Ozk4dO3as3/NYWVlZ8vv9EQ8AgP2s7EVJKQipgwcP6ujRoyooKJAklZaWqrW1VXV1deF5tmzZoq6uLpWUlFhdHACAi8QdUu3t7aqvr1d9fb0kqampSfX19dq/f7/a29v10EMPadeuXdq3b582b96sW265RX/xF3+hGTNmSJKuuOIKzZw5U4sXL9bbb7+tN998U0uXLtVtt92WspF9Vic/3IdDWF+hHuA0cYfUnj17NGnSJE2aNEmSVFlZqUmTJmn58uUaMmSI3nvvPX3nO9/RZZddpkWLFmny5Mn6/e9/r6ysrPBnPP/88xo7dqymTZumm2++WTfccIN++ctfmvetYkBQAYDz+QzDcF1rHQqFFAgE1NbWZsr5Kd9Knwmlghek83X86EWhW/d2EMs6kegOf6ztOBeY1dlKJqyQzIVV3YpwQrfe6308YWUVQgqIYrCN0ishRkAhFka1fesKIdWDscKgN4WYmN3j6tkAxPOZZrwPkJy748WtOnphQAVSrXdgxBogib4P6C2WgLIrxAgpIAluDAY3lhnpi5ACbNRfYAwWJIm+D+gtnh6SUZ36HhUhBSTJacHAFcsRC7MCx+rz+IQUYIJEGv9YekvRzjslehNCAgqSOeGUyt4UP+aNghF+ALzI7HCJGF0a56CzWNtxelIAAMcipAAgDVhxiC4Vh/0IKQBAQlJxnpOQioIf9ALAwJI5HxUPLovUDy46CwB99e49uf7OvG5HrwoAvmLHzxjoScWAC88CSHepOrzXGz2pGNGjApCu7AooiZCKC0EFIJ3Z0QYSUgDgccn8nsnuy2kRUgAAx2LgBAB4lFPvthsPelIA4EFeCCiJnhQAeIpXwqkbPSkAgGMRUgDgEV7rRUmEFADAwQipOPGDXgBOZEUvys4rTXQjpBJAUAFwEqsDyk6M7ktQz6Di4rMAUi1VwWT3Tjk9KQBAVHYHlERImcIJCxJA+kjF+SentGtxh9SOHTs0e/ZsFRYWyufzaf369RHTfT5f1Mfjjz8enueiiy7qM33VqlVJfxkA8DqvDpDoT9whdeLECU2cOFGrV6+OOv3w4cMRj2effVY+n0/z5s2LmO/RRx+NmO++++5L7Bs4hNMWLAB4QdwDJ8rLy1VeXt7v9GAwGPH81Vdf1U033aSLL7444vXs7Ow+8/ano6NDHR0d4eehUCiOEqcOd/AFYDVftbm9KSf3oiSLz0m1tLTod7/7nRYtWtRn2qpVqzRixAhNmjRJjz/+uDo7O/v9nJqaGgUCgfCjqKjIymInxYkLGQCiccow84FYOgT917/+tbKzszV37tyI13/yk5/o6quvVm5urt566y1VVVXp8OHDeuKJJ6J+TlVVlSorK8PPQ6GQK4LKi70qs/bg3LBxAE6VbG+q9/bn5J1rn2EYCZfO5/Np3bp1mjNnTtTpY8eO1be+9S099dRTA37Os88+qx/96Edqb29XVlbWoP83FAopEAiora1Nfr8/kaKnlFfCyss/GATcKt7t0ikBFWs7btnhvt///vdqaGjQD3/4w0HnLSkpUWdnp/bt22dVcZAkL164EvCCeHb0nDrMfCCWhdSvfvUrTZ48WRMnThx03vr6emVkZCgvL8+q4iAJVgYU4Qckz1cdX1i5IZy6xX1Oqr29XY2NjeHnTU1Nqq+vV25urkaPHi3pq27cK6+8on/913/t8/7a2lrt3r1bN910k7Kzs1VbW6tly5bp9ttv1wUXXJDEV3EuRv0BsJtbD63H3ZPas2ePJk2apEmTJkmSKisrNWnSJC1fvjw8z0svvSTDMDR//vw+78/KytJLL72kb37zm7ryyiv1j//4j1q2bJl++ctfJvE1nM9Ney6pRm8KMEd/QeT0YeYDSWrghF3cNnCiJzf2qFIVIm7d0wPcwkkBZfvACUTnlpOVdjCq6VUBiMStOmzi5d9SJas7qOhZAeZw844xIQUAHuTmYOqJw30288qKZAUO/QHx89opBUIKADzCS+HUjZDCoOw8N0RvCkhvhBQcj6AC0hchhZjYPdKO4elAeiKkEDO7g0oiqIB0wxB0xMWMoEo2aPgdFZA+6Ekh5QgXALEipGALggpALAgpB/DibxtSgfNTwFlebUcIKYfw6go2ECec3wK8wMvtBwMnHISLziamZ1DFGnzxhBuHJmGGWNc5r95hN1H0pBwoHVa8bnYEQLy9L3prSFY861Cs86ZLO0FIOVS6rIDSV0HV/UjWYBt4ooFDUCFRiaw7g67HadQ+EFIOlk4rYjfOU8FLklkX+3tvurULhBTSBuEFuA8h5XDpttckWdObMiOgCDnYLR3bA0LKBdJxxeSwH9Jd720gHdsBiZByDa/dbTMWZgUVYQW3S7dtvydCymXSbWXlN0pIR6z3ZxFSLkRQAekj3bb33ggpl0q3Fdes31EBcBdCCq5CUCGdpNvOaDSElIuxAgPOlshOFTtikQgpl0vHoGIjhpvEs76ybvfFVdA9YLCgSuSq6rEM22aDgpcZ1eat44l8TjrugEbjMwzDdTURCoUUCATU1tYmv99vd3FcZbDASuQ3RXaGVap/A0Uwe1t/61Mql3u6hFOs7Xhch/tqamo0ZcoUZWdnKy8vT3PmzFFDQ0PEPCdPnlRFRYVGjBih888/X/PmzVNLS0vEPPv379esWbM0fPhw5eXl6aGHHlJnZ2c8RQEkMeoP3pIuARWPuA73bd++XRUVFZoyZYo6Ozv105/+VNOnT9eHH36o8847T5K0bNky/e53v9Mrr7yiQCCgpUuXau7cuXrzzTclSWfOnNGsWbMUDAb11ltv6fDhw7rjjjs0dOhQ/dM//ZP53xARjBVGv72pZG5jYXdQDPb/ueoEBjPQOpLMOk7wJCepw32ff/658vLytH37dt14441qa2vTqFGj9MILL+h73/ueJOnjjz/WFVdcodraWl133XV6/fXX9e1vf1uHDh1Sfn6+JOmZZ57Rww8/rM8//1yZmZmD/l8O9yUnWkiZ0YjbHVSDSYfviMRYcddciYAaiCWH+3pra2uTJOXm5kqS6urqdPr0aZWVlYXnGTt2rEaPHq3a2lpJUm1tra666qpwQEnSjBkzFAqF9MEHH0T9Px0dHQqFQhEPJI4NB7Ae25k5Eg6prq4u3X///br++us1fvx4SVJzc7MyMzOVk5MTMW9+fr6am5vD8/QMqO7p3dOiqampUSAQCD+KiooSLTb+rPcGlA5XHU+H74j4xHsBYm7tnnoJD0GvqKjQ+++/r507d5pZnqiqqqpUWVkZfh4KhQgqE/Q+P+WrTr4RTvb9bjic1v0d3VBWN3HCuc1YDLb8CShzJRRSS5cu1YYNG7Rjxw5deOGF4deDwaBOnTql1tbWiN5US0uLgsFgeJ6333474vO6R/91z9NbVlaWsrKyEikqBjHQQAo7WB0A3Z9r1k0Q3dCoOl3PZZGKHQAre8MElPniOtxnGIaWLl2qdevWacuWLSouLo6YPnnyZA0dOlSbN28Ov9bQ0KD9+/ertLRUklRaWqo//OEPOnLkSHieTZs2ye/3a9y4ccl8F3iI1YfVzBq6zv2qktNf3bmhTt1QRi+IK6QqKir03HPP6YUXXlB2draam5vV3NysL7/8UpIUCAS0aNEiVVZWauvWraqrq9Ndd92l0tJSXXfddZKk6dOna9y4cfrBD36g//3f/9X//M//6Gc/+5kqKiroLdnEqXt/qWgE6AnZx45Gnl6U+8QVUk8//bTa2to0depUFRQUhB8vv/xyeJ6f//zn+va3v6158+bpxhtvVDAY1G9/+9vw9CFDhmjDhg0aMmSISktLdfvtt+uOO+7Qo48+at63AuLAgApnMrtOrVhGLHfrcVkkSIr87ZSTNrxU9XT4DVVqxVPfZtWrFet1z7LRk4pPSn4nBe/ouYE5qbFNVWDSm0odr9QTAZUa9KQQofdIPyc1KKkIT86DWcvK+k3VpbF6/x8CKjH0pGAKJzWoXhlJ55XvEY9UfGd2MLyJnhT65dTzVBK9Kjdxyu1UkilHtM+kB5UcelJIWiLnqRL9/VH3+2J9LwHiDl4bZi59tV0QUKlDSGFA8QRVz+leaeCt/h5O66FiYIRT6hFSMEW0xtwrQYXEOC2AE10fWY/tRUhhUIP1pgbaiNnA4STxro8MM7dfwldBR3rpeSHaQYf6JnB1dUsvV2PhZ6Mvp9d3IjtOBJR9CCnEbLArpg+0IZtxG5B4Ob2x9BrqG1bgcB/i0juIukc6RXu9t1Qe+qPBTC2v1jcj+exHTwpxi3WjjdbzMvN+Tv3+Xws/W0rNd3CTWOvBKfVG6LgLPSlYKtUNQqoCqvffGJhT6o2Ach9CCpaz+9Cf09nds0hGomW3Y/kTUO5ESCEl+gsqMxurVDT2bg4Us8VTF73ntaoe+1unCCj34tp9SKkBRwdWx/lZPeb3Sni4pYfpxPru95p9BJQjxdqOE1KwxUBhFSsnNpSpkG73vkr0+xJOzhZrO87oPtiiuwExI6zSjVGdXFC5JaAIJ0iEFGwWb4Pi9FBL1TDrRIPKLQHVG8GTvhg4AVdxcmPllGHW/XFTQHHNPHQjpACLODGo3IaAAiEF10r3EIjnluxu7UUBhBRcJ5E7BqcztwYUvShIDJyAS8Vz65C4PtfEz0oVp5TZ1OVAQOHP6EnBtaxoyMy+Cka6IKBgFXpScDUzGrRow9rtuP+VVxAyMBMhhbTX3w+LnXJrCacL1xPhBAtwuA/4MxpZwHkIKQAJ4/wdrEZIAQAcy5XnpLov3B4KhWwuCTznZN+XYl7LknmvW/X4zmyPiEf3+jLYjThceauOgwcPqqioyO5iAACSdODAAV144YX9TndlSHV1damhoUHjxo3TgQMHuKdUEkKhkIqKiqhHE1CX5qAezePkujQMQ8ePH1dhYaEyMvo/8+TKw30ZGRn62te+Jkny+/2Oq3w3oh7NQ12ag3o0j1PrMhAIDDoPAycAAI5FSAEAHMu1IZWVlaUVK1YoKyvL7qK4GvVoHurSHNSjebxQl64cOAEASA+u7UkBALyPkAIAOBYhBQBwLEIKAOBYhBQAwLFcGVKrV6/WRRddpHPPPVclJSV6++237S6S41VXV8vn80U8xo4dG55+8uRJVVRUaMSIETr//PM1b948tbS02FhiZ9ixY4dmz56twsJC+Xw+rV+/PmK6YRhavny5CgoKNGzYMJWVlemTTz6JmOfYsWNasGCB/H6/cnJytGjRIrW3t6fwWzjDYHV555139llHZ86cGTEPdSnV1NRoypQpys7OVl5enubMmaOGhoaIeWLZnvfv369Zs2Zp+PDhysvL00MPPaTOzs5UfpWYuC6kXn75ZVVWVmrFihXau3evJk6cqBkzZujIkSN2F83xrrzySh0+fDj82LlzZ3jasmXL9Nprr+mVV17R9u3bdejQIc2dO9fG0jrDiRMnNHHiRK1evTrq9Mcee0xPPvmknnnmGe3evVvnnXeeZsyYoZMnz14efMGCBfrggw+0adMmbdiwQTt27NCSJUtS9RUcY7C6lKSZM2dGrKMvvvhixHTqUtq+fbsqKiq0a9cubdq0SadPn9b06dN14sSJ8DyDbc9nzpzRrFmzdOrUKb311lv69a9/rbVr12r58uV2fKWBGS5z7bXXGhUVFeHnZ86cMQoLC42amhobS+V8K1asMCZOnBh1WmtrqzF06FDjlVdeCb/20UcfGZKM2traFJXQ+SQZ69atCz/v6uoygsGg8fjjj4dfa21tNbKysowXX3zRMAzD+PDDDw1JxjvvvBOe5/XXXzd8Pp/xxz/+MWVld5redWkYhrFw4ULjlltu6fc91GV0R44cMSQZ27dvNwwjtu35v//7v42MjAyjubk5PM/TTz9t+P1+o6OjI7VfYBCu6kmdOnVKdXV1KisrC7+WkZGhsrIy1dbW2lgyd/jkk09UWFioiy++WAsWLND+/fslSXV1dTp9+nREvY4dO1ajR4+mXgfQ1NSk5ubmiHoLBAIqKSkJ11ttba1ycnJ0zTXXhOcpKytTRkaGdu/enfIyO922bduUl5enyy+/XPfee6+OHj0ankZdRtfW1iZJys3NlRTb9lxbW6urrrpK+fn54XlmzJihUCikDz74IIWlH5yrQupPf/qTzpw5E1GxkpSfn6/m5mabSuUOJSUlWrt2rTZu3Kinn35aTU1N+sY3vqHjx4+rublZmZmZysnJiXgP9Tqw7roZaH1sbm5WXl5exPRzzjlHubm51G0vM2fO1H/8x39o8+bN+ud//mdt375d5eXlOnPmjCTqMpquri7df//9uv766zV+/HhJiml7bm5ujrredk9zElfeqgPxKy8vD/89YcIElZSUaMyYMfrNb36jYcOG2Vgy4Cu33XZb+O+rrrpKEyZM0CWXXKJt27Zp2rRpNpbMuSoqKvT+++9HnF/2Glf1pEaOHKkhQ4b0GaXS0tKiYDBoU6ncKScnR5dddpkaGxsVDAZ16tQptba2RsxDvQ6su24GWh+DwWCfQT2dnZ06duwYdTuIiy++WCNHjlRjY6Mk6rK3pUuXasOGDdq6dWvEnW1j2Z6DwWDU9bZ7mpO4KqQyMzM1efJkbd68OfxaV1eXNm/erNLSUhtL5j7t7e369NNPVVBQoMmTJ2vo0KER9drQ0KD9+/dTrwMoLi5WMBiMqLdQKKTdu3eH6620tFStra2qq6sLz7NlyxZ1dXWppKQk5WV2k4MHD+ro0aMqKCiQRF12MwxDS5cu1bp167RlyxYVFxdHTI9ley4tLdUf/vCHiNDftGmT/H6/xo0bl5ovEiu7R27E66WXXjKysrKMtWvXGh9++KGxZMkSIycnJ2KUCvp64IEHjG3bthlNTU3Gm2++aZSVlRkjR440jhw5YhiGYdxzzz3G6NGjjS1bthh79uwxSktLjdLSUptLbb/jx48b7777rvHuu+8akownnnjCePfdd43PPvvMMAzDWLVqlZGTk2O8+uqrxnvvvWfccsstRnFxsfHll1+GP2PmzJnGpEmTjN27dxs7d+40Lr30UmP+/Pl2fSXbDFSXx48fNx588EGjtrbWaGpqMt544w3j6quvNi699FLj5MmT4c+gLg3j3nvvNQKBgLFt2zbj8OHD4ccXX3wRnmew7bmzs9MYP368MX36dKO+vt7YuHGjMWrUKKOqqsqOrzQg14WUYRjGU089ZYwePdrIzMw0rr32WmPXrl12F8nxbr31VqOgoMDIzMw0vva1rxm33nqr0djYGJ7+5ZdfGj/+8Y+NCy64wBg+fLjx3e9+1zh8+LCNJXaGrVu3GpL6PBYuXGgYxlfD0B955BEjPz/fyMrKMqZNm2Y0NDREfMbRo0eN+fPnG+eff77h9/uNu+66yzh+/LgN38ZeA9XlF198YUyfPt0YNWqUMXToUGPMmDHG4sWL++x8UpdG1DqUZKxZsyY8Tyzb8759+4zy8nJj2LBhxsiRI40HHnjAOH36dIq/zeC4nxQAwLFcdU4KAJBeCCkAgGMRUgAAxyKkAACORUgBAByLkAIAOBYhBQBwLEIKAOBYhBQAwLEIKQCAYxFSAADH+n+N7GwRm8OiiQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([-0.0058,  1.0587,  0.8064,  0.7614,  1.0901,  0.9573,  0.8626,  0.9790,\n",
      "         1.2164, -0.0241, -0.0013,  0.0055,  1.0071,  1.2495,  1.0169,  1.0134,\n",
      "         0.8628,  0.9762,  0.2192,  1.1007], device='cuda:0')\n",
      "真实的属性向量tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1.])\n",
      "真实标签为：D+EL+L+S\n",
      "欧式距离计算的标签为：D+EL+L+S\n",
      "余弦相似度计算的标签为：D+EL+L+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_four_wm_tensor, test_four_att_tensor, attri.four_defect_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor,test_single_att_tensor)\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor,test_two_att_tensor)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_three_dataset = MyDataSet(test_three_wm_tensor,test_three_att_tensor)\n",
    "test_three_loader = DataLoader(test_three_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_four_dataset = MyDataSet(test_four_wm_tensor,test_four_att_tensor)\n",
    "test_four_loader = DataLoader(test_four_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9570093457943926\n",
      "0.9653846153846154\n",
      "0.9225\n",
      "0.89125\n",
      "0.8926401080351114\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, attri.single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, attri.two_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, attri.three_defect_att, len(test_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_four_loader, attri.four_defect_att, len(test_four_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_loader, attri.total_defect_att, len(test_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
