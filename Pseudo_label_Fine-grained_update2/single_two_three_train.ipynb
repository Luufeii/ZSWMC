{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这里用单、二、三故障训练，然后对四故障进行打伪标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 52, 52]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 52, 52]) torch.Size([8400, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 224, 224]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 224, 224]) torch.Size([8400, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 9100\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "8400 8400\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_four_wm\n",
    "val_att = val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm + test_four_wm\n",
    "test_att = test_single_att + test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23110 400 7405\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "\n",
    "train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "val_dataset = MyDataSet(val_wm_tensor,val_att_tensor)\n",
    "test_dataset = MyDataSet(test_wm_tensor,test_att_tensor)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 13 232\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader),len(val_loader),len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor\n",
    "del val_wm_tensor,val_att_tensor\n",
    "del test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "# 替换第一个卷积以适应我们的单通道图像\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# 替换最后的全连接层以适配我们的属性输出\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(attri.att_name))\n",
    "model.add_module('sigmoid', nn.Sigmoid())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)  # 这个损失函数适用于每个样本可以属于多个类别的场景，这里的属性类似于多标签预测\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加正则化项\n",
    "def regularization_loss(model, lambda_reg):\n",
    "    l2_reg = 0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param) ** 2  # 计算L2范数的平方\n",
    "    return lambda_reg * l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100  # 训练迭代的次数，一个epoch把训练集过一遍\n",
    "lambda_reg = 0.01  # 正则化强度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间为：24.804362058639526, 总Loss:24030.33839416504\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:1.332440346479416\n",
      "第1轮训练后,整体验证集上的Accuracy:0.67\n",
      "————第2轮训练开始————\n",
      "训练时间为：22.323282957077026, 总Loss:20779.489391326904\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:0.8597697131335735\n",
      "第2轮训练后,整体验证集上的Accuracy:0.7875\n",
      "————第3轮训练开始————\n",
      "训练时间为：22.50121283531189, 总Loss:17977.632976531982\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:0.9782530926167965\n",
      "第3轮训练后,整体验证集上的Accuracy:0.74\n",
      "————第4轮训练开始————\n",
      "训练时间为：22.49122428894043, 总Loss:15554.69454574585\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:0.796798825263977\n",
      "第4轮训练后,整体验证集上的Accuracy:0.8925\n",
      "————第5轮训练开始————\n",
      "训练时间为：22.495537281036377, 总Loss:13458.79821395874\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:0.7292640022933483\n",
      "第5轮训练后,整体验证集上的Accuracy:0.885\n",
      "————第6轮训练开始————\n",
      "训练时间为：22.47903037071228, 总Loss:11645.765604019165\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:0.7058699503540993\n",
      "第6轮训练后,整体验证集上的Accuracy:0.8175\n",
      "————第7轮训练开始————\n",
      "训练时间为：22.48220443725586, 总Loss:10077.235036849976\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:0.7766434215009212\n",
      "第7轮训练后,整体验证集上的Accuracy:0.77\n",
      "————第8轮训练开始————\n",
      "训练时间为：22.501817226409912, 总Loss:8720.459707260132\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:0.6215604022145271\n",
      "第8轮训练后,整体验证集上的Accuracy:0.875\n",
      "————第9轮训练开始————\n",
      "训练时间为：22.500667095184326, 总Loss:7546.514337539673\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:0.7639544196426868\n",
      "第9轮训练后,整体验证集上的Accuracy:0.8175\n",
      "————第10轮训练开始————\n",
      "训练时间为：22.509986400604248, 总Loss:6531.049999237061\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:0.6902667544782162\n",
      "第10轮训练后,整体验证集上的Accuracy:0.8225\n",
      "————第11轮训练开始————\n",
      "训练时间为：22.49955940246582, 总Loss:5652.51287651062\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:0.6564370058476925\n",
      "第11轮训练后,整体验证集上的Accuracy:0.8725\n",
      "————第12轮训练开始————\n",
      "训练时间为：22.507561922073364, 总Loss:4892.469888687134\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:0.6107737515121698\n",
      "第12轮训练后,整体验证集上的Accuracy:0.8725\n",
      "————第13轮训练开始————\n",
      "训练时间为：22.49765944480896, 总Loss:4235.000938415527\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:0.6517165265977383\n",
      "第13轮训练后,整体验证集上的Accuracy:0.83\n",
      "————第14轮训练开始————\n",
      "训练时间为：22.50613045692444, 总Loss:3666.2698650360107\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:0.5621842164546251\n",
      "第14轮训练后,整体验证集上的Accuracy:0.895\n",
      "————第15轮训练开始————\n",
      "训练时间为：22.49140238761902, 总Loss:3174.3043212890625\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:0.5338951945304871\n",
      "第15轮训练后,整体验证集上的Accuracy:0.92\n",
      "————第16轮训练开始————\n",
      "训练时间为：22.49812602996826, 总Loss:2748.8668937683105\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:0.5562603119760752\n",
      "第16轮训练后,整体验证集上的Accuracy:0.9225\n",
      "————第17轮训练开始————\n",
      "训练时间为：22.497008562088013, 总Loss:2380.852199077606\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:0.6469715517014265\n",
      "第17轮训练后,整体验证集上的Accuracy:0.82\n",
      "————第18轮训练开始————\n",
      "训练时间为：22.492188453674316, 总Loss:2062.582407474518\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:0.5285007227212191\n",
      "第18轮训练后,整体验证集上的Accuracy:0.86\n",
      "————第19轮训练开始————\n",
      "训练时间为：22.493507385253906, 总Loss:1787.4846587181091\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:0.6627348884940147\n",
      "第19轮训练后,整体验证集上的Accuracy:0.875\n",
      "————第20轮训练开始————\n",
      "训练时间为：22.49873161315918, 总Loss:1549.6280417442322\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:0.7401680015027523\n",
      "第20轮训练后,整体验证集上的Accuracy:0.8325\n",
      "————第21轮训练开始————\n",
      "训练时间为：22.50840711593628, 总Loss:1344.0035898685455\n",
      "****第21轮训练结束****\n",
      "第21轮训练后,整体验证集上的Loss:0.6252346150577068\n",
      "第21轮训练后,整体验证集上的Accuracy:0.9\n",
      "————第22轮训练开始————\n",
      "训练时间为：22.49742293357849, 总Loss:1166.34530210495\n",
      "****第22轮训练结束****\n",
      "第22轮训练后,整体验证集上的Loss:0.7735687382519245\n",
      "第22轮训练后,整体验证集上的Accuracy:0.8475\n",
      "————第23轮训练开始————\n",
      "训练时间为：22.484009981155396, 总Loss:1012.9220283031464\n",
      "****第23轮训练结束****\n",
      "第23轮训练后,整体验证集上的Loss:0.8715282082557678\n",
      "第23轮训练后,整体验证集上的Accuracy:0.825\n",
      "————第24轮训练开始————\n",
      "训练时间为：22.490931272506714, 总Loss:880.3653650283813\n",
      "****第24轮训练结束****\n",
      "第24轮训练后,整体验证集上的Loss:0.7618257664144039\n",
      "第24轮训练后,整体验证集上的Accuracy:0.8575\n",
      "————第25轮训练开始————\n",
      "训练时间为：22.508025884628296, 总Loss:766.1033201217651\n",
      "****第25轮训练结束****\n",
      "第25轮训练后,整体验证集上的Loss:0.7589613944292068\n",
      "第25轮训练后,整体验证集上的Accuracy:0.8825\n",
      "————第26轮训练开始————\n",
      "训练时间为：22.500667572021484, 总Loss:667.5917171239853\n",
      "****第26轮训练结束****\n",
      "第26轮训练后,整体验证集上的Loss:0.6207939051091671\n",
      "第26轮训练后,整体验证集上的Accuracy:0.9125\n",
      "————第27轮训练开始————\n",
      "训练时间为：22.508156776428223, 总Loss:582.6429708003998\n",
      "****第27轮训练结束****\n",
      "第27轮训练后,整体验证集上的Loss:0.641284629702568\n",
      "第27轮训练后,整体验证集上的Accuracy:0.795\n",
      "————第28轮训练开始————\n",
      "训练时间为：22.498278379440308, 总Loss:509.6263254880905\n",
      "****第28轮训练结束****\n",
      "第28轮训练后,整体验证集上的Loss:0.5896674655377865\n",
      "第28轮训练后,整体验证集上的Accuracy:0.885\n",
      "————第29轮训练开始————\n",
      "训练时间为：22.49891424179077, 总Loss:446.7854439020157\n",
      "****第29轮训练结束****\n",
      "第29轮训练后,整体验证集上的Loss:0.6889688111841679\n",
      "第29轮训练后,整体验证集上的Accuracy:0.945\n",
      "————第30轮训练开始————\n",
      "训练时间为：22.499486923217773, 总Loss:392.75572526454926\n",
      "****第30轮训练结束****\n",
      "第30轮训练后,整体验证集上的Loss:0.5625300295650959\n",
      "第30轮训练后,整体验证集上的Accuracy:0.8875\n",
      "————第31轮训练开始————\n",
      "训练时间为：22.502150535583496, 总Loss:346.38440907001495\n",
      "****第31轮训练结束****\n",
      "第31轮训练后,整体验证集上的Loss:1.2750068753957748\n",
      "第31轮训练后,整体验证集上的Accuracy:0.89\n",
      "————第32轮训练开始————\n",
      "训练时间为：22.489868640899658, 总Loss:306.49165111780167\n",
      "****第32轮训练结束****\n",
      "第32轮训练后,整体验证集上的Loss:0.8756245225667953\n",
      "第32轮训练后,整体验证集上的Accuracy:0.8375\n",
      "————第33轮训练开始————\n",
      "训练时间为：22.50505018234253, 总Loss:272.317302107811\n",
      "****第33轮训练结束****\n",
      "第33轮训练后,整体验证集上的Loss:1.6021469756960869\n",
      "第33轮训练后,整体验证集上的Accuracy:0.8825\n",
      "————第34轮训练开始————\n",
      "训练时间为：22.49685835838318, 总Loss:243.0591335296631\n",
      "****第34轮训练结束****\n",
      "第34轮训练后,整体验证集上的Loss:2.4871368259191513\n",
      "第34轮训练后,整体验证集上的Accuracy:0.76\n",
      "————第35轮训练开始————\n",
      "训练时间为：22.503413200378418, 总Loss:217.78337436914444\n",
      "****第35轮训练结束****\n",
      "第35轮训练后,整体验证集上的Loss:1.8680372685194016\n",
      "第35轮训练后,整体验证集上的Accuracy:0.6975\n",
      "————第36轮训练开始————\n",
      "训练时间为：22.501006603240967, 总Loss:196.01056718826294\n",
      "****第36轮训练结束****\n",
      "第36轮训练后,整体验证集上的Loss:2.634205140173435\n",
      "第36轮训练后,整体验证集上的Accuracy:0.64\n",
      "————第37轮训练开始————\n",
      "训练时间为：22.508137702941895, 总Loss:177.41241911053658\n",
      "****第37轮训练结束****\n",
      "第37轮训练后,整体验证集上的Loss:0.5788509882986546\n",
      "第37轮训练后,整体验证集上的Accuracy:0.925\n",
      "————第38轮训练开始————\n",
      "训练时间为：22.50055193901062, 总Loss:161.25611689686775\n",
      "****第38轮训练结束****\n",
      "第38轮训练后,整体验证集上的Loss:0.7495538108050823\n",
      "第38轮训练后,整体验证集上的Accuracy:0.9425\n",
      "————第39轮训练开始————\n",
      "训练时间为：22.504927158355713, 总Loss:147.37424093484879\n",
      "****第39轮训练结束****\n",
      "第39轮训练后,整体验证集上的Loss:6.6349117159843445\n",
      "第39轮训练后,整体验证集上的Accuracy:0.795\n",
      "————第40轮训练开始————\n",
      "训练时间为：22.501579523086548, 总Loss:135.34014642238617\n",
      "****第40轮训练结束****\n",
      "第40轮训练后,整体验证集上的Loss:1.0282383151352406\n",
      "第40轮训练后,整体验证集上的Accuracy:0.35\n",
      "————第41轮训练开始————\n",
      "训练时间为：22.4732723236084, 总Loss:124.87914490699768\n",
      "****第41轮训练结束****\n",
      "第41轮训练后,整体验证集上的Loss:2.366825133562088\n",
      "第41轮训练后,整体验证集上的Accuracy:0.6725\n",
      "————第42轮训练开始————\n",
      "训练时间为：22.510074853897095, 总Loss:115.83905991911888\n",
      "****第42轮训练结束****\n",
      "第42轮训练后,整体验证集上的Loss:4.2724589407444\n",
      "第42轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第43轮训练开始————\n",
      "训练时间为：22.49672293663025, 总Loss:108.14504307508469\n",
      "****第43轮训练结束****\n",
      "第43轮训练后,整体验证集上的Loss:2.9462177753448486\n",
      "第43轮训练后,整体验证集上的Accuracy:0.4025\n",
      "————第44轮训练开始————\n",
      "训练时间为：22.512112140655518, 总Loss:101.19940999150276\n",
      "****第44轮训练结束****\n",
      "第44轮训练后,整体验证集上的Loss:3.8789272606372833\n",
      "第44轮训练后,整体验证集上的Accuracy:0.2925\n",
      "————第45轮训练开始————\n",
      "训练时间为：22.50939631462097, 总Loss:95.20134499669075\n",
      "****第45轮训练结束****\n",
      "第45轮训练后,整体验证集上的Loss:0.785377636551857\n",
      "第45轮训练后,整体验证集上的Accuracy:0.8775\n",
      "————第46轮训练开始————\n",
      "训练时间为：22.607966899871826, 总Loss:89.70033970475197\n",
      "****第46轮训练结束****\n",
      "第46轮训练后,整体验证集上的Loss:2.0234449431300163\n",
      "第46轮训练后,整体验证集上的Accuracy:0.4075\n",
      "————第47轮训练开始————\n",
      "训练时间为：22.51130509376526, 总Loss:85.32480412721634\n",
      "****第47轮训练结束****\n",
      "第47轮训练后,整体验证集上的Loss:0.9201739951968193\n",
      "第47轮训练后,整体验证集上的Accuracy:0.7575\n",
      "————第48轮训练开始————\n",
      "训练时间为：22.497158527374268, 总Loss:81.1408592313528\n",
      "****第48轮训练结束****\n",
      "第48轮训练后,整体验证集上的Loss:0.8180681616067886\n",
      "第48轮训练后,整体验证集上的Accuracy:0.8825\n",
      "————第49轮训练开始————\n",
      "训练时间为：22.519939422607422, 总Loss:77.69945707917213\n",
      "****第49轮训练结束****\n",
      "第49轮训练后,整体验证集上的Loss:0.6840416304767132\n",
      "第49轮训练后,整体验证集上的Accuracy:0.8675\n",
      "————第50轮训练开始————\n",
      "训练时间为：22.495825052261353, 总Loss:74.6322603225708\n",
      "****第50轮训练结束****\n",
      "第50轮训练后,整体验证集上的Loss:0.7592677585780621\n",
      "第50轮训练后,整体验证集上的Accuracy:0.765\n",
      "————第51轮训练开始————\n",
      "训练时间为：22.51125955581665, 总Loss:71.88612695038319\n",
      "****第51轮训练结束****\n",
      "第51轮训练后,整体验证集上的Loss:2.058688499033451\n",
      "第51轮训练后,整体验证集上的Accuracy:0.2875\n",
      "————第52轮训练开始————\n",
      "训练时间为：22.503157377243042, 总Loss:69.57593168318272\n",
      "****第52轮训练结束****\n",
      "第52轮训练后,整体验证集上的Loss:1.258082576096058\n",
      "第52轮训练后,整体验证集上的Accuracy:0.575\n",
      "————第53轮训练开始————\n",
      "训练时间为：22.509825706481934, 总Loss:67.44777530431747\n",
      "****第53轮训练结束****\n",
      "第53轮训练后,整体验证集上的Loss:0.6268410570919514\n",
      "第53轮训练后,整体验证集上的Accuracy:0.9075\n",
      "————第54轮训练开始————\n",
      "训练时间为：22.50744080543518, 总Loss:65.91121082007885\n",
      "****第54轮训练结束****\n",
      "第54轮训练后,整体验证集上的Loss:2.0762457102537155\n",
      "第54轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第55轮训练开始————\n",
      "训练时间为：22.50639772415161, 总Loss:64.68954461812973\n",
      "****第55轮训练结束****\n",
      "第55轮训练后,整体验证集上的Loss:3.157398506999016\n",
      "第55轮训练后,整体验证集上的Accuracy:0.6075\n",
      "————第56轮训练开始————\n",
      "训练时间为：22.505927801132202, 总Loss:63.315283447504044\n",
      "****第56轮训练结束****\n",
      "第56轮训练后,整体验证集上的Loss:0.7597421370446682\n",
      "第56轮训练后,整体验证集上的Accuracy:0.8625\n",
      "————第57轮训练开始————\n",
      "训练时间为：22.5136661529541, 总Loss:61.57530216872692\n",
      "****第57轮训练结束****\n",
      "第57轮训练后,整体验证集上的Loss:1.1769087836146355\n",
      "第57轮训练后,整体验证集上的Accuracy:0.835\n",
      "————第58轮训练开始————\n",
      "训练时间为：22.506286144256592, 总Loss:61.24784833192825\n",
      "****第58轮训练结束****\n",
      "第58轮训练后,整体验证集上的Loss:7.178116053342819\n",
      "第58轮训练后,整体验证集上的Accuracy:0.235\n",
      "————第59轮训练开始————\n",
      "训练时间为：22.50602889060974, 总Loss:60.19974894821644\n",
      "****第59轮训练结束****\n",
      "第59轮训练后,整体验证集上的Loss:2.397531643509865\n",
      "第59轮训练后,整体验证集上的Accuracy:0.57\n",
      "————第60轮训练开始————\n",
      "训练时间为：22.51033926010132, 总Loss:58.89466172456741\n",
      "****第60轮训练结束****\n",
      "第60轮训练后,整体验证集上的Loss:1.7030918076634407\n",
      "第60轮训练后,整体验证集上的Accuracy:0.4875\n",
      "————第61轮训练开始————\n",
      "训练时间为：22.49942946434021, 总Loss:58.51137898862362\n",
      "****第61轮训练结束****\n",
      "第61轮训练后,整体验证集上的Loss:1.2615076452493668\n",
      "第61轮训练后,整体验证集上的Accuracy:0.575\n",
      "————第62轮训练开始————\n",
      "训练时间为：22.506715059280396, 总Loss:57.509988725185394\n",
      "****第62轮训练结束****\n",
      "第62轮训练后,整体验证集上的Loss:8.171836495399475\n",
      "第62轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第63轮训练开始————\n",
      "训练时间为：22.505876779556274, 总Loss:58.45382380485535\n",
      "****第63轮训练结束****\n",
      "第63轮训练后,整体验证集上的Loss:2.3704082518815994\n",
      "第63轮训练后,整体验证集上的Accuracy:0.31\n",
      "————第64轮训练开始————\n",
      "训练时间为：22.500697135925293, 总Loss:56.43493628501892\n",
      "****第64轮训练结束****\n",
      "第64轮训练后,整体验证集上的Loss:0.8321185521781445\n",
      "第64轮训练后,整体验证集上的Accuracy:0.7975\n",
      "————第65轮训练开始————\n",
      "训练时间为：22.503977298736572, 总Loss:55.945694744586945\n",
      "****第65轮训练结束****\n",
      "第65轮训练后,整体验证集上的Loss:2.3270886689424515\n",
      "第65轮训练后,整体验证集上的Accuracy:0.57\n",
      "————第66轮训练开始————\n",
      "训练时间为：22.49802327156067, 总Loss:55.47821427881718\n",
      "****第66轮训练结束****\n",
      "第66轮训练后,整体验证集上的Loss:1.5403876602649689\n",
      "第66轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第67轮训练开始————\n",
      "训练时间为：22.504669189453125, 总Loss:55.846319913864136\n",
      "****第67轮训练结束****\n",
      "第67轮训练后,整体验证集上的Loss:0.8566485047340393\n",
      "第67轮训练后,整体验证集上的Accuracy:0.8975\n",
      "————第68轮训练开始————\n",
      "训练时间为：22.497796058654785, 总Loss:55.229071378707886\n",
      "****第68轮训练结束****\n",
      "第68轮训练后,整体验证集上的Loss:0.9830682389438152\n",
      "第68轮训练后,整体验证集上的Accuracy:0.375\n",
      "————第69轮训练开始————\n",
      "训练时间为：22.50665521621704, 总Loss:54.537839353084564\n",
      "****第69轮训练结束****\n",
      "第69轮训练后,整体验证集上的Loss:0.6476444490253925\n",
      "第69轮训练后,整体验证集上的Accuracy:0.9575\n",
      "————第70轮训练开始————\n",
      "训练时间为：22.49905014038086, 总Loss:54.17212188243866\n",
      "****第70轮训练结束****\n",
      "第70轮训练后,整体验证集上的Loss:0.7181008458137512\n",
      "第70轮训练后,整体验证集上的Accuracy:0.84\n",
      "————第71轮训练开始————\n",
      "训练时间为：22.4937105178833, 总Loss:53.87929958105087\n",
      "****第71轮训练结束****\n",
      "第71轮训练后,整体验证集上的Loss:4.719557911157608\n",
      "第71轮训练后,整体验证集上的Accuracy:0.2375\n",
      "————第72轮训练开始————\n",
      "训练时间为：22.501218557357788, 总Loss:53.9526496976614\n",
      "****第72轮训练结束****\n",
      "第72轮训练后,整体验证集上的Loss:1.1551537439227104\n",
      "第72轮训练后,整体验证集上的Accuracy:0.5275\n",
      "————第73轮训练开始————\n",
      "训练时间为：22.501339435577393, 总Loss:54.49154369533062\n",
      "****第73轮训练结束****\n",
      "第73轮训练后,整体验证集上的Loss:3.6239036172628403\n",
      "第73轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第74轮训练开始————\n",
      "训练时间为：22.512321710586548, 总Loss:53.458701848983765\n",
      "****第74轮训练结束****\n",
      "第74轮训练后,整体验证集上的Loss:1.1797317191958427\n",
      "第74轮训练后,整体验证集上的Accuracy:0.815\n",
      "————第75轮训练开始————\n",
      "训练时间为：22.504116535186768, 总Loss:53.02953523397446\n",
      "****第75轮训练结束****\n",
      "第75轮训练后,整体验证集上的Loss:0.7529821321368217\n",
      "第75轮训练后,整体验证集上的Accuracy:0.74\n",
      "————第76轮训练开始————\n",
      "训练时间为：22.5068039894104, 总Loss:52.819655418395996\n",
      "****第76轮训练结束****\n",
      "第76轮训练后,整体验证集上的Loss:0.7445483058691025\n",
      "第76轮训练后,整体验证集上的Accuracy:0.9175\n",
      "————第77轮训练开始————\n",
      "训练时间为：22.50825023651123, 总Loss:52.920085072517395\n",
      "****第77轮训练结束****\n",
      "第77轮训练后,整体验证集上的Loss:0.6069107502698898\n",
      "第77轮训练后,整体验证集上的Accuracy:0.95\n",
      "————第78轮训练开始————\n",
      "训练时间为：22.508814811706543, 总Loss:52.61463451385498\n",
      "****第78轮训练结束****\n",
      "第78轮训练后,整体验证集上的Loss:1.363268829882145\n",
      "第78轮训练后,整体验证集上的Accuracy:0.275\n",
      "————第79轮训练开始————\n",
      "训练时间为：22.498818397521973, 总Loss:52.66267108917236\n",
      "****第79轮训练结束****\n",
      "第79轮训练后,整体验证集上的Loss:1.8707293793559074\n",
      "第79轮训练后,整体验证集上的Accuracy:0.745\n",
      "————第80轮训练开始————\n",
      "训练时间为：22.512166500091553, 总Loss:52.38964785635471\n",
      "****第80轮训练结束****\n",
      "第80轮训练后,整体验证集上的Loss:1.1109411157667637\n",
      "第80轮训练后,整体验证集上的Accuracy:0.44\n",
      "————第81轮训练开始————\n",
      "训练时间为：22.50635838508606, 总Loss:52.18126837909222\n",
      "****第81轮训练结束****\n",
      "第81轮训练后,整体验证集上的Loss:0.6614109762012959\n",
      "第81轮训练后,整体验证集上的Accuracy:0.6975\n",
      "————第82轮训练开始————\n",
      "训练时间为：22.50915217399597, 总Loss:53.849984124302864\n",
      "****第82轮训练结束****\n",
      "第82轮训练后,整体验证集上的Loss:1.2239465788006783\n",
      "第82轮训练后,整体验证集上的Accuracy:0.565\n",
      "————第83轮训练开始————\n",
      "训练时间为：22.507800817489624, 总Loss:52.01532809436321\n",
      "****第83轮训练结束****\n",
      "第83轮训练后,整体验证集上的Loss:2.6619847491383553\n",
      "第83轮训练后,整体验证集上的Accuracy:0.27\n",
      "————第84轮训练开始————\n",
      "训练时间为：22.50336766242981, 总Loss:51.954399436712265\n",
      "****第84轮训练结束****\n",
      "第84轮训练后,整体验证集上的Loss:3.33304226398468\n",
      "第84轮训练后,整体验证集上的Accuracy:0.205\n",
      "————第85轮训练开始————\n",
      "训练时间为：22.505320072174072, 总Loss:52.41221618652344\n",
      "****第85轮训练结束****\n",
      "第85轮训练后,整体验证集上的Loss:0.8605522774159908\n",
      "第85轮训练后,整体验证集上的Accuracy:0.635\n",
      "————第86轮训练开始————\n",
      "训练时间为：22.493069171905518, 总Loss:51.60430993139744\n",
      "****第86轮训练结束****\n",
      "第86轮训练后,整体验证集上的Loss:0.6595864444971085\n",
      "第86轮训练后,整体验证集上的Accuracy:0.84\n",
      "————第87轮训练开始————\n",
      "训练时间为：22.503690242767334, 总Loss:51.55418288707733\n",
      "****第87轮训练结束****\n",
      "第87轮训练后,整体验证集上的Loss:3.727237120270729\n",
      "第87轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第88轮训练开始————\n",
      "训练时间为：22.513489484786987, 总Loss:52.705803751945496\n",
      "****第88轮训练结束****\n",
      "第88轮训练后,整体验证集上的Loss:0.9496289566159248\n",
      "第88轮训练后,整体验证集上的Accuracy:0.6225\n",
      "————第89轮训练开始————\n",
      "训练时间为：22.505926370620728, 总Loss:51.42880128324032\n",
      "****第89轮训练结束****\n",
      "第89轮训练后,整体验证集上的Loss:1.9438666626811028\n",
      "第89轮训练后,整体验证集上的Accuracy:0.245\n",
      "————第90轮训练开始————\n",
      "训练时间为：22.500706434249878, 总Loss:52.18250586092472\n",
      "****第90轮训练结束****\n",
      "第90轮训练后,整体验证集上的Loss:1.4473283737897873\n",
      "第90轮训练后,整体验证集上的Accuracy:0.255\n",
      "————第91轮训练开始————\n",
      "训练时间为：22.50624418258667, 总Loss:51.37526452541351\n",
      "****第91轮训练结束****\n",
      "第91轮训练后,整体验证集上的Loss:0.7161474972963333\n",
      "第91轮训练后,整体验证集上的Accuracy:0.8825\n",
      "————第92轮训练开始————\n",
      "训练时间为：22.50240683555603, 总Loss:51.11198724806309\n",
      "****第92轮训练结束****\n",
      "第92轮训练后,整体验证集上的Loss:2.46689373254776\n",
      "第92轮训练后,整体验证集上的Accuracy:0.25\n",
      "————第93轮训练开始————\n",
      "训练时间为：22.510300397872925, 总Loss:51.219802752137184\n",
      "****第93轮训练结束****\n",
      "第93轮训练后,整体验证集上的Loss:0.7525516077876091\n",
      "第93轮训练后,整体验证集上的Accuracy:0.6825\n",
      "————第94轮训练开始————\n",
      "训练时间为：22.50560474395752, 总Loss:51.07240556180477\n",
      "****第94轮训练结束****\n",
      "第94轮训练后,整体验证集上的Loss:2.4243325293064117\n",
      "第94轮训练后,整体验证集上的Accuracy:0.4875\n",
      "————第95轮训练开始————\n",
      "训练时间为：22.504910707473755, 总Loss:55.23583035171032\n",
      "****第95轮训练结束****\n",
      "第95轮训练后,整体验证集上的Loss:2.272893413901329\n",
      "第95轮训练后,整体验证集上的Accuracy:0.2675\n",
      "————第96轮训练开始————\n",
      "训练时间为：22.51088523864746, 总Loss:51.00718814134598\n",
      "****第96轮训练结束****\n",
      "第96轮训练后,整体验证集上的Loss:1.193515032529831\n",
      "第96轮训练后,整体验证集上的Accuracy:0.4625\n",
      "————第97轮训练开始————\n",
      "训练时间为：22.511179208755493, 总Loss:51.79414339363575\n",
      "****第97轮训练结束****\n",
      "第97轮训练后,整体验证集上的Loss:1.674051709473133\n",
      "第97轮训练后,整体验证集上的Accuracy:0.45\n",
      "————第98轮训练开始————\n",
      "训练时间为：22.508772611618042, 总Loss:51.0303450524807\n",
      "****第98轮训练结束****\n",
      "第98轮训练后,整体验证集上的Loss:0.9880225658416748\n",
      "第98轮训练后,整体验证集上的Accuracy:0.76\n",
      "————第99轮训练开始————\n",
      "训练时间为：22.506739854812622, 总Loss:50.858423575758934\n",
      "****第99轮训练结束****\n",
      "第99轮训练后,整体验证集上的Loss:0.9440852962434292\n",
      "第99轮训练后,整体验证集上的Accuracy:0.78\n",
      "————第100轮训练开始————\n",
      "训练时间为：22.506044626235962, 总Loss:51.17656992375851\n",
      "****第100轮训练结束****\n",
      "第100轮训练后,整体验证集上的Loss:5.339372038841248\n",
      "第100轮训练后,整体验证集上的Accuracy:0.25\n",
      "训练结束，第69轮的模型在验证集上准确率最高，为0.9575\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for i in range(epochs):\n",
    "    # total_train_steps = 0\n",
    "    print(f'————第{i+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels) + regularization_loss(model, lambda_reg)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{i+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for data_v in val_loader:  \n",
    "            imgs,labels = data_v\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model,val_loader,attri.four_defect_att,val_size,'cos')\n",
    "    print(f'第{i+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{i+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:  # 我们在这里保存准确率最高的模型\n",
    "        best_acc = acc\n",
    "        No = i+1\n",
    "        torch.save(obj=model,f='model_saved_pseudo/train_single_two_three.pth')\n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('model_saved_pseudo/train_single_two_three.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(np.array(test_single_wm), dtype=torch.float32)\n",
    "test_single_att_tensor = torch.tensor(np.array(test_single_att), dtype=torch.float32)\n",
    "\n",
    "test_two_wm_tensor = torch.tensor(np.array(test_two_wm), dtype=torch.float32)\n",
    "test_two_att_tensor = torch.tensor(np.array(test_two_att), dtype=torch.float32)\n",
    "\n",
    "test_three_wm_tensor = torch.tensor(np.array(test_three_wm), dtype=torch.float32)\n",
    "test_three_att_tensor = torch.tensor(np.array(test_three_att), dtype=torch.float32)\n",
    "\n",
    "test_four_wm_tensor = torch.tensor(np.array(test_four_wm), dtype=torch.float32)\n",
    "test_four_att_tensor = torch.tensor(np.array(test_four_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([ 0.1212,  0.7122,  0.6782,  0.7176,  1.0872,  0.9592,  0.7463,  0.8676,\n",
      "         1.1251, -0.0218, -0.0032, -0.0181,  0.7554,  1.1927,  0.7563,  0.9145,\n",
      "         0.7463,  0.8677,  0.3372,  0.9084], device='cuda:0')\n",
      "真实的属性向量tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1.])\n",
      "真实标签为：D+EL+L+S\n",
      "欧式距离计算的标签为：D+EL+L+S\n",
      "余弦相似度计算的标签为：D+EL+L+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_four_wm_tensor, test_four_att_tensor, attri.four_defect_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor,test_single_att_tensor)\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor,test_two_att_tensor)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_three_dataset = MyDataSet(test_three_wm_tensor,test_three_att_tensor)\n",
    "test_three_loader = DataLoader(test_three_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_four_dataset = MyDataSet(test_four_wm_tensor,test_four_att_tensor)\n",
    "test_four_loader = DataLoader(test_four_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7258566978193146\n",
      "0.9492307692307692\n",
      "0.9275\n",
      "0.93375\n",
      "0.8064821066846726\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, attri.single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, attri.two_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, attri.three_defect_att, len(test_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_four_loader, attri.four_defect_att, len(test_four_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_loader, attri.total_defect_att, len(test_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
