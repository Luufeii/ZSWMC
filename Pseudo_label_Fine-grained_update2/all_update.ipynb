{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们只迭代更新映射层(全连接层)和语义属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.M_attri import Att\n",
    "from py_file.Get_Data import DATA\n",
    "from py_file.data_set import MyDataSet\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Resize(224)  # ResNet模型适合的图片大小为224x244\n",
    "# 输入的张量需要带着批次维度和通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri = Att()\n",
    "attri.compute_mul_defect_att()\n",
    "\n",
    "train_data_path = '/mnt/workspace/DATA/train_WM.npz'\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "pseudo_two_data_path = 'data_fake_label/two_fake_label_WM.npz' \n",
    "pseudo_two_data = np.load(pseudo_two_data_path)\n",
    "\n",
    "pseudo_three_data_path = 'data_fake_label/three_fake_label_WM.npz' \n",
    "pseudo_three_data = np.load(pseudo_three_data_path)\n",
    "\n",
    "pseudo_four_data_path = 'data_fake_label/four_fake_label_WM.npz' \n",
    "pseudo_four_data = np.load(pseudo_four_data_path)\n",
    "\n",
    "val_data_path = '/mnt/workspace/DATA/val_WM.npz'\n",
    "val_data = np.load(val_data_path)\n",
    "\n",
    "test_data_path = '/mnt/workspace/DATA/test_WM.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "att_dimen = len(attri.att_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换为对应的属性向量\n",
    "train_label = train_data['label_name']\n",
    "pseudo_two_label = pseudo_two_data['label_name']\n",
    "pseudo_three_label = pseudo_three_data['label_name']\n",
    "pseudo_four_label = pseudo_four_data['label_name']\n",
    "val_label = val_data['label_name']\n",
    "test_label = test_data['label_name']\n",
    "\n",
    "train_att_vector = []\n",
    "pseudo_two_att_vector = []\n",
    "pseudo_three_att_vector = []\n",
    "pseudo_four_att_vector = []\n",
    "val_att_vector = []\n",
    "test_att_vector = []\n",
    "\n",
    "for l in train_data['label_name']:\n",
    "    train_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_two_data['label_name']:\n",
    "    pseudo_two_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_three_data['label_name']:\n",
    "    pseudo_three_att_vector.append(attri.total_defect_att[l])\n",
    "for l in pseudo_four_data['label_name']:\n",
    "    pseudo_four_att_vector.append(attri.total_defect_att[l])\n",
    "for l in val_data['label_name']:\n",
    "    val_att_vector.append(attri.total_defect_att[l])\n",
    "for l in test_data['label_name']:\n",
    "    test_att_vector.append(attri.total_defect_att[l])\n",
    "\n",
    "train_att_vector = np.array(train_att_vector)  # 因为np.array没有append方法，所以先使用list通过append添加元素，然后再将list转换为np.array\n",
    "pseudo_two_att_vector = np.array(pseudo_two_att_vector)\n",
    "pseudo_three_att_vector = np.array(pseudo_three_att_vector)\n",
    "pseudo_four_att_vector = np.array(pseudo_four_att_vector)\n",
    "val_att_vector = np.array(val_att_vector)\n",
    "test_att_vector = np.array(test_att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 52, 52]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 52, 52]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 52, 52]) torch.Size([8400, 20])\n",
      "torch.Size([2800, 1, 52, 52]) torch.Size([2800, 20])\n",
      "torch.Size([3700, 1, 52, 52]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 52, 52]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm = train_data['denoise_wm']\n",
    "train_wm_tensor = torch.reshape(torch.tensor(train_wm, dtype=torch.float32),(len(train_wm),1,52,52))\n",
    "train_att_tensor = torch.tensor(train_att_vector, dtype=torch.float32)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "\n",
    "pseudo_two_wm = pseudo_two_data['denoise_wm']\n",
    "pseudo_two_wm_tensor = torch.reshape(torch.tensor(pseudo_two_wm, dtype=torch.float32),(len(pseudo_two_wm),1,52,52))\n",
    "pseudo_two_att_tensor = torch.tensor(pseudo_two_att_vector, dtype=torch.float32)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "\n",
    "pseudo_three_wm = pseudo_three_data['denoise_wm']\n",
    "pseudo_three_wm_tensor = torch.reshape(torch.tensor(pseudo_three_wm, dtype=torch.float32),(len(pseudo_three_wm),1,52,52))\n",
    "pseudo_three_att_tensor = torch.tensor(pseudo_three_att_vector, dtype=torch.float32)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "\n",
    "pseudo_four_wm = pseudo_four_data['denoise_wm']\n",
    "pseudo_four_wm_tensor = torch.reshape(torch.tensor(pseudo_four_wm, dtype=torch.float32),(len(pseudo_four_wm),1,52,52))\n",
    "pseudo_four_att_tensor = torch.tensor(pseudo_four_att_vector, dtype=torch.float32)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "\n",
    "val_wm = val_data['denoise_wm']\n",
    "val_wm_tensor = torch.reshape(torch.tensor(val_wm, dtype=torch.float32),(len(val_wm),1,52,52))\n",
    "val_att_tensor = torch.tensor(val_att_vector, dtype=torch.float32)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "\n",
    "test_wm = test_data['denoise_wm']\n",
    "test_wm_tensor = torch.reshape(torch.tensor(test_wm, dtype=torch.float32),(len(test_wm),1,52,52))\n",
    "test_att_tensor = torch.tensor(test_att_vector, dtype=torch.float32)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25910, 1, 224, 224]) torch.Size([25910, 20])\n",
      "torch.Size([9100, 1, 224, 224]) torch.Size([9100, 20])\n",
      "torch.Size([8400, 1, 224, 224]) torch.Size([8400, 20])\n",
      "torch.Size([2800, 1, 224, 224]) torch.Size([2800, 20])\n",
      "torch.Size([3700, 1, 224, 224]) torch.Size([3700, 20])\n",
      "torch.Size([7405, 1, 224, 224]) torch.Size([7405, 20])\n"
     ]
    }
   ],
   "source": [
    "train_wm_tensor = trans(train_wm_tensor)  # 修改图片大小，以适应网络输入\n",
    "pseudo_two_wm_tensor = trans(pseudo_two_wm_tensor)\n",
    "pseudo_three_wm_tensor = trans(pseudo_three_wm_tensor)\n",
    "pseudo_four_wm_tensor = trans(pseudo_four_wm_tensor)\n",
    "val_wm_tensor = trans(val_wm_tensor)\n",
    "test_wm_tensor = trans(test_wm_tensor)\n",
    "print(train_wm_tensor.shape, train_att_tensor.shape)\n",
    "print(pseudo_two_wm_tensor.shape, pseudo_two_att_tensor.shape)\n",
    "print(pseudo_three_wm_tensor.shape, pseudo_three_att_tensor.shape)\n",
    "print(pseudo_four_wm_tensor.shape, pseudo_four_att_tensor.shape)\n",
    "print(val_wm_tensor.shape, val_att_tensor.shape)\n",
    "print(test_wm_tensor.shape, test_att_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 9100\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "8400 8400\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n",
      "2800 2800\n",
      "torch.Size([1, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 转换为列表的形式，方便后续拼接\n",
    "pseudo_two_wm = list(pseudo_two_wm_tensor)\n",
    "pseudo_two_label = list(pseudo_two_label)\n",
    "pseudo_two_att = list(pseudo_two_att_tensor)\n",
    "print(len(pseudo_two_wm),len(pseudo_two_att))\n",
    "print(pseudo_two_wm[10].shape,pseudo_two_att[10].shape)\n",
    "\n",
    "pseudo_three_wm = list(pseudo_three_wm_tensor)\n",
    "pseudo_three_label = list(pseudo_three_label)\n",
    "pseudo_three_att = list(pseudo_three_att_tensor)\n",
    "print(len(pseudo_three_wm),len(pseudo_three_att))\n",
    "print(pseudo_three_wm[10].shape, pseudo_three_att[10].shape)\n",
    "\n",
    "pseudo_four_wm = list(pseudo_four_wm_tensor)\n",
    "pseudo_four_label = list(pseudo_four_label)\n",
    "pseudo_four_att = list(pseudo_four_att_tensor)\n",
    "print(len(pseudo_four_wm),len(pseudo_four_att))\n",
    "print(pseudo_four_wm[10].shape, pseudo_four_att[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pseudo_two_wm_tensor, pseudo_two_att_tensor, pseudo_three_wm_tensor, pseudo_three_att_tensor, pseudo_four_wm_tensor, pseudo_four_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_oh = train_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "train_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "train_single_label = []\n",
    "train_single_att = []\n",
    "\n",
    "train_two_wm = []\n",
    "train_two_label = []\n",
    "train_two_att = []\n",
    "\n",
    "train_three_wm = []\n",
    "train_three_label = []\n",
    "train_three_att = []\n",
    "\n",
    "train_four_wm = []\n",
    "train_four_label = []\n",
    "train_four_att = []\n",
    "for i in range(len(train_label_oh)):\n",
    "    if train_label_oh[i].sum() <= 1:\n",
    "        train_single_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_single_label.append(train_label[i])\n",
    "        train_single_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 2:\n",
    "        train_two_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_two_label.append(train_label[i])\n",
    "        train_two_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 3:\n",
    "        train_three_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_three_label.append(train_label[i])\n",
    "        train_three_att.append(np.array(train_att_tensor[i]))\n",
    "    elif train_label_oh[i].sum() == 4:\n",
    "        train_four_wm.append(np.array(train_wm_tensor[i]))\n",
    "        train_four_label.append(train_label[i])\n",
    "        train_four_att.append(np.array(train_att_tensor[i]))\n",
    "\n",
    "del train_data,train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_oh = val_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "val_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "val_single_label = []\n",
    "val_single_att = []\n",
    "\n",
    "val_two_wm = []\n",
    "val_two_label = []\n",
    "val_two_att = []\n",
    "\n",
    "val_three_wm = []\n",
    "val_three_label = []\n",
    "val_three_att = []\n",
    "\n",
    "val_four_wm = []\n",
    "val_four_label = []\n",
    "val_four_att = []\n",
    "\n",
    "for i in range(len(val_label_oh)):\n",
    "    if val_label_oh[i].sum() <= 1:\n",
    "        val_single_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_single_label.append(val_label[i])\n",
    "        val_single_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 2:\n",
    "        val_two_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_two_label.append(val_label[i])\n",
    "        val_two_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 3:\n",
    "        val_three_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_three_label.append(val_label[i])\n",
    "        val_three_att.append(np.array(val_att_tensor[i]))\n",
    "    elif val_label_oh[i].sum() == 4:\n",
    "        val_four_wm.append(np.array(val_wm_tensor[i]))\n",
    "        val_four_label.append(val_label[i])\n",
    "        val_four_att.append(np.array(val_att_tensor[i]))\n",
    "\n",
    "del val_data,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_oh = test_data['label_one_hot']\n",
    "# 通过one_hot标签给数据分为单缺陷、双缺陷、三缺陷以及四缺陷\n",
    "\n",
    "test_single_wm = []  # 先定义列表，然后转换为tensor\n",
    "test_single_label = []\n",
    "test_single_att = []\n",
    "\n",
    "test_two_wm = []\n",
    "test_two_label = []\n",
    "test_two_att = []\n",
    "\n",
    "test_three_wm = []\n",
    "test_three_label = []\n",
    "test_three_att = []\n",
    "\n",
    "test_four_wm = []\n",
    "test_four_label = []\n",
    "test_four_att = []\n",
    "for i in range(len(test_label_oh)):\n",
    "    if test_label_oh[i].sum() <= 1:\n",
    "        test_single_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_single_label.append(test_label[i])\n",
    "        test_single_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 2:\n",
    "        test_two_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_two_label.append(test_label[i])\n",
    "        test_two_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 3:\n",
    "        test_three_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_three_label.append(test_label[i])\n",
    "        test_three_att.append(np.array(test_att_tensor[i]))\n",
    "    elif test_label_oh[i].sum() == 4:\n",
    "        test_four_wm.append(np.array(test_wm_tensor[i]))\n",
    "        test_four_label.append(test_label[i])\n",
    "        test_four_att.append(np.array(test_att_tensor[i]))\n",
    "\n",
    "del test_data,test_wm_tensor,test_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wm = train_single_wm + pseudo_two_wm + pseudo_three_wm + pseudo_four_wm\n",
    "train_label = train_single_label + pseudo_two_label + pseudo_three_label + pseudo_four_label\n",
    "train_att = train_single_att + pseudo_two_att + pseudo_three_att + pseudo_four_att\n",
    "\n",
    "train_wm_tensor = torch.tensor(np.array(train_wm), dtype=torch.float32)\n",
    "train_att_tensor = torch.tensor(np.array(train_att), dtype=torch.float32)\n",
    "# 由于更新语义需要的样本较多，所以我们使用训练集的样本来更新语义\n",
    "train_single_wm_tensor = torch.tensor(np.array(train_single_wm), dtype=torch.float32)\n",
    "train_two_wm_tensor = torch.tensor(np.array(train_two_wm), dtype=torch.float32)\n",
    "train_three_wm_tensor = torch.tensor(np.array(train_three_wm), dtype=torch.float32)\n",
    "train_four_wm_tensor = torch.tensor(np.array(train_four_wm), dtype=torch.float32)\n",
    "\n",
    "\n",
    "val_wm = val_single_wm + val_two_wm + val_three_wm + val_four_wm\n",
    "val_label = val_single_label + val_two_label + val_three_label + val_four_label\n",
    "val_att = val_single_att + val_two_att + val_three_att + val_four_att\n",
    "\n",
    "val_wm_tensor = torch.tensor(np.array(val_wm), dtype=torch.float32)\n",
    "val_att_tensor = torch.tensor(np.array(val_att), dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_wm = test_single_wm + test_two_wm + test_three_wm + test_four_wm\n",
    "test_label = test_single_label + test_two_label + test_three_label + test_four_label\n",
    "test_att = test_single_att + test_two_att + test_three_att + test_four_att\n",
    "\n",
    "test_wm_tensor = torch.tensor(np.array(test_wm), dtype=torch.float32)\n",
    "test_att_tensor = torch.tensor(np.array(test_att), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_wm_tensor)\n",
    "val_size = len(val_wm_tensor)\n",
    "test_size = len(test_wm_tensor)\n",
    "# 因为我们每次训练后，需要更新训练样本的语义，所以我们的dataset和dataloader在训练的for循环里定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_defect_att = attri.single_defect_att\n",
    "two_defect_att = attri.two_defect_att\n",
    "three_defect_att = attri.three_defect_att\n",
    "four_defect_att = attri.four_defect_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们使用已经在可见类上训练，建立了一定的视觉到语义映射关系的模型\n",
    "model = torch.load('model_saved_pseudo/train_all.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 如果需要微调后面的层，可以选择性地解冻\n",
    "for param in model.fc.parameters():  # 解冻全连接层和sigmoid\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.sigmoid.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练时需要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备为：cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 定义训练的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') # 只有一张显卡的话，'cuda'和'cuda:0'是一样的\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'使用的设备为：{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_file.func_Test import Test_Func\n",
    "# 需要的函数都已经集成在了Test_Func里\n",
    "func = Test_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们以余弦相似度进行KNN\n",
    "def cosine_similarity(v1, v2):  # 参数v1,v2是np.array,不能是tensor，可以用np.array()将tensor转换为array\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    # 计算两个向量的模\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    # 计算余弦相似度\n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def knn(query_embedding, embeddings, k=5):\n",
    "    similarities = []\n",
    "    for embedding in embeddings:\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append(similarity)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]  # [::-1] 表示逆序，因为np.argsort()默认是升序\n",
    "\n",
    "    k_embeddings = []\n",
    "    for i in range(k):\n",
    "        k_embeddings.append(embeddings[sorted_indices[i]])\n",
    "    k_embeddings = np.array(k_embeddings)  # 转换为np.array\n",
    "    return k_embeddings  # 返回了与query最相似的k个embedding\n",
    "\n",
    "\n",
    "def update_semantic(model, old_att_dict, inputs, k=5):\n",
    "    outputs = []\n",
    "    for wm in inputs:\n",
    "        wm = wm.to(device)\n",
    "        wm = wm.reshape((1,1,224,224))\n",
    "        out = model(wm)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        out = out.reshape((-1,))  # out是一个一维向量，需要将其转换为一维向量\n",
    "        outputs.append(out)\n",
    "    new_att_dict = {}\n",
    "    for label,att in old_att_dict.items():\n",
    "        k_embeddings = knn(att, outputs, k=k)\n",
    "        new_att = np.mean(k_embeddings, axis=0)\n",
    "        new_att_dict[label] = torch.tensor(new_att, dtype=torch.float32)\n",
    "\n",
    "    return new_att_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_func = nn.MSELoss().to(device=device)\n",
    "learning_rate = 1e-2  # 0.01\n",
    "optimizer = torch.optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20  # 训练迭代的次数，一个epoch把训练集过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————第1轮训练开始————\n",
      "训练时间为：9.080036878585815, 总Loss:5.689762492198497\n",
      "****第1轮训练结束****\n",
      "第1轮训练后,整体验证集上的Loss:1.3668226449517533\n",
      "第1轮训练后,整体验证集上的Accuracy:0.9064864864864864\n",
      "————第2轮训练开始————\n",
      "训练时间为：8.74190616607666, 总Loss:5.480696703307331\n",
      "****第2轮训练结束****\n",
      "第2轮训练后,整体验证集上的Loss:1.3352903932973277\n",
      "第2轮训练后,整体验证集上的Accuracy:0.9037837837837838\n",
      "————第3轮训练开始————\n",
      "训练时间为：8.898241758346558, 总Loss:5.361566722393036\n",
      "****第3轮训练结束****\n",
      "第3轮训练后,整体验证集上的Loss:1.2715045353979804\n",
      "第3轮训练后,整体验证集上的Accuracy:0.9094594594594595\n",
      "————第4轮训练开始————\n",
      "训练时间为：9.200631856918335, 总Loss:5.290285538416356\n",
      "****第4轮训练结束****\n",
      "第4轮训练后,整体验证集上的Loss:1.2622649800905492\n",
      "第4轮训练后,整体验证集上的Accuracy:0.9110810810810811\n",
      "————第5轮训练开始————\n",
      "训练时间为：9.048060894012451, 总Loss:5.258677099365741\n",
      "****第5轮训练结束****\n",
      "第5轮训练后,整体验证集上的Loss:1.256811962404754\n",
      "第5轮训练后,整体验证集上的Accuracy:0.91\n",
      "————第6轮训练开始————\n",
      "训练时间为：8.784574747085571, 总Loss:5.1783354710787535\n",
      "****第6轮训练结束****\n",
      "第6轮训练后,整体验证集上的Loss:1.255641099458444\n",
      "第6轮训练后,整体验证集上的Accuracy:0.908918918918919\n",
      "————第7轮训练开始————\n",
      "训练时间为：8.80336332321167, 总Loss:5.044640564825386\n",
      "****第7轮训练结束****\n",
      "第7轮训练后,整体验证集上的Loss:1.2160365939635085\n",
      "第7轮训练后,整体验证集上的Accuracy:0.9121621621621622\n",
      "————第8轮训练开始————\n",
      "训练时间为：8.838994979858398, 总Loss:5.166445378679782\n",
      "****第8轮训练结束****\n",
      "第8轮训练后,整体验证集上的Loss:1.2308730354852742\n",
      "第8轮训练后,整体验证集上的Accuracy:0.9081081081081082\n",
      "————第9轮训练开始————\n",
      "训练时间为：9.246234655380249, 总Loss:5.071428040973842\n",
      "****第9轮训练结束****\n",
      "第9轮训练后,整体验证集上的Loss:1.1845170302403858\n",
      "第9轮训练后,整体验证集上的Accuracy:0.9135135135135135\n",
      "————第10轮训练开始————\n",
      "训练时间为：9.115483045578003, 总Loss:5.066818447317928\n",
      "****第10轮训练结束****\n",
      "第10轮训练后,整体验证集上的Loss:1.1997647634707391\n",
      "第10轮训练后,整体验证集上的Accuracy:0.91\n",
      "————第11轮训练开始————\n",
      "训练时间为：8.94853138923645, 总Loss:5.030459293164313\n",
      "****第11轮训练结束****\n",
      "第11轮训练后,整体验证集上的Loss:1.193008110014489\n",
      "第11轮训练后,整体验证集上的Accuracy:0.9105405405405406\n",
      "————第12轮训练开始————\n",
      "训练时间为：8.913463115692139, 总Loss:5.0130987744778395\n",
      "****第12轮训练结束****\n",
      "第12轮训练后,整体验证集上的Loss:1.1765660357050365\n",
      "第12轮训练后,整体验证集上的Accuracy:0.9108108108108108\n",
      "————第13轮训练开始————\n",
      "训练时间为：9.118303298950195, 总Loss:5.047141786664724\n",
      "****第13轮训练结束****\n",
      "第13轮训练后,整体验证集上的Loss:1.2082699541351758\n",
      "第13轮训练后,整体验证集上的Accuracy:0.907027027027027\n",
      "————第14轮训练开始————\n",
      "训练时间为：9.185168504714966, 总Loss:5.030260338447988\n",
      "****第14轮训练结束****\n",
      "第14轮训练后,整体验证集上的Loss:1.1951972410897724\n",
      "第14轮训练后,整体验证集上的Accuracy:0.9075675675675675\n",
      "————第15轮训练开始————\n",
      "训练时间为：8.894477844238281, 总Loss:5.010729570873082\n",
      "****第15轮训练结束****\n",
      "第15轮训练后,整体验证集上的Loss:1.1913511458114954\n",
      "第15轮训练后,整体验证集上的Accuracy:0.9054054054054054\n",
      "————第16轮训练开始————\n",
      "训练时间为：8.915177345275879, 总Loss:4.978880951181054\n",
      "****第16轮训练结束****\n",
      "第16轮训练后,整体验证集上的Loss:1.19862548308447\n",
      "第16轮训练后,整体验证集上的Accuracy:0.9064864864864864\n",
      "————第17轮训练开始————\n",
      "训练时间为：8.81509518623352, 总Loss:4.969760503154248\n",
      "****第17轮训练结束****\n",
      "第17轮训练后,整体验证集上的Loss:1.1929150553914951\n",
      "第17轮训练后,整体验证集上的Accuracy:0.9056756756756756\n",
      "————第18轮训练开始————\n",
      "训练时间为：8.885404825210571, 总Loss:4.9717346196994185\n",
      "****第18轮训练结束****\n",
      "第18轮训练后,整体验证集上的Loss:1.1909041244944092\n",
      "第18轮训练后,整体验证集上的Accuracy:0.9091891891891892\n",
      "————第19轮训练开始————\n",
      "训练时间为：8.988658428192139, 总Loss:4.9820969956927\n",
      "****第19轮训练结束****\n",
      "第19轮训练后,整体验证集上的Loss:1.2024043047858868\n",
      "第19轮训练后,整体验证集上的Accuracy:0.9045945945945946\n",
      "————第20轮训练开始————\n",
      "训练时间为：8.843646764755249, 总Loss:4.971540668047965\n",
      "****第20轮训练结束****\n",
      "第20轮训练后,整体验证集上的Loss:1.188672926655272\n",
      "第20轮训练后,整体验证集上的Accuracy:0.9056756756756756\n",
      "训练结束，第9轮的模型在验证集上准确率最高，为0.9135135135135135\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "best_acc = 0\n",
    "No = 0\n",
    "for epoch in range(epochs):\n",
    "    # 每轮训练前，我们更新缺陷类型属性\n",
    "    single_defect_att = update_semantic(model, single_defect_att, train_single_wm_tensor, 50)  # 获得新的缺陷属性字典\n",
    "    two_defect_att = update_semantic(model, two_defect_att, train_two_wm_tensor, 50)\n",
    "    three_defect_att = update_semantic(model, three_defect_att, train_three_wm_tensor, 50)\n",
    "    four_defect_att = update_semantic(model, four_defect_att, train_four_wm_tensor, 50)\n",
    "\n",
    "    total_defect_att = {**single_defect_att, **two_defect_att, **three_defect_att, **four_defect_att}\n",
    "\n",
    "    for i in range(len(train_label)):\n",
    "        train_att_tensor[i] = total_defect_att[train_label[i]]\n",
    "\n",
    "    # 定义dataset和dataloader\n",
    "    train_dataset = MyDataSet(train_wm_tensor,train_att_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    print(f'————第{epoch+1}轮训练开始————')\n",
    "\n",
    "    model.train()   # 开始训练\n",
    "    total_train_loss = 0\n",
    "    start_time = time.time()\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'训练时间为：{end_time-start_time}, 总Loss:{total_train_loss}')  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "    print(f'****第{epoch+1}轮训练结束****')\n",
    "\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()   # 开始验证\n",
    "\n",
    "    for i in range(len(val_label)):\n",
    "        val_att_tensor[i] = total_defect_att[val_label[i]]\n",
    "    # 定义dataset和dataloader\n",
    "    val_dataset = MyDataSet(val_wm_tensor, val_att_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    # with的作用是可以确保代码块执行完毕后，资源被正确释放，也就是使用with，在执行完外码块之后，它会自动地关闭所打开的内容\n",
    "    # 例如关闭文件、释放线程锁等\n",
    "    with torch.no_grad():   # 这里要进行验证，不需要修改参数，所以不计算梯度\n",
    "        for imgs,labels in val_loader:  \n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            # 计算损失\n",
    "            loss = loss_func(outputs,labels)\n",
    "            total_val_loss = total_val_loss+loss.item()  # loss是一个tensor数据类型，loss.item()是一个浮点数数据类型\n",
    "\n",
    "    # 计算准确率\n",
    "    acc = func.get_acc(model, val_loader, total_defect_att, val_size, 'cos')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Loss:{total_val_loss}')\n",
    "    print(f'第{epoch+1}轮训练后,整体验证集上的Accuracy:{acc}')\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        No = epoch+1\n",
    "        # 保存最好的模型和语义属性\n",
    "        torch.save(obj=model,f='model_saved_pseudo/all_updated.pth')\n",
    "\n",
    "        with open('updated_semantic_all/updated_single_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(single_defect_att, file)  # pickle 模块的dump函数，将数据写入文件，pickle可以写入任何类型的数据\n",
    "        with open('updated_semantic_all/updated_two_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(two_defect_att, file)\n",
    "        with open('updated_semantic_all/updated_three_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(three_defect_att, file)\n",
    "        with open('updated_semantic_all/updated_four_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(four_defect_att, file)\n",
    "        with open('updated_semantic_all/updated_total_dict.pkl', 'wb') as file:\n",
    "            pickle.dump(total_defect_att, file)\n",
    "        \n",
    "\n",
    "print(f'训练结束，第{No}轮的模型在验证集上准确率最高，为{best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset,train_loader,val_dataset,val_loader,val_wm_tensor,val_att_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_wm_tensor,train_att_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "model = torch.load('model_saved_pseudo/train_all.pth')\n",
    "with open('updated_semantic_all/updated_single_dict.pkl', 'rb') as file:\n",
    "    single_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_two_dict.pkl', 'rb') as file:\n",
    "    two_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_three_dict.pkl', 'rb') as file:\n",
    "    three_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_four_dict.pkl', 'rb') as file:\n",
    "    four_defect_att = pickle.load(file)\n",
    "with open('updated_semantic_all/updated_total_dict.pkl', 'rb') as file:\n",
    "    total_defect_att = pickle.load(file)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10623/3154717973.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "test_single_att_tensor = torch.tensor(test_single_att, dtype=torch.float32)\n",
    "for i in range(len(test_single_label)):\n",
    "    test_single_att_tensor[i] = single_defect_att[test_single_label[i]]\n",
    "\n",
    "test_two_att_tensor = torch.tensor(test_two_att, dtype=torch.float32)\n",
    "for i in range(len(test_two_label)):\n",
    "    test_two_att_tensor[i] = two_defect_att[test_two_label[i]]\n",
    "\n",
    "test_three_att_tensor = torch.tensor(test_three_att, dtype=torch.float32)\n",
    "for i in range(len(test_three_label)):\n",
    "    test_three_att_tensor[i] = three_defect_att[test_three_label[i]]\n",
    "\n",
    "test_four_att_tensor = torch.tensor(test_four_att, dtype=torch.float32)\n",
    "for i in range(len(test_four_label)):\n",
    "    test_four_att_tensor[i] = four_defect_att[test_four_label[i]]\n",
    "\n",
    "for i in range(len(test_label)):\n",
    "    test_att_tensor[i] = total_defect_att[test_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_wm_tensor = torch.tensor(test_single_wm, dtype=torch.float32)\n",
    "test_two_wm_tensor = torch.tensor(test_two_wm, dtype=torch.float32)\n",
    "test_three_wm_tensor = torch.tensor(test_three_wm, dtype=torch.float32)\n",
    "test_four_wm_tensor = torch.tensor(test_four_wm, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的属性向量tensor([-8.4590e-02,  9.1562e-01,  8.1191e-02,  4.6611e-02,  8.3880e-01,\n",
      "         9.2828e-01,  8.7764e-01,  1.0067e+00,  4.9613e-01, -7.5861e-04,\n",
      "        -5.3198e-03,  7.5355e-03,  4.2945e-01,  5.4447e-01,  4.4094e-01,\n",
      "         2.1445e-01,  8.5323e-01,  9.9173e-01,  8.1588e-01,  2.0375e-01],\n",
      "       device='cuda:0')\n",
      "真实的属性向量tensor([-0.0063,  0.9050,  0.0600,  0.0906,  0.9901,  0.9742,  0.8256,  1.0416,\n",
      "         0.9234,  0.0102,  0.0142,  0.0270,  0.9138,  0.8092,  0.9381,  0.1804,\n",
      "         0.8180,  1.0508,  0.8682,  0.0960])\n",
      "真实标签为：D+ER+S\n",
      "欧式距离计算的标签为：D+ER\n",
      "余弦相似度计算的标签为：D+ER+S\n"
     ]
    }
   ],
   "source": [
    "func.show_result(model, test_wm_tensor, test_att_tensor, total_defect_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集里的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = MyDataSet(test_single_wm_tensor, test_single_att_tensor)\n",
    "test_two_dataset = MyDataSet(test_two_wm_tensor, test_two_att_tensor)\n",
    "test_three_dataset = MyDataSet(test_three_wm_tensor, test_three_att_tensor)\n",
    "test_four_dataset = MyDataSet(test_four_wm_tensor, test_four_att_tensor)\n",
    "test_dataset = MyDataSet(test_wm_tensor, test_att_tensor)\n",
    "\n",
    "test_single_loader = DataLoader(test_single_dataset, batch_size=32, shuffle=False)\n",
    "test_two_loader = DataLoader(test_two_dataset, batch_size=32, shuffle=False)\n",
    "test_three_loader = DataLoader(test_three_dataset, batch_size=32, shuffle=False)\n",
    "test_four_loader = DataLoader(test_four_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694704049844237\n",
      "0.9707692307692307\n",
      "0.9458333333333333\n",
      "0.93375\n",
      "0.9114112086428089\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, single_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, two_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, three_defect_att, len(test_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_four_loader, four_defect_att, len(test_four_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_loader, total_defect_att, len(test_dataset), 'cos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9538940809968848\n",
      "0.9365384615384615\n",
      "0.8854166666666666\n",
      "0.8225\n"
     ]
    }
   ],
   "source": [
    "print(func.get_acc(model, test_single_loader, total_defect_att, len(test_single_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_two_loader, total_defect_att, len(test_two_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_three_loader, total_defect_att, len(test_three_dataset), 'cos'))\n",
    "print(func.get_acc(model, test_four_loader, total_defect_att, len(test_four_dataset), 'cos'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
